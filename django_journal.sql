/*
 Navicat Premium Data Transfer

 Source Server         : localhost
 Source Server Type    : MySQL
 Source Server Version : 100427 (10.4.27-MariaDB)
 Source Host           : localhost:3306
 Source Schema         : django_journal

 Target Server Type    : MySQL
 Target Server Version : 100427 (10.4.27-MariaDB)
 File Encoding         : 65001

 Date: 11/02/2023 14:41:36
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for app_article
-- ----------------------------
DROP TABLE IF EXISTS `app_article`;
CREATE TABLE `app_article`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `volume` int NOT NULL,
  `issue` int NOT NULL,
  `issue_title` varchar(300) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `date` datetime(6) NOT NULL,
  `title` varchar(500) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `abstract` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `text` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `created_at` datetime(6) NOT NULL,
  `state` varchar(15) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `published_at` datetime(6) NULL DEFAULT NULL,
  `author_id` int NOT NULL,
  `journal_id` int NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `app_article_journal_id_98adda81_fk_app_journal_id`(`journal_id` ASC) USING BTREE,
  INDEX `app_article_author_id_95508eba_fk_app_myuser_id`(`author_id` ASC) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 9 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of app_article
-- ----------------------------
INSERT INTO `app_article` VALUES (1, 1, 1, 'ON INSTANTANEOUS FREQUENCY', '2020-05-15 17:47:22.000000', 'ON INSTANTANEOUS FREQUENCY', 'Instantaneous frequency (IF) is necessary for understanding the detailed mechanisms for nonlinear and nonstationary processes. Historically, IF was computed from analytic signal (AS) through the Hilbert transform. This paper offers an overview of the difficulties involved in using AS, and two new methods to overcome the difficulties for computing IF. The first approach is to compute the quadrature (defined here as a simple 90° shift of phase angle) directly. The second approach is designated as', '<p>Instantaneous frequency (IF) is necessary for understanding the detailed mechanisms for nonlinear and nonstationary processes. Historically, IF was computed from analytic signal (AS) through the Hilbert transform. This paper offers an overview of the difficulties involved in using AS, and two new methods to overcome the difficulties for computing IF. The first approach is to compute the quadrature (defined here as a simple 90&deg; shift of phase angle) directly. The second approach is designated as the normalized Hilbert transform (NHT), which consists of applying the Hilbert transform to the empirically determined FM signals. Additionally, we have also introduced alternative methods to compute local frequency, the generalized zero-crossing (GZC), and the teager energy operator (TEO) methods. Through careful comparisons, we found that the NHT and direct quadrature gave the best overall performance. While the TEO method is the most localized, it is limited to data from linear processes, the GZC method is the most robust and accurate although limited to the mean frequency over a quarter wavelength of temporal resolution. With these results, we believe most of the problems associated with the IF determination are resolved, and a true time&ndash;frequency analysis is thus taking another step toward maturity.<img alt=\"\" src=\"data:image/jpeg;base64,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\" style=\"float:left; height:177px; width:285px\" /></p>\r\n\r\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\" style=\"width:500px\">\r\n	<tbody>\r\n		<tr>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n		<tr>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n		<tr>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p>&nbsp;</p>', '2020-05-15 17:47:22.403744', 'Published', '2020-05-16 17:57:05.000000', 5, 1);
INSERT INTO `app_article` VALUES (2, 1, 2, 'An Overview of the CERN Beamline for Schools Compe', '2020-05-16 05:55:13.000000', 'An Overview of the CERN Beamline for Schools Compe', 'Since 2014 CERN has been organizing “Beamline for Schools” (BL4S), an international science competition for teams of high school students. The students are asked to propose an experiment that can be realized at a particle beam line. Experienced scientists evaluate the proposals and select two winning teams that are then invited to perform their experiments with the help of professional scientists. This paper provides a brief overview of the competition and presents in more detail the conditions', '<p>Since 2014 CERN has been organizing &ldquo;Beamline for Schools&rdquo; (BL4S), an international science competition for teams of high school students. The students are asked to propose an experiment that can be realized at a particle beam line. Experienced scientists evaluate the proposals and select two winning teams that are then invited to perform their experiments with the help of professional scientists. This paper provides a brief overview of the competition and presents in more detail the conditions of the beam lines as well as the pool of detectors and instruments that are available to the students. The paper closes with an outlook on the future of the competition.<img alt=\"\" src=\"https://www.worldscientific.com/na101/home/literatum/publisher/wspc/journals/covergifs/tpe/cover.jpg\" style=\"float:left; height:582px; width:450px\" /></p>', '2020-05-16 05:55:14.007016', 'Published', '2020-05-16 17:56:16.000000', 5, 2);
INSERT INTO `app_article` VALUES (3, 1, 2, 'A kernel for multi-parameter persistent homology', '2020-05-17 15:24:08.000000', 'A kernel for multi-parameter persistent homology', 'Topological data analysis and its main method, persistent homology, provide a toolkit for computing topological information of high-dimensional and noisy data sets. Kernels for one-parameter persistent homology have been established to connect persistent homology with machine learning techniques with applicability on shape analysis, recognition and classification. We contribute a kernel construction for multi-parameter persistence by integrating a one-parameter kernel weighted along straight lines. We prove that our kernel is stable and efficiently computable, which establishes a theoretical connection between topological data analysis and machine learning for multivariate data analysis.', '<h2>1.&nbsp;Introduction</h2>\r\n\r\n<p>Topological data analysis (TDA) is an active area in data science with a growing interest and notable successes in a number of applications in science and engineering&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0001\" name=\"bbib0001\">[1]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0002\" name=\"bbib0002\">[2]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0003\" name=\"bbib0003\">[3]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0004\" name=\"bbib0004\">[4]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0005\" name=\"bbib0005\">[5]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0006\" name=\"bbib0006\">[6]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0007\" name=\"bbib0007\">[7]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0008\" name=\"bbib0008\">[8]</a>. TDA extracts in-depth geometric information in amorphous solids&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0005\" name=\"bbib0005\">[5]</a>, determines robust topological properties of evolution from genomic data sets&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0002\" name=\"bbib0002\">[2]</a>&nbsp;and identifies distinct diabetes subgroups&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0006\" name=\"bbib0006\">[6]</a>&nbsp;and a new subtype of breast cancer&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0009\" name=\"bbib0009\">[9]</a>&nbsp;in high-dimensional clinical data sets, to name a few. In the context of shape analysis, TDA techniques have been used in the recognition, classification&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0010\" name=\"bbib0010\">[10]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0011\" name=\"bbib0011\">[11]</a>, summarization&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0012\" name=\"bbib0012\">[12]</a>, and clustering&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0013\" name=\"bbib0013\">[13]</a>&nbsp;of 2D/3D shapes and surfaces. Oftentimes, such techniques capture and highlight structures in data that conventional techniques fail to treat&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0011\" name=\"bbib0011\">[11]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0013\" name=\"bbib0013\">[13]</a>&nbsp;or reveal properly&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0005\" name=\"bbib0005\">[5]</a>.</p>\r\n\r\n<p>TDA employs the mathematical notion of&nbsp;<em>simplicial complexes</em>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0014\" name=\"bbib0014\">[14]</a>&nbsp;to encode higher order interactions in the system, and at its core uses the computational framework of&nbsp;<em>persistent homology</em>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0015\" name=\"bbib0015\">[15]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0016\" name=\"bbib0016\">[16]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0017\" name=\"bbib0017\">[17]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0018\" name=\"bbib0018\">[18]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0019\" name=\"bbib0019\">[19]</a>&nbsp;to extract multi-scale topological features of the data. In particular, TDA extracts a rich set of topological features from high-dimensional and noisy data sets that complement geometric and statistical features, which offers a different perspective for machine learning. The question is,&nbsp;<em>how can we establish and enrich the theoretical connections between TDA and machine learning</em>?</p>\r\n\r\n<p>Informally,&nbsp;<em>homology</em>&nbsp;was developed to classify topological spaces by examining their topological features such as connected components, tunnels, voids and holes of higher dimensions;&nbsp;<em>persistent homology</em>&nbsp;studies homology of a data set at multiple scales. Such information is summarized by the&nbsp;<em>persistence diagram</em>, a finite multi-set of points in the plane. A persistence diagram yields a complete description of the topological properties of a data set, making it an attractive tool to define features of data that take topology into consideration. Furthermore, a celebrated theorem of persistent homology is the&nbsp;<em>stability</em>&nbsp;of persistence diagrams&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0020\" name=\"bbib0020\">[20]</a>&nbsp;&ndash; small changes in the data lead to small changes of the corresponding diagrams, making it suitable for robust data analysis.</p>\r\n\r\n<p>However, interfacing persistence diagrams directly with machine learning poses technical difficulties, because persistence diagrams contain point sets in the plane that do not have the structure of an inner product, which allows length and angle to be measured. In other words, such diagrams lack a Hilbert space structure for kernel-based learning methods such as kernel SVMs or PCAs&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0021\" name=\"bbib0021\">[21]</a>. Recent work proposes several variants of&nbsp;<em>feature maps</em>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0021\" name=\"bbib0021\">[21]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0022\" name=\"bbib0022\">[22]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0023\" name=\"bbib0023\">[23]</a>&nbsp;that transform persistence diagrams into&nbsp;<em>L</em><sup>2</sup>-functions over&nbsp;R2. This idea immediately enables the application of topological features for kernel-based machine learning methods as establishing a kernel function implicitly defines a Hilbert space structure&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0021\" name=\"bbib0021\">[21]</a>.</p>\r\n\r\n<p>A serious limit of standard persistent homology and its initial interfacing with machine learning&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0021\" name=\"bbib0021\">[21]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0022\" name=\"bbib0022\">[22]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0023\" name=\"bbib0023\">[23]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0024\" name=\"bbib0024\">[24]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0025\" name=\"bbib0025\">[25]</a>&nbsp;is the restriction to only a single scale parameter, thereby confining its applicability to the univariate setting. However, in many real-world applications, such as data acquisition and geometric modeling, we often encounter richer information described by multivariate data sets&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0026\" name=\"bbib0026\">[26]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0027\" name=\"bbib0027\">[27]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0028\" name=\"bbib0028\">[28]</a>. Consider, for example, climate simulations where multiple physical parameters such as temperature and pressure are computed simultaneously; and we are interested in understanding the interplay between these parameters. Consider another example in multivariate shape analysis, various families of functions carry information about the geometry of 3D shape objects, such as mesh density, eccentricity&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0029\" name=\"bbib0029\">[29]</a>&nbsp;or Heat Kernel Signature&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0030\" name=\"bbib0030\">[30]</a>; and we are interested in creating multivariate signatures of shapes from such functions. Unlike the univariate setting, very few topological tools exist for the study of multivariate data&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0029\" name=\"bbib0029\">[29]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0031\" name=\"bbib0031\">[31]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0032\" name=\"bbib0032\">[32]</a>, let alone the integration of multivariate topological features with machine learning.</p>\r\n\r\n<p>The active area of&nbsp;<em>multi-parameter persistent homology</em>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0026\" name=\"bbib0026\">[26]</a>&nbsp;studies the extension of persistence to two or more (independent) scale parameters. A complete discrete invariant such as the persistence diagram does not exist for more than one parameter&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0026\" name=\"bbib0026\">[26]</a>. To gain partial information, it is common to study&nbsp;<em>slices</em>, that is, one-dimensional affine subspaces where all parameters are connected by a linear equation. In this paper, we establish, for the first time, a theoretical connection between topological features and machine learning algorithms via the kernel approach for multi-parameter persistent homology. Such a theoretical underpinning is necessary for applications in multivariate data analysis.</p>\r\n\r\n<h3>Our contribution</h3>\r\n\r\n<p>We propose the first kernel construction for multi-parameter persistent homology. Our kernel is&nbsp;<em>generic, stable</em>&nbsp;and can be&nbsp;<em>approximated in polynomial time</em>. For simplicity, we formulate all our results for the case of two parameters, although they extend to more than two parameters.</p>\r\n\r\n<p>Our input is a data set that is filtered according to two scale parameters and has a finite description size; we call this a&nbsp;<em>bi-filtration</em>&nbsp;and postpone its formal definition to&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#sec0002\" name=\"bsec0002\">Section&nbsp;2</a>. Our main contribution is the definition of a feature map that assigns to a bi-filtration&nbsp;X&nbsp;a function&nbsp;&Phi;X:&Delta;(2)&rarr;R,&nbsp;where &Delta;<sup>(2)</sup>&nbsp;is a subset of&nbsp;R4. Moreover,&nbsp;&Phi;X2&nbsp;is integrable over &Delta;<sup>(2)</sup>, effectively including the space of bi-filtrations into the Hilbert space&nbsp;<em>L</em><sup>2</sup>(&Delta;<sup>(2)</sup>). Therefore, based on the standard scalar product in&nbsp;<em>L</em><sup>2</sup>(&Delta;<sup>(2)</sup>), a 2-parameter kernel is defined such that for two given bi-filtrations&nbsp;X&nbsp;and&nbsp;Y&nbsp;we have(1)〈X,Y〉&Phi;:=&int;&Delta;(2)&Phi;X&Phi;Yd&mu;.We construct our feature map by interpreting a point of &Delta;<sup>(2)</sup>&nbsp;as a pair of (distinct) points in&nbsp;R2&nbsp;that define a unique slice. Along this slice, the data simplifies to a&nbsp;<em>mono-filtration</em>&nbsp;(i.e., a filtration that depends on a single scale parameter), and we can choose among a large class of feature maps and kernel constructions of standard, one-parameter persistence. To make the feature map well-defined, we restrict our attention to a finite rectangle&nbsp;<em>R</em>.</p>\r\n\r\n<p>Our inclusion into a Hilbert space induces a distance between bi-filtrations as(2)d&Phi;(X,Y):=&int;(&Phi;X&minus;&Phi;Y)2d&mu;.We prove a stability bound, relating this distance measure to the matching distance and the interleaving distance (see the paragraph on related work below). We also show that this stability bound is tight up to constant factors (see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#sec0004\" name=\"bsec0004\">Section&nbsp;4</a>).</p>\r\n\r\n<p>Finally, we prove that our kernel construction admits an efficient approximation scheme. Fixing an absolute error bound ϵ, we give a polynomial time algorithm in 1/ϵ and the size of the bi-filtrations&nbsp;X&nbsp;and&nbsp;Y&nbsp;to compute a value&nbsp;<em>r</em>&nbsp;such that&nbsp;r&le;〈X,Y〉&Phi;&le;r+ϵ. On a high level, the algorithm subdivides the domain into boxes of smaller and smaller width and evaluates the integral of&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#eq0001\" name=\"beq0001\">(1)</a>&nbsp;by lower and upper sums within each subdomain, terminating the process when the desired accuracy has been achieved. The technical difficulty lies in the accurate and certifiable approximation of the variation of the feature map when moving the argument within a subdomain.</p>\r\n\r\n<h3>Related work</h3>\r\n\r\n<p>Our approach heavily relies on the construction of stable and efficiently computable feature maps for mono-filtrations. This line of research was started by Reininghaus et&nbsp;al.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0021\" name=\"bbib0021\">[21]</a>, whose approach we discuss in some detail in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#sec0002\" name=\"bsec0002\">Section&nbsp;2</a>. Alternative kernel constructions appeared in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0024\" name=\"bbib0024\">[24]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0033\" name=\"bbib0033\">[33]</a>. Kernel constructions fit into the general framework of including the space of persistence diagrams in a larger space with more favorable properties. Other examples of this idea are persistent landscapes&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0022\" name=\"bbib0022\">[22]</a>&nbsp;and persistent images&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0034\" name=\"bbib0034\">[34]</a>, which can be interpreted as kernel constructions as well. Kernels and related variants defined on mono-filtrations have been used to discriminate and classify shapes and surfaces&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0021\" name=\"bbib0021\">[21]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0025\" name=\"bbib0025\">[25]</a>. An alternative approach comes from the definition of suitable (polynomial) functions on persistence diagrams to arrive at a fixed-dimensional vector in&nbsp;Rd&nbsp;on which machine learning tasks can be performed; see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0035\" name=\"bbib0035\">[35]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0036\" name=\"bbib0036\">[36]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0037\" name=\"bbib0037\">[37]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0038\" name=\"bbib0038\">[38]</a>.</p>\r\n\r\n<p>As previously mentioned, a persistence diagram for multi-parameter persistence does not exist&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0026\" name=\"bbib0026\">[26]</a>. However, bi-filtrations still admit meaningful distance measures, which lead to the notion of closeness of two bi-filtrations. The most prominent such distance is the&nbsp;<em>interleaving distance</em>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0039\" name=\"bbib0039\">[39]</a>, which, however, has recently been proved to be NP-complete to compute and approximate&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0040\" name=\"bbib0040\">[40]</a>. Computationally attractive alternatives are (multi-parameter) bottleneck distance&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0041\" name=\"bbib0041\">[41]</a>&nbsp;and the&nbsp;<em>matching distance</em>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0042\" name=\"bbib0042\">[42]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0043\" name=\"bbib0043\">[43]</a>, which compares the persistence diagrams along all slices (appropriately weighted) and picks the worst discrepancy as the distance of the bi-filtrations. This distance can be approximated up to a precision ϵ using an appropriate subsample of the lines&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0042\" name=\"bbib0042\">[42]</a>, and also computed exactly in polynomial time&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0043\" name=\"bbib0043\">[43]</a>. Our approach extends these works in the sense that not just a distance, but an inner product on bi-filtrations, is defined with our inclusion into a Hilbert space. In a similar spirit, the software library RIVET&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0044\" name=\"bbib0044\">[44]</a>&nbsp;provides a visualization tool to explore bi-filtrations by scanning through the slices.</p>\r\n\r\n<h2>2.&nbsp;Preliminaries</h2>\r\n\r\n<p>We introduce the basic topological terminology needed in this work. We restrict ourselves to the case of simplicial complexes as input structures for a clearer geometric intuition of the concepts, but our results generalize to more abstract input types (such as minimal representations of persistence modules) without problems.</p>\r\n\r\n<h3>Mono-filtrations</h3>\r\n\r\n<p>Given a vertex set&nbsp;<em>V</em>, an&nbsp;<em>(abstract) simplex</em>&nbsp;is a non-empty subset of&nbsp;<em>V</em>, and an&nbsp;<em>(abstract) simplicial complex</em>&nbsp;is a collection of such subsets that is closed under the operation of taking non-empty subsets. A&nbsp;<em>subcomplex</em>&nbsp;of a simplicial complex&nbsp;<em>X</em>&nbsp;is a simplicial complex&nbsp;<em>Y</em>&nbsp;with&nbsp;<em>Y</em>&sube;<em>X</em>. Fixing a finite simplicial complex&nbsp;<em>X</em>, a&nbsp;<em>mono-filtration</em>&nbsp;X&nbsp;of&nbsp;<em>X</em>&nbsp;is a map that assigns to each real number&nbsp;<em>&alpha;</em>, a subcomplex&nbsp;X(&alpha;)&nbsp;of&nbsp;<em>X</em>, with the property that whenever&nbsp;<em>&alpha;</em> &le; <em>&beta;</em>,&nbsp;X(&alpha;)&sube;X(&beta;). The&nbsp;<em>size</em>&nbsp;of&nbsp;X&nbsp;is the number of simplices of&nbsp;<em>X</em>. Since&nbsp;<em>X</em>&nbsp;is finite,&nbsp;X(&alpha;)&nbsp;changes at only finitely many places when&nbsp;<em>&alpha;</em>&nbsp;grows continuously from&nbsp;&minus;&infin;&nbsp;to&nbsp;+&infin;; we call these values&nbsp;<em>critical</em>. More formally,&nbsp;<em>&alpha;</em>&nbsp;is&nbsp;<em>critical</em>&nbsp;if there exists no open neighborhood of&nbsp;<em>&alpha;</em>&nbsp;such that the mono-filtration assigns the identical subcomplex to each value in the neighborhood. For a simplex&nbsp;<em>&sigma;</em>&nbsp;of&nbsp;<em>X</em>, we call the&nbsp;<em>critical value</em>&nbsp;of&nbsp;<em>&sigma;</em>&nbsp;the infimum over all&nbsp;<em>&alpha;</em>&nbsp;for which&nbsp;&sigma;&isin;X(&alpha;). For simplicity, we assume that this infimum is a minimum, so every simplex has a unique critical value wherever it is included in the mono-filtration.</p>\r\n\r\n<h3>Bi-filtrations</h3>\r\n\r\n<p>For points in&nbsp;R2,&nbsp;we write (<em>a, b</em>) &le; (<em>c, d</em>) if&nbsp;<em>a</em> &le; <em>c</em>&nbsp;and&nbsp;<em>b</em> &le; <em>d</em>. Similarly, we say (<em>a, b</em>) &lt; (<em>c, d</em>) if&nbsp;<em>a</em> &lt; <em>c</em>&nbsp;and&nbsp;<em>b</em> &lt; <em>d</em>. For a finite simplicial complex&nbsp;<em>X</em>, a&nbsp;<em>bi-filtration</em>&nbsp;X&nbsp;of&nbsp;<em>X</em>&nbsp;is a map that assigns to each point&nbsp;p&isin;R2&nbsp;a subcomplex&nbsp;X(p)&nbsp;of&nbsp;<em>X</em>, such that whenever&nbsp;<em>p</em> &le; <em>q</em>,&nbsp;X(p)&sube;X(q). Again, a point&nbsp;p=(p1,p2)&nbsp;is called&nbsp;<em>critical</em>&nbsp;for&nbsp;X&nbsp;if, for any ϵ &gt; 0, both&nbsp;X(p1&minus;ϵ,p2)&nbsp;and&nbsp;X(p1,p2&minus;ϵ)&nbsp;are not identical to&nbsp;X(p). Note that unlike in the mono-filtration case, the set of critical points might not be finite. We call a bi-filtration&nbsp;<em>tame</em>&nbsp;if it has only finitely many such critical points. For a simplex&nbsp;<em>&sigma;</em>, a point&nbsp;p&isin;R2&nbsp;is&nbsp;<em>critical</em>&nbsp;for&nbsp;<em>&sigma;</em>&nbsp;if, for any ϵ &gt; 0,&nbsp;<em>&sigma;</em>&nbsp;is neither in&nbsp;X(p1&minus;ϵ,p2)&nbsp;nor in&nbsp;X(p1,p2&minus;ϵ),&nbsp;whereas&nbsp;<em>&sigma;</em>&nbsp;is in both&nbsp;X(p1+ϵ,p2)&nbsp;and&nbsp;X(p1,p2+ϵ). Again, for simplicity, we assume that&nbsp;&sigma;&isin;X(p)&nbsp;in this case. A consequence of tameness is that each simplex has a finite number of critical points. Therefore, we can represent a tame bi-filtration of a finite simplicial complex&nbsp;<em>X</em>&nbsp;by specifying the set of critical points for each simplex in&nbsp;<em>X</em>. The sum of the number of critical points over all simplices of&nbsp;<em>X</em>&nbsp;is called the&nbsp;<em>size</em>&nbsp;of the bi-filtration. We henceforth assume that bi-filtrations are always represented in this form; in particular, we assume tameness throughout this paper.</p>\r\n\r\n<p>A standard example to generate bi-filtrations is by an arbitrary function&nbsp;F:X&rarr;R2&nbsp;with the property that if&nbsp;<em>&tau;</em>&thinsp;&sub;&thinsp;<em>&sigma;</em>&nbsp;are two simplices of&nbsp;<em>X, F</em>(<em>&tau;</em>) &le; <em>F</em>(<em>&sigma;</em>). We define the&nbsp;<em>sublevel set</em>&nbsp;XF(p)&nbsp;asXF(p):={&sigma;&isin;X∣F(&sigma;)&le;p},and let&nbsp;XF&nbsp;denote its corresponding&nbsp;<em>sublevel set bi-filtration</em>. It is easy to verify that&nbsp;XF&nbsp;yields a (tame) bi-filtration and&nbsp;<em>F</em>(<em>&sigma;</em>) is the unique critical value of&nbsp;<em>&sigma;</em>&nbsp;in the bi-filtration.</p>\r\n\r\n<h3>Slices of a bi-filtration</h3>\r\n\r\n<p>A bi-filtration&nbsp;X&nbsp;contains an infinite collection of mono-filtrations. Let&nbsp;L&nbsp;be the set of all non-vertical lines in&nbsp;R2&nbsp;with positive slope. Fixing any line&nbsp;ℓ&isin;L,&nbsp;we observe that when traversing this line in positive direction, the subcomplexes of the bi-filtration are nested in each other. Note that ℓ intersects the anti-diagonal&nbsp;x=&minus;y&nbsp;in a unique base point&nbsp;<em>b</em>. Parameterizing ℓ as&nbsp;b+&lambda;&middot;a,&nbsp;where&nbsp;<em>a</em>&nbsp;is the (positive) unit direction vector of ℓ, we obtain the mono-filtrationXℓ(&alpha;):=X(b+&alpha;&middot;a).We will refer to this mono-filtration&nbsp;Xℓ&nbsp;as a&nbsp;<em>slice</em>&nbsp;of&nbsp;X&nbsp;along ℓ (and sometimes also call ℓ itself the slice, abusing notation). The critical values of a slice can be inferred by the critical points of the bi-filtration in a computationally straightforward way. Instead of a formal description, we refer to&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0001\" name=\"bfig0001\">Fig.&nbsp;1</a>&nbsp;for a graphical description. Also, if the bi-filtration is of size&nbsp;<em>n</em>, each of its slices is of size at most&nbsp;<em>n</em>.</p>\r\n\r\n<p><img alt=\"Fig. 1\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S2590148619300056-gr1.jpg\" style=\"height:194px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S2590148619300056-gr1.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 1.&nbsp;The three black points mark the three critical points of some simplex&nbsp;<em>&sigma;</em>&nbsp;in&nbsp;<em>X</em>. The shaded area denotes the positions at which&nbsp;<em>&sigma;</em>&nbsp;is present in the bi-filtration. Along the given slice (red line), the dashed lines denote the first position where the corresponding critical point &ldquo;affects&rdquo; the slice. This position is either the upper-vertical, or right-horizontal projection of the critical point onto the slice, depending on whether the critical point is below or above the line. For&nbsp;<em>&sigma;</em>, we see that it enters the slice at the position marked by the blue point.</p>\r\n\r\n<h3>Persistent homology</h3>\r\n\r\n<p>A mono-filtration&nbsp;X&nbsp;gives rise to a persistence diagram. Formally, we obtain this diagram by applying the homology functor to&nbsp;X,&nbsp;yielding a sequence of vector spaces and linear maps between them, and splitting this sequence into indecomposable parts using representation theory. Instead of rolling out the entire theory (which is explained, for instance, in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0045\" name=\"bbib0045\">[45]</a>), we give an intuitive description here.</p>\r\n\r\n<p>Persistent homology measures how the topological features of a data set evolve when considered across a varying scale parameter&nbsp;<em>&alpha;</em>. The most common example involves a point cloud in&nbsp;Rd,&nbsp;where considering a fixed scale&nbsp;<em>&alpha;</em>&nbsp;means replacing the points by balls of radius&nbsp;<em>&alpha;</em>. As&nbsp;<em>&alpha;</em>&nbsp;increases, the data set undergoes various topological configurations, starting as a disconnected point cloud for&nbsp;&alpha;=0&nbsp;and ending up as a topological ball when&nbsp;<em>&alpha;</em>&nbsp;approaches &infin;; see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>(a) for an example in&nbsp;R2.</p>\r\n\r\n<p><img alt=\"Fig. 2\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S2590148619300056-gr2.jpg\" style=\"height:157px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S2590148619300056-gr2.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 2.&nbsp;Computing persistent homology of a point cloud in&nbsp;R2. (a) A nested sequence of topological spaces formed by unions of balls at increasing parameter values. (b) A mono-filtration of simplicial complexes that captures the same topological information as in (a). (c) 0-dimensional and 1-dimensional persistence diagrams combined.</p>\r\n\r\n<p>The topological information of this process can be summarized as a finite multi-set of points in the plane, called the&nbsp;<em>persistence diagram</em>. Each point of the diagram corresponds to a topological feature (i.e., connected components, tunnels, voids, etc.), and its coordinates specify at which scales the feature appears and disappears in the data. As illustrated in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>(a), all five (connected) components are born (i.e.,&nbsp;appear) at&nbsp;&alpha;=0. The green component dies (i.e., &nbsp;disappears) when it merges with the red component at&nbsp;&alpha;=2.5; similarly, the orange, blue and pink components die at scales 3, 3.2 and 3.7, respectively. The red component never dies as&nbsp;<em>&alpha;</em>&nbsp;goes to &infin;. The 0-dimensional persistence diagram is defined to have one point per component with birth and death value as its coordinates (<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>(c)). The&nbsp;<em>persistence</em>&nbsp;of a feature is then merely its distance from the diagonal. While we focus on the components, the concept generalizes to higher dimensions, such as tunnels (1-dimensional homology) and voids (2-dimensional homology). For instance, in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>(a), a tunnel appears at&nbsp;&alpha;=4.2&nbsp;and disappears at&nbsp;&alpha;=5.6,&nbsp;which gives rise to a purple point (4.2, 5.6) in the 1-dimensional persistence diagram (<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>(c)).</p>\r\n\r\n<p>From a computational point of view, the nested sequence of spaces formed by unions of balls (<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>(a)) can be replaced by a nested sequence of simplicial complexes by taking their nerves, thereby forming a mono-filtration of simplicial complexes that captures the same topological information but has a much smaller footprint (<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>(b)).</p>\r\n\r\n<p>In the context of shape analysis, we apply persistent homology to capture the topological information of 2D and 3D shape objects by employing various types of mono-filtrations. A simple example is illustrated in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0003\" name=\"bfig0003\">Fig.&nbsp;3</a>: we extract point clouds sampled from the boundary of 2D shape objects and compute the persistence diagrams using Vietoris-Rips complex filtrations.</p>\r\n\r\n<p><img alt=\"Fig. 3\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S2590148619300056-gr3.jpg\" style=\"height:400px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S2590148619300056-gr3.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 3.&nbsp;The persistence diagrams of 2D shape objects. Black and red points are 0-dimensional and 1-dimensional features respectively (ignoring points with &infin; persistence).</p>\r\n\r\n<h3>Stability of persistent homology</h3>\r\n\r\n<p>Bottleneck distance represents a similarity measure between persistence diagrams. Let&nbsp;<em>D, D</em>&prime; be two persistence diagrams. Without loss of generality, we can assume that both contain infinitely many copies of the points on the diagonal. The&nbsp;<em>bottleneck distance</em>&nbsp;between&nbsp;<em>D</em>&nbsp;and&nbsp;<em>D</em>&prime; is defined as(3)dB(D,D&prime;):=inf&gamma;supx&isin;D∥x&minus;&gamma;(x)∥&infin;,where&nbsp;<em>&gamma;</em>&nbsp;ranges over all bijections from&nbsp;<em>D</em>&nbsp;to&nbsp;<em>D</em>&prime;. We will also use the notation&nbsp;dB(X,Y)&nbsp;for two mono-filtrations instead of&nbsp;dB(D(X),D(Y))</p>\r\n\r\n<p>A crucial result for persistent homology is the&nbsp;<em>stability theorem</em>&nbsp;proven in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0046\" name=\"bbib0046\">[46]</a>&nbsp;and re-stated in our notation as follows. Given two functions&nbsp;f,g:X&rarr;R&nbsp;whose sublevel sets form two mono-filtrations of a finite simplicial complex&nbsp;<em>X</em>, the induced persistence diagrams satisfy(4)dB(Df,Dg)&le;∥f&minus;g∥&infin;:=sup&sigma;&isin;X|f(&sigma;)&minus;g(&sigma;)|.</p>\r\n\r\n<h3>Feature maps for mono-filtrations</h3>\r\n\r\n<p>Several feature maps aimed at the construction of a kernel for mono-filtrations have been proposed in the literature&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0021\" name=\"bbib0021\">[21]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0022\" name=\"bbib0022\">[22]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0023\" name=\"bbib0023\">[23]</a>. We discuss one example: the persistence scale-space kernel&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0021\" name=\"bbib0021\">[21]</a>&nbsp;assigns to a mono-filtration&nbsp;X&nbsp;an&nbsp;<em>L</em><sup>2</sup>-function&nbsp;ϕX&nbsp;defined on&nbsp;&Delta;(1):={(x1,x2)&isin;R2∣x1&lt;x2}. The main idea behind the definition of&nbsp;ϕX&nbsp;is to define a sum of Gaussian peaks, all of the same height and width, with each peak centered at one finite off-diagonal point of the persistence diagram&nbsp;D(X)&nbsp;of&nbsp;X. To make the construction robust against perturbations, the function has to be equal to 0 across the diagonal (the boundary of &Delta;<sup>(1)</sup>). This is achieved by adding negative Gaussian peaks at the reflections of the off-diagonal points along the diagonal. Writing&nbsp;z&macr;&nbsp;for the reflection of a point&nbsp;<em>z</em>, we obtain the formula,(5)ϕX(x):=14&pi;t&sum;z&isin;D(X)e∥x&minus;z∥224t&minus;e∥x&minus;z&macr;∥224t,where&nbsp;<em>t</em>&nbsp;is the width of the Gaussian, which is a free parameter of the construction. See&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0004\" name=\"bfig0004\">Fig.&nbsp;4</a>(b) and (c) for an illustration of a transformation of a persistence diagram to the function&nbsp;ϕX. The induced kernel enjoys several stability properties and can be evaluated efficiently without explicit construction of the feature map; see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0021\" name=\"bbib0021\">[21]</a>&nbsp;for details.</p>\r\n\r\n<p><img alt=\"Fig. 4\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S2590148619300056-gr4.jpg\" style=\"height:187px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S2590148619300056-gr4.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 4.&nbsp;An illustration of the construction of a feature map for multi-parameter persistent homology. (a) Given a bi-filtration&nbsp;X&nbsp;and a point (<em>p, q</em>) &isin; &Delta;<sup>(2)</sup>, the line ℓ passing through them is depicted and the parameter&nbsp;<em>&lambda;<sub>p</sub></em>&nbsp;and&nbsp;<em>&lambda;<sub>q</sub></em>&nbsp;computed. (b) The point (<em>&lambda;<sub>p</sub>, &lambda;<sub>q</sub></em>) is embedded in the persistence diagram of the mono-filtration&nbsp;Xℓ&nbsp;obtained as the slice of&nbsp;X&nbsp;along ℓ. (c) The point (<em>&lambda;<sub>p</sub>, &lambda;<sub>q</sub></em>) is assigned the value&nbsp;ϕXℓ(&lambda;p,&lambda;q)&nbsp;via the feature map&nbsp;<em>ϕ</em>.</p>\r\n\r\n<p>More generally, in this paper, we look at the class of all feature maps that assign to a mono-filtration&nbsp;X&nbsp;a function in&nbsp;<em>L</em><sup>2</sup>(&Delta;<sup>(1)</sup>). For such a feature map&nbsp;ϕX,&nbsp;we define the following properties:</p>\r\n\r\n<p>&bull;</p>\r\n\r\n<p><em>Absolutely boundedness.</em>&nbsp;There exists a constant&nbsp;<em>v</em><sub>1</sub> &gt; 0 such that, for any mono-filtration&nbsp;X&nbsp;of size&nbsp;<em>n</em>&nbsp;and any&nbsp;<em>x</em> &isin; &Delta;<sup>(1)</sup>,&nbsp;0&le;ϕX(x)&le;v1&middot;n.</p>\r\n\r\n<p>&bull;</p>\r\n\r\n<p><em>Lipschitzianity.</em>&nbsp;There exists a constant&nbsp;<em>v</em><sub>2</sub> &gt; 0 such that, for any mono-filtration&nbsp;X&nbsp;of size&nbsp;<em>n</em>&nbsp;and any&nbsp;<em>x, x</em>&prime; &isin; &Delta;<sup>(1)</sup>,&nbsp;|ϕX(x)&minus;ϕX(x&prime;)|&le;v2&middot;n&middot;∥x&minus;x&prime;∥2.</p>\r\n\r\n<p>&bull;</p>\r\n\r\n<p><em>Internal stability.</em>&nbsp;There exists a constant&nbsp;<em>v</em><sub>3</sub> &gt; 0 such that, for any pair of mono-filtrations&nbsp;X,Y&nbsp;of size&nbsp;<em>n</em>&nbsp;and any&nbsp;<em>x</em> &isin; &Delta;<sup>(1)</sup>,&nbsp;|ϕX(x)&minus;ϕY(x)|&le;v3&middot;n&middot;dB(X,Y).</p>\r\n\r\n<p>&bull;</p>\r\n\r\n<p><em>Efficiency.</em>&nbsp;For any&nbsp;<em>x</em> &isin; &Delta;<sup>(1)</sup>,&nbsp;ϕX(x)&nbsp;can be computed in polynomial time in the size of&nbsp;X,&nbsp;that is, in&nbsp;<em>O</em>(<em>n<sup>k</sup></em>) for some&nbsp;<em>k</em> &ge; 0.</p>\r\n\r\n<p>It can be verified easily that the scale-space feature map from above satisfies all these properties. The same is true, for instance, if the Gaussian peaks are replaced by linear peaks (that is, replacing the Gaussian kernel in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#eq0005\" name=\"beq0005\">(5)</a>&nbsp;by a triangle kernel).</p>\r\n\r\n<h2>3.&nbsp;A feature map for multi-parameter persistent homology</h2>\r\n\r\n<p>Let&nbsp;<em>ϕ</em>&nbsp;be a feature map (such as the scale-space kernel) that assigns to a mono-filtration a function in&nbsp;<em>L</em><sup>2</sup>(&Delta;<sup>(1)</sup>). Starting from&nbsp;<em>ϕ</em>, we construct a feature map &Phi; on the set of all bi-filtrations &Omega; that has values in a Hilbert space.</p>\r\n\r\n<p>The feature map &Phi; assigns to a bi-filtration&nbsp;X&nbsp;a function&nbsp;&Phi;X:&Delta;(2)&rarr;R. We set&Delta;(2):={(p,q)∣p&isin;R2,q&isin;R2,p&lt;q}</p>\r\n\r\n<p>as the set of all pairs of points where the first point is smaller than the second one. &Delta;<sup>(2)</sup>&nbsp;can be interpreted naturally as a subset of&nbsp;R4,&nbsp;but we will usually consider elements of &Delta;<sup>(2)</sup>&nbsp;as pairs of points in&nbsp;R2.</p>\r\n\r\n<p>Fixing (<em>p, q</em>) &isin; &Delta;<sup>(2)</sup>, let ℓ denote the unique slice through these two points. Along this slice, the bi-filtration gives rise to a mono-filtration&nbsp;Xℓ,&nbsp;and consequently a function&nbsp;ϕXℓ:&Delta;(1)&rarr;R&nbsp;using the considered feature map for mono-filtrations. Moreover, using the parameterization of the slice ℓ as&nbsp;b+&lambda;&middot;a&nbsp;from&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#sec0002\" name=\"bsec0002\">Section&nbsp;2</a>, there exist real values&nbsp;<em>&lambda;<sub>p</sub>, &lambda;<sub>q</sub></em>&nbsp;such that&nbsp;b+&lambda;pa=p&nbsp;and&nbsp;b+&lambda;qa=q. Since&nbsp;<em>p</em> &lt; <em>q</em>&nbsp;and&nbsp;<em>&lambda;<sub>p</sub></em> &lt; <em>&lambda;<sub>q</sub></em>, hence (<em>&lambda;<sub>p</sub>, &lambda;<sub>q</sub></em>) &isin; &Delta;<sup>(1)</sup>. We define&nbsp;&Phi;X(p,q)&nbsp;to be the weighted function value of&nbsp;ϕXℓ&nbsp;at (<em>&lambda;<sub>p</sub>, &lambda;<sub>q</sub></em>) (see also&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0004\" name=\"bfig0004\">Fig.&nbsp;4</a>), that is,(6)&Phi;X(p,q):=w(p,q)&middot;ϕXℓ(&lambda;p,&lambda;q),where&nbsp;<em>w</em>(<em>p, q</em>) is a weight function&nbsp;w:&Delta;(2)&rarr;R&nbsp;defined below.</p>\r\n\r\n<p>The weight function&nbsp;<em>w</em>&nbsp;has two components. First, let&nbsp;<em>R</em>&nbsp;be a bounded axis-aligned rectangle in&nbsp;R2; its bottom-left corner coincides with the origin of the coordinate axes. We define&nbsp;<em>w</em>&nbsp;such that its weight is 0 if&nbsp;<em>p</em>&nbsp;or&nbsp;<em>q</em>&nbsp;is outside of&nbsp;<em>R</em>. Second, for pairs of points within&nbsp;<em>R</em> &times; <em>R</em>, we assign a weight depending on the slope of the induced slices. Formally, let ℓ be parameterized as&nbsp;b+&lambda;&middot;a&nbsp;as above, and recall that&nbsp;<em>a</em>&nbsp;is a unit vector with non-negative coordinates. Write&nbsp;a=(a1,a2)&nbsp;and set&nbsp;ℓ^:=min{a1,a2}. Then, we definew(p,q):=&chi;R(p)&middot;&chi;R(q)&middot;ℓ^,where&nbsp;<em>&chi;<sub>R</sub></em>&nbsp;is the characteristic function of&nbsp;<em>R</em>, mapping a point&nbsp;<em>x</em>&nbsp;to 1 if&nbsp;<em>x</em> &isin; <em>R</em>&nbsp;and 0 otherwise.</p>\r\n\r\n<p>The factor&nbsp;ℓ^&nbsp;ensures that slices that are close to being horizontal or vertical attain less importance in the feature map. The same weight is assigned to slices in the matching distance&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0042\" name=\"bbib0042\">[42]</a>.&nbsp;ℓ^&nbsp;is not important for obtaining an&nbsp;<em>L</em><sup>2</sup>-function, but its meaning will become clear in the stability results of&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#sec0004\" name=\"bsec0004\">Section&nbsp;4</a>. We also remark that the largest weight is attained for the diagonal slice with a value of&nbsp;1/2. Consequently,&nbsp;<em>w</em>&nbsp;is a non-negative function upper bounded by&nbsp;1/2.</p>\r\n\r\n<p>To summarize, our map &Phi; depends on the choice of an axis-aligned rectangle&nbsp;<em>R</em>&nbsp;and a choice of feature map for mono-filtrations, which itself might have associated parameters. For instance, using the scale-space feature map requires the choice of the width&nbsp;<em>t</em>&nbsp;(see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#eq0005\" name=\"beq0005\">(5)</a>). It is only left to argue that the image of the feature map &Phi; is indeed an&nbsp;<em>L</em><sup>2</sup>-function.</p>\r\n\r\n<p><strong>Theorem 1</strong></p>\r\n\r\n<p><em>If ϕ is absolutely bounded, then</em>&nbsp;&Phi;X&nbsp;<em>is in L</em><sup>2</sup>(&Delta;<sup>(2)</sup>)<em>.</em></p>\r\n\r\n<p><strong>Proof</strong></p>\r\n\r\n<p>Let&nbsp;X&nbsp;be a bi-filtration of size&nbsp;<em>n</em>. As mentioned earlier, each slice&nbsp;Xℓ&nbsp;is of a size at most&nbsp;<em>n</em>. By absolute boundedness and the fact that the weight function is upper bounded by&nbsp;12,&nbsp;it follows that&nbsp;|&Phi;X(p,q)|&le;v1n2&nbsp;for all (<em>p, q</em>). Since the support of&nbsp;&Phi;X&nbsp;is compact (<em>R</em> &times; <em>R</em>), the integral of&nbsp;&Phi;X2&nbsp;over &Delta;<sup>(2)</sup>&nbsp;is finite, being absolutely bounded and compactly supported.&nbsp;□</p>\r\n\r\n<p>Note that&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#enun0001\" name=\"benun0001\">Theorem&nbsp;1</a>&nbsp;remains true even without restricting the weight function to&nbsp;<em>R</em>, provided we consider a weight function that is square-integrable over &Delta;<sup>(2)</sup>. We skip the (easy) proof.</p>\r\n\r\n<h2>4.&nbsp;Stability</h2>\r\n\r\n<p>An important and desirable property for a kernel is its stability. In general, stability means that small perturbations in the input data imply small perturbations in the output data. In our setting, small changes between multi-filtrations (with respect to matching distance) should not induce large changes in their corresponding feature maps (with respect to&nbsp;<em>L</em><sup>2</sup>&nbsp;distance).</p>\r\n\r\n<p>Adopted to our notation, the matching distance is defined asdmatch(X,Y)=supℓ&isin;L(ℓ^&middot;dB(Xℓ,Yℓ)),where&nbsp;L&nbsp;is the set of non-vertical lines with positive slope&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0047\" name=\"bbib0047\">[47]</a>.</p>\r\n\r\n<p><strong>Theorem 2</strong></p>\r\n\r\n<p><em>Let</em>&nbsp;X&nbsp;<em>and</em>&nbsp;Y&nbsp;<em>be two bi-filtrations. If ϕ is absolutely bounded and internally stable, we have</em>∥&Phi;X&minus;&Phi;Y∥L2&le;C&middot;n&middot;area(R)&middot;dmatch(X,Y),<em>for some constant C.</em></p>\r\n\r\n<p><strong>Proof</strong></p>\r\n\r\n<p>Absolute boundedness ensures that the left-hand side is well-defined by&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#enun0001\" name=\"benun0001\">Theorem&nbsp;1</a>. Now we use the definition of&nbsp;∥&middot;∥L2&nbsp;and the internal stability of&nbsp;<em>ϕ</em>&nbsp;to obtain∥&Phi;X&minus;&Phi;Y∥L22=&int;&Delta;(2)|w(p,q)&middot;ϕXℓ(&lambda;p,&lambda;q)&minus;w(p,q)&middot;ϕYℓ(&lambda;p,&lambda;q)|2d&mu;&le;&int;&Delta;(2)(w(p,q)&middot;v3&middot;n&middot;dB(Xℓ,Yℓ))2d&mu;=(v3&middot;n)2&int;&Delta;(2)(w(p,q)&middot;dB(Xℓ,Yℓ))2d&mu;Since&nbsp;<em>w</em>(<em>p, q</em>) is zero outside&nbsp;<em>R</em> &times; <em>R</em>, the integral does not change when restricted to &Delta;<sup>(2)</sup>&thinsp;&cap;&thinsp;(<em>R</em> &times; <em>R</em>). Within this set,&nbsp;<em>w</em>(<em>p, q</em>) simplifies to&nbsp;ℓ^,&nbsp;with ℓ the line through&nbsp;<em>p</em>&nbsp;and&nbsp;<em>q</em>. Hence, we can further bound=(v3&middot;n)2&int;&Delta;(2)&cap;(R&times;R)(ℓ^&middot;dB(Xℓ,Yℓ))2d&mu;&le;(v3&middot;n)2&int;&Delta;(2)&cap;(R&times;R)supℓ&isin;L(ℓ^&middot;dB(Xℓ,Yℓ))︸=dmatch(X,Y)2d&mu;=(v3&middot;n&middot;dmatch(X,Y))2&int;&Delta;(2)&cap;(R&times;R)1d&mu;.The claimed inequality follows by noting that the final integral is equal to&nbsp;14area(R)2.&nbsp;□</p>\r\n\r\n<p>As a corollary, we get the the same stability statement with respect to interleaving distance instead of matching distance [<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0048\" name=\"bbib0048\">48</a>, Thm.1]. Furthermore, we obtain a stability bound for sublevel set bi-filtrations of functions&nbsp;X&rarr;R2&nbsp;[<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0047\" name=\"bbib0047\">47</a>, Thm.4]:</p>\r\n\r\n<p><strong>Corollary 3</strong></p>\r\n\r\n<p><em>Let</em>&nbsp;F,G:X&rarr;R2&nbsp;<em>be two functions that give rise to sublevel set bi-filtrations</em>&nbsp;X&nbsp;<em>and</em>&nbsp;Y,&nbsp;<em>respectively. If ϕ is absolutely bounded and internally stable, we have</em>∥&Phi;X&minus;&Phi;Y∥L2&le;C&middot;n&middot;area(R)&middot;∥F&minus;G∥&infin;,<em>for some constant C.</em></p>\r\n\r\n<p>We remark that the appearance of&nbsp;<em>n</em>&nbsp;in the stability bound is not desirable as the bound worsens when the complex size increases (unlike, for instance, the bottleneck stability bound in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#eq0004\" name=\"beq0004\">(4)</a>, which is independent of&nbsp;<em>n</em>). The factor of&nbsp;<em>n</em>&nbsp;comes from the internal stability property of&nbsp;<em>ϕ</em>, so we have to strengthen this condition on&nbsp;<em>ϕ</em>. However, we show that such an improvement is impossible for a large class of &ldquo;reasonable&rdquo; feature maps.</p>\r\n\r\n<p>For two bi-filtrations&nbsp;X,Y&nbsp;we define&nbsp;X&oplus;Y&nbsp;by setting&nbsp;(X&oplus;Y)(p):=X(p)⊔Y(p)&nbsp;for all&nbsp;p&isin;R2. A feature map &Phi; is&nbsp;<em>additive</em>&nbsp;if&nbsp;&Phi;X&oplus;Y=&Phi;(X)+&Phi;(Y)&nbsp;for all bi-filtrations&nbsp;X,Y. &Phi; is called&nbsp;<em>non-trivial</em>&nbsp;if there is a bi-filtration&nbsp;X&nbsp;such that&nbsp;∥&Phi;∥L2&ne;0. Additivity and non-triviality for feature maps&nbsp;<em>ϕ</em>&nbsp;on mono-filtrations is defined in the analogous way. Note that, for instance, the scale space feature map is additive. Moreover, because&nbsp;(X&oplus;Y)ℓ=Xℓ&oplus;Yℓ&nbsp;for every slice ℓ, a feature map &Phi; is additive if the underlying&nbsp;<em>ϕ</em>&nbsp;is additive.</p>\r\n\r\n<p>For mono-filtrations, no additive, non-trivial feature map&nbsp;<em>ϕ</em>&nbsp;can satisfy∥ϕX&minus;ϕY∥&le;C&middot;n&delta;&middot;dB(X,Y)with&nbsp;X,Y&nbsp;mono-filtrations and&nbsp;<em>&delta;</em> &isin; [0, 1); the proof of this statement is implicit in [<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#bib0021\" name=\"bbib0021\">21</a>, Thm&nbsp;3]. With similar ideas, we show that the same result holds in the multi-parameter case.</p>\r\n\r\n<p><strong>Theorem 4</strong></p>\r\n\r\n<p><em>If</em>&nbsp;&Phi;&nbsp;<em>is additive and there exists C</em> &gt; 0&nbsp;<em>and &delta;</em> &isin; [0, 1)&nbsp;<em>such that</em>∥&Phi;X&minus;&Phi;Y∥L2&le;C&middot;n&delta;&middot;dmatch(X,Y)<em>for all bi-filtrations</em>&nbsp;X&nbsp;<em>and</em>&nbsp;Y,&nbsp;<em>then</em>&nbsp;&Phi;&nbsp;<em>is trivial.</em></p>\r\n\r\n<p><strong>Proof</strong></p>\r\n\r\n<p>Assume to the contrary that there exists a bi-filtration&nbsp;X&nbsp;such that&nbsp;∥&Phi;X∥L2&gt;0. Then, writing&nbsp;O&nbsp;for the empty bi-filtration, by additivity we get&nbsp;∥&Phi;⊔i=1nX&minus;&Phi;O∥L2=n∥&Phi;X&minus;&Phi;O∥L2&gt;0. On the other hand,&nbsp;dmatch(⊔i=1nX,O)=dmatch(X,O). Hence, with&nbsp;<em>C</em>&nbsp;and&nbsp;<em>&delta;</em>&nbsp;as in the statement of the theorem,∥&Phi;⊔i=1nX&minus;&Phi;O∥L2C&middot;n&delta;&middot;dmatch(⊔i=1nX,O)=n∥&Phi;X&minus;&Phi;O∥L2C&middot;n&delta;&middot;dmatch(X,O)=n1&minus;&delta;∥&Phi;X&minus;&Phi;O∥L2C&middot;dmatch(X,O)⟶n&rarr;&infin;&infin;,a contradiction.&nbsp;□</p>\r\n\r\n<h2>5.&nbsp;Approximability</h2>\r\n\r\n<p>We provide an approximation algorithm to compute the kernel of two bi-filtrations&nbsp;X&nbsp;and&nbsp;Y&nbsp;up to any absolute error ϵ &gt; 0. Recall that our feature map &Phi; depends on the choice of a bounding box&nbsp;<em>R</em>. In this section, we assume&nbsp;<em>R</em>&nbsp;to be the unit square [0, 1] &times; [0, 1] for simplicity. We prove the following theorem that shows our kernel construction admits an efficient approximation scheme that is polynomial in 1/ϵ and the size of the bi-filtrations.</p>\r\n\r\n<p><strong>Theorem 5</strong></p>\r\n\r\n<p><em>Assume ϕ is absolutely bounded, Lipschitz, internally stable and efficiently computable. Given two bi-filtrations</em>&nbsp;X&nbsp;<em>and</em>&nbsp;Y&nbsp;<em>of size n and</em>&nbsp;ϵ &gt; 0,&nbsp;<em>we can compute a number r such that</em>&nbsp;r&le;〈X,Y〉&Phi;&le;r+ϵ&nbsp;<em>in polynomial time in n and</em>&nbsp;1/ϵ<em>.</em></p>\r\n\r\n<p>The proof of&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#enun0005\" name=\"benun0005\">Theorem&nbsp;5</a>&nbsp;will be illustrated in the following paragraphs, postponing most of the technical details to&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#sec0007\" name=\"bsec0007\">Appendix&nbsp;A</a>.</p>\r\n\r\n<h3>Algorithm</h3>\r\n\r\n<p>Given two bi-filtrations&nbsp;X&nbsp;and&nbsp;Y&nbsp;of size&nbsp;<em>n</em>&nbsp;and ϵ &gt; 0, our goal is to efficiently approximate&nbsp;〈X,Y〉&Phi;&nbsp;by some number&nbsp;<em>r</em>. On the highest level, we compute a sequence of approximation intervals (with decreasing lengths)&nbsp;J1,J2,J3,&hellip;,&nbsp;each containing the desired kernel value&nbsp;〈X,Y〉&Phi;. The computation terminates as soon as we find some&nbsp;<em>J<sub>i</sub></em>&nbsp;of width at most ϵ, in which case we return the left endpoint as an approximation to&nbsp;<em>r</em>.</p>\r\n\r\n<p>For&nbsp;s&isin;N&nbsp;(N&nbsp;being the set of natural numbers), we compute&nbsp;<em>J<sub>s</sub></em>&nbsp;as follows. We split&nbsp;<em>R</em>&nbsp;into 2<sup><em>s</em></sup> &times; 2<sup><em>s</em></sup>&nbsp;congruent squares (each of side length&nbsp;2&minus;s) which we refer to as&nbsp;<em>boxes</em>. See&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#fig0005\" name=\"bfig0005\">Fig.&nbsp;5</a>(a) for an example when&nbsp;s=3. We call a pair of such boxes a&nbsp;<em>box pair</em>. The integral from&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#eq0001\" name=\"beq0001\">(1)</a>&nbsp;can then be split into a sum of integrals over all 2<sup>4<em>s</em></sup>&nbsp;box pairs. That is,〈X,Y〉&Phi;=&int;&Delta;(2)&Phi;X&Phi;Yd&mu;=&sum;(B1,B2)&int;&Delta;(2)&cap;(B1&times;B2)&Phi;X&Phi;Yd&mu;.For each box pair, we compute an approximation interval for the integral, and sum them up using interval arithmetic to obtain&nbsp;<em>J<sub>s</sub></em>.</p>\r\n\r\n<p><img alt=\"Fig. 5\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S2590148619300056-gr5.jpg\" style=\"height:221px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S2590148619300056-gr5.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 5.&nbsp;(a) The two given slices realize the largest and smallest possible slope among all slices traversing the pink box pair. It can be easily seen that the difference of the unit vector of the center line to one of the unit vectors of these two lines realizes&nbsp;<em>A</em>&nbsp;for the given box pair. (b) Computing variations for the center slice and a traversing slice of a box pair.</p>\r\n\r\n<p>We first give some (almost trivial) bounds for&nbsp;〈X,Y〉&Phi;. Let (<em>B</em><sub>1</sub>,&nbsp;<em>B</em><sub>2</sub>) be a box pair with centers located at&nbsp;<em>c</em><sub>1</sub>&nbsp;and&nbsp;<em>c</em><sub>2</sub>, respectively. By construction,&nbsp;vol(B1&times;B2)=2&minus;4s. By the absolute boundedness of&nbsp;<em>ϕ</em>, we have(7)&int;&Delta;(2)&cap;(B1&times;B2)&Phi;X&Phi;Yd&mu;&le;&int;(B1&times;B2)(12v1n&middot;12v1n)d&mu;(8)=v12n22vol(B1&times;B2)=v12n224s+1,where&nbsp;1/2&nbsp;is the maximal weight. Let&nbsp;U:=v12n224s+1. If&nbsp;<em>c</em><sub>1</sub> &le; <em>c</em><sub>2</sub>, then we can choose [0,&nbsp;<em>U</em>] as approximation interval. Otherwise, if&nbsp;c1&not;&le;c2,&nbsp;then&nbsp;&Delta;(2)&cap;(B1&times;B2)=&empty;; we simply choose [0,0] as approximation interval.</p>\r\n\r\n<p>We can derive a second lower and upper bound for&nbsp;〈X,Y〉&Phi;&nbsp;as follows. We evaluate&nbsp;&Phi;X&nbsp;and&nbsp;&Phi;Y&nbsp;at the pair of centers (<em>c</em><sub>1</sub>,&nbsp;<em>c</em><sub>2</sub>), which is possible due to the efficiency hypothesis of&nbsp;<em>ϕ</em>. Let&nbsp;vX=&Phi;X(c1,c2)&nbsp;and&nbsp;vY=&Phi;Y(c1,c2). Then, we compute&nbsp;<em>variations</em>&delta;X,&delta;Y&ge;0&nbsp;relative to the box pair, with the property that, for any pair (<em>p, q</em>) &isin; <em>B</em><sub>1</sub> &times; <em>B</em><sub>2</sub>,&nbsp;&Phi;X(p,q)&isin;[vX&minus;&delta;X,vX+&delta;X],&nbsp;and&nbsp;&Phi;Y(p,q)&isin;[vY&minus;&delta;Y,vY+&delta;Y]. In other words, variations describe how far the value of&nbsp;&Phi;X&nbsp;(or&nbsp;&Phi;Y) deviates from its value at (<em>c</em><sub>1</sub>,&nbsp;<em>c</em><sub>2</sub>) within&nbsp;<em>B</em><sub>1</sub> &times; <em>B</em><sub>2</sub>. Combined with the derivations starting in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#eq0007\" name=\"beq0007\">(7)</a>, we have for any pair (<em>p, q</em>) &isin; <em>B</em><sub>1</sub> &times; <em>B</em><sub>2</sub>,(9)max{0,(vX&minus;&delta;X)(vY&minus;&delta;Y)}(10)&le;&Phi;X(p,q)&Phi;Y(p,q)</p>\r\n\r\n<p>(11)&le;min{v12n22,(vX+&delta;X)(vY+&delta;Y)}.</p>\r\n\r\n<p>By multiplying the bounds obtained in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2590148619300056#eq0009\" name=\"beq0009\">(9)</a>&nbsp;by the volume of &Delta;<sup>(2)</sup>&thinsp;&cap;&thinsp;(<em>B</em><sub>1</sub> &times; <em>B</em><sub>2</sub>), we get a lower and an upper bound for the integral of&nbsp;&Phi;X&Phi;Y&nbsp;over a box pair (<em>B</em><sub>1</sub>,&nbsp;<em>B</em><sub>2</sub>). By summing over all possible box pairs, the obtained lower and upper bounds are the endpoints of&nbsp;<em>J<sub>s</sub></em>.</p>', '2020-05-17 15:24:08.103819', 'Published', '2020-05-17 17:56:16.000000', 1, 4);
INSERT INTO `app_article` VALUES (4, 1, 3, 'Explanation in artificial intelligence: Insights', '2020-05-20 11:58:52.751702', 'Explanation in artificial intelligence: Insights', 'There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to provide more transparency to their algorithms. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers\' intuition of what constitutes a ‘good’ explanation. There exist vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations to the explanation process. This paper argues that the field of explainable artificial intelligence can build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.', '<h2>1.&nbsp;Introduction</h2>\r\n\r\n<p>Recently, the notion of&nbsp;<em>explainable artificial intelligence</em>&nbsp;has seen a&nbsp;<a href=\"https://www.sciencedirect.com/topics/engineering/resurgence\" title=\"Learn more about Resurgence from ScienceDirect\'s AI-generated Topic Pages\">resurgence</a>, after having slowed since the burst of work on explanation in expert systems over three decades ago; for example, see Chandrasekaran et al.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0230\" name=\"bbr0230\">[23]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1670\" name=\"bbr1670\">[168]</a>, and Buchanan and Shortliffe&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0140\" name=\"bbr0140\">[14]</a>. Sometimes abbreviated XAI (eXplainable artificial intelligence), the idea can be found in grant solicitations&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0320\" name=\"bbr0320\">[32]</a>&nbsp;and in the popular press&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1360\" name=\"bbr1360\">[136]</a>. This resurgence is driven by evidence that many AI applications have limited take up, or are not appropriated at all, due to ethical concerns&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0020\" name=\"bbr0020\">[2]</a>&nbsp;and a&nbsp;<em>lack of trust</em>&nbsp;on behalf of their users&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1650\" name=\"bbr1650\">[166]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1010\" name=\"bbr1010\">[101]</a>. The running hypothesis is that by building more transparent, interpretable, or explainable systems, users will be better equipped to understand and therefore trust the intelligent agents&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1290\" name=\"bbr1290\">[129]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0250\" name=\"bbr0250\">[25]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0650\" name=\"bbr0650\">[65]</a>.</p>\r\n\r\n<p>While there are many ways to increase trust and transparency of intelligent agents, two complementary approaches will form part of many trusted&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/autonomous-system\" title=\"Learn more about autonomous system from ScienceDirect\'s AI-generated Topic Pages\">autonomous systems</a>: (1) generating decisions<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#fn0010\" name=\"bfn0010\"><sup>1</sup></a>&nbsp;in which one of the criteria taken into account during the computation is how well a human could understand the decisions in the given context, which is often called&nbsp;<em><a href=\"https://www.sciencedirect.com/topics/computer-science/interpretability\" title=\"Learn more about Interpretability from ScienceDirect\'s AI-generated Topic Pages\">interpretability</a></em>&nbsp;or&nbsp;<em>explainability</em>; and (2) explicitly explaining decisions to people, which we will call&nbsp;<em>explanation</em>. Applications of explanation are considered in many sub-fields of artificial intelligence, such as justifying&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/autonomous-agent\" title=\"Learn more about Autonomous Agent from ScienceDirect\'s AI-generated Topic Pages\">autonomous agent</a>&nbsp;behaviour&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1290\" name=\"bbr1290\">[129]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0650\" name=\"bbr0650\">[65]</a>, debugging of machine learning models&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0890\" name=\"bbr0890\">[89]</a>, explaining medical decision-making&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0450\" name=\"bbr0450\">[45]</a>, and explaining predictions of classifiers&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1560\" name=\"bbr1560\">[157]</a>.</p>\r\n\r\n<p>If we want to design, and implement intelligent agents that are truly capable of providing explanations to&nbsp;<em>people</em>, then it is fair to say that models of how humans explain decisions and behaviour to each other are a good way to start analysing the problem. Researchers argue that people employ certain&nbsp;<em>biases</em>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0820\" name=\"bbr0820\">[82]</a>&nbsp;and&nbsp;<em>social expectations</em>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0720\" name=\"bbr0720\">[72]</a>&nbsp;when they generate and evaluate explanation, and I argue that such biases and expectations can improve human interactions with explanatory AI. For example, de Graaf and Malle&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0340\" name=\"bbr0340\">[34]</a>&nbsp;argues that because people assign human-like traits to artificial agents, people will expect explanations using the same conceptual framework used to explain human behaviours.</p>\r\n\r\n<p>Despite the recent resurgence of explanation and interpretability in AI, most of the research and practice in this area seems to use the researchers&#39; intuitions of what constitutes a &lsquo;good&rsquo; explanation. Miller et al.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1320\" name=\"bbr1320\">[132]</a>&nbsp;shows in a small sample that research in explainable AI typically does not cite or build on frameworks of explanation from social science. They argue that this could lead to failure. The very experts who understand decision-making models the best are not in the right position to judge the usefulness of explanations to lay users &mdash; a phenomenon that Miller et al. refer to (paraphrasing Cooper&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1320\" name=\"bbr1320\">[132]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0310\" name=\"bbr0310\">[31]</a>) as &ldquo;the inmates running the asylum&rdquo;. Therefore, a strong understanding of how people define, generate, select, evaluate, and present explanations seems almost essential.</p>\r\n\r\n<p>In the fields of philosophy, cognitive psychology/science, and social psychology, there is a vast and mature body of work that studies these exact topics. For millennia, philosophers have asked the questions about what constitutes an explanation, what is the function of explanations, and what are their structure. For over 50 years, cognitive and social psychologists have analysed how people attribute and evaluate the social behaviour of others in physical environments. For over two decades, cognitive psychologists and scientists have investigated how people generate explanations and how they evaluate their quality.</p>\r\n\r\n<p>I argue here that there is considerable scope to infuse this valuable body of research into explainable AI.&nbsp;<a href=\"https://www.sciencedirect.com/topics/engineering/intelligent-buildings\" title=\"Learn more about Intelligent Buildings from ScienceDirect\'s AI-generated Topic Pages\">Building intelligent</a>&nbsp;agents capable of explanation is a challenging task, and approaching this challenge in a vacuum considering only the computational problems will not solve the greater problems of trust in AI. Further, while some recent work builds on the early findings on explanation in expert systems, that early research was undertaken prior to much of the work on explanation in social science. I contend that newer theories can form the basis of explainable AI &mdash; although there is still a lot to learn from early work in explainable AI around design and implementation.</p>\r\n\r\n<p>This paper aims to promote the inclusion of this existing research into the field of explanation in AI. As part of this work, over 250 publications on explanation were surveyed from social science venues. A smaller subset of these were chosen to be presented in this paper, based on their currency and relevance to the topic. The paper presents relevant theories on explanation, describes, in many cases, the experimental evidence supporting these theories, and presents ideas on how this work can be infused into explainable AI.</p>\r\n\r\n<h3>1.1.&nbsp;Scope</h3>\r\n\r\n<p>In this article, the term &lsquo;<em>Explainable AI</em>&rsquo; loosely refers to an explanatory agent revealing underlying causes to its or another agent&#39;s decision making. However, it is important to note that the solution to explainable AI is not just &lsquo;more AI&rsquo;. Ultimately, it is a human&ndash;agent interaction problem. Human-agent interaction can be defined as the intersection of artificial intelligence, social science, and&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/human-computer-interaction\" title=\"Learn more about Human Computer Interaction from ScienceDirect\'s AI-generated Topic Pages\">human&ndash;computer interaction</a>&nbsp;(HCI); see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#fg0010\" name=\"bfg0010\">Fig. 1</a>. Explainable AI is just one problem inside human&ndash;agent interaction.</p>\r\n\r\n<p><img alt=\"Fig. 1\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0004370218305988-gr001.jpg\" style=\"height:304px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S0004370218305988-gr001_lrg.jpg\" target=\"_blank\" title=\"Download high-res image (103KB)\">Download :&nbsp;Download high-res image (103KB)</a></li>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S0004370218305988-gr001.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 1.&nbsp;Scope of explainable artificial intelligence.</p>\r\n\r\n<p>This article highlights the top circle in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#fg0010\" name=\"bfg0010\">Fig. 1</a>: the philosophy, social and cognitive psychology, and cognitive science views of explanation, and their relation to the other two circles: their impact on the design of both artificial intelligence and our interactions with them. With this scope of explainable AI in mind, the scope of this article is threefold:</p>\r\n\r\n<p>&bull;</p>\r\n\r\n<p><em>Survey</em>: To survey and review relevant articles on the philosophical, cognitive, and social foundations of explanation, with an emphasis on &lsquo;everyday&rsquo; explanation.</p>\r\n\r\n<p>&bull;</p>\r\n\r\n<p><em>Everyday explanation</em>: To focus on &lsquo;everyday&rsquo; (or local) explanations as a tool and process for an agent, who we call the&nbsp;<em>explainer</em>, to explain decisions made by&nbsp;<em>itself or another agent</em>&nbsp;to a&nbsp;<em>person</em>, who we call the&nbsp;<em>explainee</em>. &lsquo;Everyday&rsquo; explanations are the explanations of why particular facts (events, properties, decisions, etc.) occurred, rather than explanations of more general relationships, such as those seen in scientific explanation. We justify this focus based on the observation from AI literature that trust is lost when users cannot understand traces of observed behaviour or decisions&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1650\" name=\"bbr1650\">[166]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1290\" name=\"bbr1290\">[129]</a>, rather than trying to understand and construct generalised theories. Despite this, everyday explanations also sometimes refer to generalised theories, as we will see later in Section&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0060\" name=\"bse0060\">2</a>, so scientific explanation is relevant, and some work from this area is surveyed in the paper.</p>\r\n\r\n<p>&bull;</p>\r\n\r\n<p><em>Relationship to explainable AI</em>: To draw important points from relevant articles to some of the different sub-fields of explainable AI.</p>\r\n\r\n<p>The following topics are considered&nbsp;<em>out of scope</em>&nbsp;of this article:</p>\r\n\r\n<p>&bull;</p>\r\n\r\n<p><em><a href=\"https://www.sciencedirect.com/topics/engineering/causality\" title=\"Learn more about Causality from ScienceDirect\'s AI-generated Topic Pages\">Causality</a></em>: While causality is important in explanation, this paper is not a survey on the vast work on causality. I review the major positions in this field insofar as they relate to the relationship with models of explanation.</p>\r\n\r\n<p>&bull;</p>\r\n\r\n<p><em>Explainable AI</em>: This paper is not a survey on existing approaches to explanation or interpretability in AI, except those that directly contribute to the topics in scope or build on social science. For an excellent short survey on explanation in machine learning, see Biran and Cotton&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0090\" name=\"bbr0090\">[9]</a>.</p>\r\n\r\n<h3>1.2.&nbsp;Major findings</h3>\r\n\r\n<p>As part of this review, I highlight four major findings from the surveyed literature that I believe are important for explainable AI, but which I believe most research and practitioners in artificial intelligence are currently unaware:</p>\r\n\r\n<p>1.</p>\r\n\r\n<p>Explanations are&nbsp;<em>contrastive</em>&nbsp;&mdash; they are sought in response to particular&nbsp;<em>counterfactual cases</em>, which are termed&nbsp;<em>foils</em>&nbsp;in this paper. That is, people do not ask why event&nbsp;<em>P</em>&nbsp;happened, but rather why event&nbsp;<em>P</em>&nbsp;happened&nbsp;<em>instead of</em>&nbsp;some event&nbsp;<em>Q</em>. This has important social and computational consequences for explainable AI. In Sections&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0060\" name=\"bse0060\">2</a>&ndash;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0400\" name=\"bse0400\">4</a>, models of how people provide contrastive explanations are reviewed.</p>\r\n\r\n<p>2.</p>\r\n\r\n<p>Explanation are&nbsp;<em>selected</em>&nbsp;(in a biased manner) &mdash; people rarely, if ever, expect an explanation that consists of an actual and complete cause of an event. Humans are adept at selecting one or two causes from a sometimes infinite number of causes to be&nbsp;<em>the</em>&nbsp;explanation. However, this selection is influenced by certain cognitive biases. In Section&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0400\" name=\"bse0400\">4</a>, models of how people select explanations, including how this relates to contrast cases, are reviewed.</p>\r\n\r\n<p>3.</p>\r\n\r\n<p>Probabilities probably don&#39;t matter &mdash; while truth and likelihood are important in explanation and probabilities really do matter,&nbsp;<em>referring</em>&nbsp;to probabilities or statistical relationships in explanation is not as effective as referring to causes. The most likely explanation is not always the&nbsp;<em>best</em>&nbsp;explanation for a person, and importantly, using statistical generalisations to explain why events occur is unsatisfying, unless accompanied by an underlying&nbsp;<em>causal</em>&nbsp;explanation for the generalisation itself.</p>\r\n\r\n<p>4.</p>\r\n\r\n<p>Explanations are&nbsp;<em>social</em>&nbsp;&mdash; they are a transfer of knowledge, presented as part of a conversation<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#fn0020\" name=\"bfn0020\"><sup>2</sup></a>&nbsp;or interaction, and are thus presented relative to the explainer&#39;s beliefs about the explainee&#39;s beliefs. In Section&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0700\" name=\"bse0700\">5</a>, models of how people interact regarding explanations are reviewed.</p>\r\n\r\n<p>These four points all converge around a single point: explanations are not just the presentation of associations and causes (<em><a href=\"https://www.sciencedirect.com/topics/computer-science/causal-attribution\" title=\"Learn more about Causal Attribution from ScienceDirect\'s AI-generated Topic Pages\">causal attribution</a></em>), they are&nbsp;<em>contextual</em>. While an event may have many causes, often the explainee cares only about a small subset (relevant to the context), the explainer selects a subset of this subset (based on several different criteria), and explainer and explainee may interact and argue about this explanation.</p>\r\n\r\n<p>I assert that, if we are to build truly explainable AI, especially intelligent systems that are able to offer explanations, then these three points are imperative in many applications.</p>\r\n\r\n<h3>1.3.&nbsp;Outline</h3>\r\n\r\n<p>The outline of this paper is as follows. Section&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0050\" name=\"bse0050\">1.4</a>&nbsp;presents a motivating example of an explanatory agent that is used throughout the paper. Section&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0060\" name=\"bse0060\">2</a>&nbsp;presents the philosophical foundations of explanation, defining what explanations are, what they are not, how to relate to causes, their meaning and their structure. Section&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0280\" name=\"bse0280\">3</a>&nbsp;focuses on one specific type of explanation &mdash; those relating to human or social behaviour, while Section&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0400\" name=\"bse0400\">4</a>&nbsp;surveys work on how people generate and evaluate explanations more generally; that is, not just social behaviour. Section&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0700\" name=\"bse0700\">5</a>&nbsp;describes research on the dynamics of interaction in explanation between explainer and explainee. Section&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0860\" name=\"bse0860\">6</a>&nbsp;concludes and highlights several major challenges to explanation in AI.</p>\r\n\r\n<h3>1.4.&nbsp;Example</h3>\r\n\r\n<p>This section presents a simple example, which is used to illustrate many important concepts through this paper. It is of a hypothetical system that categorises images of arthropods into several different types, based on certain physical features of the arthropods, such as number of legs, number of eyes, number of wings, etc. The algorithm is assumed to have been trained on a large set of valid data and is highly accurate. It is used by entomologists to do&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/automatic-classification\" title=\"Learn more about Automatic Classification from ScienceDirect\'s AI-generated Topic Pages\">automatic classification</a>&nbsp;of their research data.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#tbl0010\" name=\"btbl0010\">Table 1</a>&nbsp;outlines a simple model of the features of arthropods for illustrative purposes. An explanation function is available for the arthropod system.</p>\r\n\r\n<p>Table 1.&nbsp;A simple lay model for distinguishing common arthropods.</p>\r\n\r\n<table>\r\n	<thead>\r\n		<tr>\r\n			<th scope=\"row\"><strong>Type</strong></th>\r\n			<th scope=\"col\"><strong>No. legs</strong></th>\r\n			<th scope=\"col\"><strong>Stinger</strong></th>\r\n			<th scope=\"col\"><strong>No. eyes</strong></th>\r\n			<th scope=\"col\"><strong>Compound eyes</strong></th>\r\n			<th scope=\"col\"><strong>Wings</strong></th>\r\n		</tr>\r\n	</thead>\r\n	<tbody>\r\n		<tr>\r\n			<th scope=\"row\">Spider</th>\r\n			<td>8</td>\r\n			<td>✘</td>\r\n			<td>8</td>\r\n			<td>✘</td>\r\n			<td>0</td>\r\n		</tr>\r\n		<tr>\r\n			<th scope=\"row\">Beetle</th>\r\n			<td>6</td>\r\n			<td>✘</td>\r\n			<td>2</td>\r\n			<td>✔</td>\r\n			<td>2</td>\r\n		</tr>\r\n		<tr>\r\n			<th scope=\"row\">Bee</th>\r\n			<td>6</td>\r\n			<td>✔</td>\r\n			<td>5</td>\r\n			<td>✔</td>\r\n			<td>4</td>\r\n		</tr>\r\n		<tr>\r\n			<th scope=\"row\">Fly</th>\r\n			<td>6</td>\r\n			<td>✘</td>\r\n			<td>5</td>\r\n			<td>✔</td>\r\n			<td>2</td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p>Now, consider the idealised and simple dialogue between a human user and &lsquo;ExplAgent&rsquo;, who is the interactive explanation agent, outlined in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#fg0020\" name=\"bfg0020\">Fig. 2</a>. This dialogue is not intended to be realistic, but is merely illustrative of how a particular explanatory agent may interact: responding to posed questions, using mixed modalities &mdash; in this case, language and visual images &mdash; and being able to answer a range of questions about its decision making. This example shows different types of questions being posed, and demonstrates that the explanatory agent will need to keep track of the state of the explanation; for example, by noting what it has already told the explainee, and may have to infer what the explainee has inferred themselves.</p>\r\n\r\n<p><img alt=\"Fig. 2\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0004370218305988-gr002.gif\" style=\"height:113px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S0004370218305988-gr002_lrg.gif\" target=\"_blank\" title=\"Download high-res image (114KB)\">Download :&nbsp;Download high-res image (114KB)</a></li>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S0004370218305988-gr002.gif\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 2.&nbsp;Example Explanation Dialogue between a Person and an Explanation Agent.</p>\r\n\r\n<p>We will refer back to this example throughout the paper and link difference parts of work the different parts of the dialogue above.</p>\r\n\r\n<h2>2.&nbsp;Philosophical foundations &mdash; what is explanation?</h2>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<blockquote>\r\n<p>&ldquo;<em>To explain an event is to provide some information about its causal history. In an act of explaining, someone who is in possession of some information about the causal history of some event &mdash;</em>&nbsp;explanatory information<em>, I shall call it &mdash; tries to convey it to someone else.</em>&rdquo; &mdash; Lewis&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0990\" name=\"bbr0990\">[99, p. 217]</a>.</p>\r\n</blockquote>\r\n\r\n<p>In this section, we outline foundational work in explanation, which helps to define&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/causal-explanation\" title=\"Learn more about Causal Explanation from ScienceDirect\'s AI-generated Topic Pages\">causal explanation</a>&nbsp;and how it differs from other concepts such as&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/causal-attribution\" title=\"Learn more about Causal Attribution from ScienceDirect\'s AI-generated Topic Pages\">causal attribution</a>&nbsp;and&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/interpretability\" title=\"Learn more about Interpretability from ScienceDirect\'s AI-generated Topic Pages\">interpretability</a>.</p>\r\n\r\n<h3>2.1.&nbsp;Definitions</h3>\r\n\r\n<p>There are several related concepts in explanation, which seem to be used interchangeably between authors and also within articles, often demonstrating some conflation of the terms. In particular, this section describes the difference between causal attribution and causal explanation. We will also briefly touch on the difference between explanation and interpretability.</p>\r\n\r\n<h4>2.1.1.&nbsp;Causality</h4>\r\n\r\n<p>The idea of&nbsp;<a href=\"https://www.sciencedirect.com/topics/engineering/causality\" title=\"Learn more about Causality from ScienceDirect\'s AI-generated Topic Pages\">causality</a>&nbsp;has attracted much work, and there are several different accounts of what constitutes a&nbsp;<em>cause</em>&nbsp;of an event or property. The various definitions of causation can be broken into two major categories:&nbsp;<em>dependence theories</em>&nbsp;and&nbsp;<em>transference theories</em>.</p>\r\n\r\n<h5>Causality and counterfactuals.</h5>\r\n\r\n<p>Hume&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0790\" name=\"bbr0790\">[79, Section VII]</a>&nbsp;is credited with deriving what is known as the&nbsp;<em>regularity theory</em>&nbsp;of causation. This theory states that there is a cause between two types of events if events of the first type are always followed by events of the second. However, as argued by Lewis&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0980\" name=\"bbr0980\">[98]</a>, the definition due to Hume is in fact about&nbsp;<em>counterfactuals</em>, rather than dependence alone. Hume argues that the co-occurrence of events&nbsp;<em>C</em>&nbsp;and&nbsp;<em>E</em>, observed from experience, do not give causal information that is useful. Instead, the cause should be understood relative to an imagined, counterfactual case: event&nbsp;<em>C</em>&nbsp;is said to have caused event&nbsp;<em>E</em>&nbsp;if, under some hypothetical counterfactual case the event&nbsp;<em>C</em>&nbsp;did not occur,&nbsp;<em>E</em>&nbsp;would not have occurred. This definition has been argued and refined, and many definitions of causality are based around this idea in one way or another; cf. Lewis&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0790\" name=\"bbr0790\">[79]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0790\" name=\"bbr0790\">[79]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0980\" name=\"bbr0980\">[98]</a>, Hilton&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0710\" name=\"bbr0710\">[71]</a>.</p>\r\n\r\n<p>This&nbsp;<em>classical counterfactual</em>&nbsp;model of causality is well understood but competing definitions exist.&nbsp;<em>Interventionist</em>&nbsp;theories of causality&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1900\" name=\"bbr1900\">[191]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0580\" name=\"bbr0580\">[58]</a>&nbsp;state that event&nbsp;<em>C</em>&nbsp;can be deemed a cause of event&nbsp;<em>E</em>&nbsp;if and only if any change to event&nbsp;<em>E</em>&nbsp;can be brought about solely by intervening on event&nbsp;<em>C</em>.&nbsp;<em>Probabilistic</em>&nbsp;theories, which are extensions of interventionist theories, state that event&nbsp;<em>C</em>&nbsp;is a cause of event&nbsp;<em>E</em>&nbsp;if and only if the occurrence of&nbsp;<em>C</em>&nbsp;increases the probability of&nbsp;<em>E</em>&nbsp;occurring&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br1280\" name=\"bbr1280\">[128]</a>.</p>\r\n\r\n<p><em>Transference</em>&nbsp;theories&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0050\" name=\"bbr0050\">[5]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0430\" name=\"bbr0430\">[43]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0390\" name=\"bbr0390\">[39]</a>, on the other hand, are not defined on dependence, but instead describe&nbsp;<em>physical</em>&nbsp;causation as the transference of energy between objects. In short, if&nbsp;<em>E</em>&nbsp;is an event representing the change of energy of an object&nbsp;<em>O</em>, then&nbsp;<em>C</em>&nbsp;causes&nbsp;<em>E</em>&nbsp;if object&nbsp;<em>O</em>&nbsp;is in contact with the object that causes&nbsp;<em>C</em>, and there is some&nbsp;<em>quantity</em>&nbsp;of energy transferred.</p>\r\n\r\n<p>While the aim here is not a detailed survey of causality, however, it is pertinent to note that the dependence theories all focus around the concept of&nbsp;<em>counterfactuals</em>: the state of affairs that&nbsp;<em>would have resulted</em>&nbsp;from some event that&nbsp;<em>did not occur</em>. Even transference theories, which are not explicitly defined as counterfactual, consider that causation is an&nbsp;<em>unnatural</em>&nbsp;transference of energy to the receiving object, implying what would have been otherwise. As such, the notion of &lsquo;counterfactual&rsquo; is important in causality.</p>\r\n\r\n<p>Gerstenberg et al.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0490\" name=\"bbr0490\">[49]</a>&nbsp;tested whether people consider counterfactuals when making causal judgements in an experiment involving colliding balls. They presented experiment participants with different scenarios involving two balls colliding, with each scenario having different outcomes, such as one ball going through a gate, just missing the gate, or missing the gate by a long distance. While wearing&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/eye-tracking-equipment\" title=\"Learn more about Eye Tracking Equipment from ScienceDirect\'s AI-generated Topic Pages\">eye-tracking equipment</a>, participants were asked to determine what the outcome would have been (a counterfactual) had the candidate cause not occurred (the balls had not collided). Using the eye-gaze data from the tracking, they showed that their participants, even in these physical environments, would trace where the ball would have gone had the balls not collided, thus demonstrating that they used counterfactual simulation to make causal judgements.</p>\r\n\r\n<h5>Necessary and sufficient causes.</h5>\r\n\r\n<p>Kelley&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0870\" name=\"bbr0870\">[87]</a>&nbsp;proposes a taxonomy of causality in social attribution, but which has more general applicability, and noted that there are two main types of&nbsp;<em>causal schemata</em>&nbsp;for causing events:&nbsp;<em>multiple necessary causes</em>&nbsp;and&nbsp;<em>multiple sufficient causes</em>. The former defines a schema in which a set of events are all necessary to cause the event in question, while the latter defines a schema in which there are multiple possible ways to cause the event, and only one of these is required. Clearly, these can be interleaved; e.g. causes&nbsp;C1,&nbsp;C2, and&nbsp;C3&nbsp;for event&nbsp;<em>E</em>, in which&nbsp;C1&nbsp;is necessary and either of&nbsp;C2&nbsp;or&nbsp;C3&nbsp;are necessary, while both&nbsp;C2&nbsp;and&nbsp;C3&nbsp;are sufficient to cause the compound event&nbsp;(C2orC3).</p>\r\n\r\n<h5>Internal and external causes.</h5>\r\n\r\n<p>Heider&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0660\" name=\"bbr0660\">[66]</a>, the grandfather of causal attribution in social psychology, argues that causes fall into two camps: internal and external. Internal causes of events are those due to the characteristics of an actor, while external causes are those due to the specific situation or the environment. Clearly, events can have causes that mix both. However, the focus of work from Heider was not on causality in general, but on&nbsp;<em>social attribution</em>, or the&nbsp;<em>perceived</em>&nbsp;causes of behaviour. That is, how people attribute the behaviour of others. Nonetheless, work in this field, as we will see in Section&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0280\" name=\"bse0280\">3</a>, builds heavily on counterfactual causality.</p>\r\n\r\n<h5>Causal chains.</h5>\r\n\r\n<p>In causality and explanation, the concept of&nbsp;<em>causal chains</em>&nbsp;is important. A causal chain is a path of causes between a set of events, in which a cause from event&nbsp;<em>C</em>&nbsp;to event&nbsp;<em>E</em>&nbsp;indicates that&nbsp;<em>C</em>&nbsp;must occur before&nbsp;<em>E</em>. Any events without a cause are&nbsp;<em>root causes</em>.</p>\r\n\r\n<p>Hilton et al.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0660\" name=\"bbr0660\">[66]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0760\" name=\"bbr0760\">[76]</a>&nbsp;define five different types of causal chain, outlined in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#tbl0020\" name=\"btbl0020\">Table 2</a>, and note that different causal chains are associated with different types of explanations.</p>\r\n\r\n<p>Table 2.&nbsp;Types of causal chains according to Hilton et al.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0660\" name=\"bbr0660\">[66]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0760\" name=\"bbr0760\">[76]</a>.</p>\r\n\r\n<table>\r\n	<thead>\r\n		<tr>\r\n			<th scope=\"row\"><strong>Type</strong></th>\r\n			<th scope=\"col\"><strong>Description</strong></th>\r\n			<th scope=\"col\"><strong>Example</strong></th>\r\n		</tr>\r\n	</thead>\r\n	<tbody>\r\n		<tr>\r\n			<th scope=\"row\">Temporal</th>\r\n			<td>Distal events do not constraint proximal events. Events can be switched in time without changing the outcome</td>\r\n			<td><em>A</em>&nbsp;and&nbsp;<em>B</em>&nbsp;together cause&nbsp;<em>C</em>; order of&nbsp;<em>A</em>&nbsp;and&nbsp;<em>B</em>&nbsp;is irrelevant; e.g. two people each flipping a coin win if both coins are heads; it is irrelevant who flips first.</td>\r\n		</tr>\r\n		<tr>\r\n			<th scope=\"row\">Coincidental</th>\r\n			<td>Distal events do not constraint proximal events. The causal relationships holds in a particular case, but not in general.</td>\r\n			<td><em>A</em>&nbsp;causes&nbsp;<em>B</em>&nbsp;this time, but the general relationship does not hold; e.g. a person smoking a cigarette causes a house fire, but this does not generally happen.</td>\r\n		</tr>\r\n		<tr>\r\n			<th scope=\"row\">Unfolding</th>\r\n			<td>Distal events strongly constrain proximal events. The causal relationships hold in general and in this particular case and cannot be switched.</td>\r\n			<td><em>A</em>&nbsp;causes&nbsp;<em>B</em>&nbsp;and&nbsp;<em>B</em>&nbsp;causes&nbsp;<em>C</em>; e.g. switching a light switch causes an electric current to run to the light, which causes the light to turn on.</td>\r\n		</tr>\r\n		<tr>\r\n			<th scope=\"row\">Opportunity chains</th>\r\n			<td>The distal event&nbsp;<em>enables</em>&nbsp;the proximal event.</td>\r\n			<td><em>A</em>&nbsp;enables&nbsp;<em>B</em>,&nbsp;<em>B</em>&nbsp;causes&nbsp;<em>C</em>; e.g. installing a light switch enables it to be switched, which causes the light to turn on.</td>\r\n		</tr>\r\n		<tr>\r\n			<th scope=\"row\">Pre-emptive</th>\r\n			<td>Distal precedes proximal and prevents the proximal from causing an event.</td>\r\n			<td><em>B</em>&nbsp;causes&nbsp;<em>C</em>,&nbsp;<em>A</em>&nbsp;would have caused&nbsp;<em>C</em>&nbsp;if&nbsp;<em>B</em>&nbsp;did not occur; e.g. my action of unlocking the car with my remote lock would have unlocked the door if my wife had not already unlocked it with the key.</td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p>People do not need to understand a complete causal chain to provide a sound explanation. This is evidently true: causes of physical events can refer back to events that occurred during the Big Bang, but nonetheless, most adults can explain to a child why a bouncing ball eventually stops.</p>\r\n\r\n<h5>Formal models of causation.</h5>\r\n\r\n<p>While several formal models of causation have been proposed, such as those based on&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/conditional-logic\" title=\"Learn more about Conditional Logic from ScienceDirect\'s AI-generated Topic Pages\">conditional logic</a>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0530\" name=\"bbr0530\">[53]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0980\" name=\"bbr0980\">[98]</a>, the model of causation that I believe would be of interest to many in artificial intelligence is the formalisation of causality by Halpern and Pearl&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0580\" name=\"bbr0580\">[58]</a>. This is a general model that should be accessible to anyone with a computer science background, has been adopted by philosophers and psychologists, and is accompanied by many additional results, such as an axiomatisation&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0570\" name=\"bbr0570\">[57]</a>&nbsp;and a series articles on complexity analysis&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0400\" name=\"bbr0400\">[40]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0410\" name=\"bbr0410\">[41]</a>.</p>\r\n\r\n<p>Halpern and Pearl&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#br0580\" name=\"bbr0580\">[58]</a>&nbsp;define a model-based approach using&nbsp;<em>structural causal models</em>&nbsp;over two sets of variables:&nbsp;<em>exogenous</em>&nbsp;variables, whose values are determined by factors external to the model, and&nbsp;<em>endogenous</em>&nbsp;variables, whose values are determined by relationships with other (exogenous or endogenous) variables. Each endogenous variable has a function that defines its value from other variables. A&nbsp;<em>context</em>&nbsp;is an assignment of values to variables. Intuitively, a context represents a &lsquo;possible world&rsquo; of the model. A model/context pair is called a&nbsp;<em>situation</em>. Given this structure, Halpern and Pearl define a&nbsp;<em>actual cause</em>&nbsp;of an event&nbsp;X=x&nbsp;(that is, endogenous variable&nbsp;<em>X</em>&nbsp;receiving the value&nbsp;<em>x</em>) as a set of events&nbsp;<em>E</em>&nbsp;(each of the form&nbsp;Y=y) such that (informally) the following three criteria hold:</p>\r\n\r\n<p><strong>AC1</strong></p>\r\n\r\n<p>Both the event&nbsp;X=x&nbsp;and the cause&nbsp;<em>E</em>&nbsp;are true in the actual situation.</p>\r\n\r\n<p><strong>AC2</strong></p>\r\n\r\n<p>If there was some&nbsp;<em>counterfactual</em>&nbsp;values for the variables of the events in&nbsp;<em>E</em>, then the event&nbsp;X=x&nbsp;would not have occurred.</p>\r\n\r\n<p><strong>AC3</strong></p>\r\n\r\n<p><em>E</em>&nbsp;is minimal &mdash; that is, there are no irrelevant events in the case.</p>\r\n\r\n<p>A&nbsp;<em>sufficient cause</em>&nbsp;is simply a non-minimal actual cause; that is, it satisfies the first two items above.</p>\r\n\r\n<p>We will return later to this model in Section&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0004370218305988#se0730\" name=\"bse0730\">5.1.2</a>&nbsp;to discuss Halpern and Pearl&#39;s model of explanation.</p>', '2020-05-17 16:55:45.438477', 'Published', '2020-05-18 07:02:46.000000', 3, 5);
INSERT INTO `app_article` VALUES (5, 1, 1, '', '2020-05-17 18:00:23.918980', 'Campus traffic and e-Learning during COVID-19 pandemic', 'The COVID-19 pandemic led to the adoption of severe measures to counteract the spread of the infection. Social distancing and lockdown measures modified people’s habits, while the Internet gained a major role in supporting remote working, e-teaching, online collaboration, gaming, video streaming, etc. All these sudden changes put unprecedented stress on the network.\r\n\r\nIn this paper, we analyze the impact of the lockdown enforcement on the Politecnico di Torino campus network. Right after the school shutdown on the 25th of February, PoliTO deployed its own in-house solution for virtual teaching. Ever since, the university provides about 600 virtual classes daily, serving more than 16 000 students per day. Here, we report a picture of how the pandemic changed PoliTO’s network traffic. We first focus on the usage of remote working and collaboration platforms. Given the peculiarity of PoliTO online teaching solution that is hosted in-house, we drill down on the traffic, characterizing both the audience and the network footprint. Overall, we present a snapshot of the abrupt changes seen on campus traffic due to COVID-19, and testify how the Internet has proved robust to successfully cope with challenges while maintaining the university operations.', '<h2>1.&nbsp;Introduction</h2>\r\n\r\n<p>Since its first outbreak between late 2019 and early 2020 in China, the COVID-19 pandemic has had a massive impact on people&rsquo;s lives and habits. The countries most affected by the virus spreading are facing an unprecedented health crisis, whose effects will impact their economic and social structures for a long time. The urge to respect social distancing and lockdown measures adopted to limit the spreading of the infection led to a shift in the fruition and supply of a wide number of services. Some examples include the increased usage of home delivery services, the shift to online lessons and the adoption of remote working solutions.</p>\r\n\r\n<p>Italy has been among the first countries hit by COVID-19. The first case was identified in the north of Italy on February 21<sup><em>st</em></sup>, and on the same date, the Government issued the fist law decree to impose quarantine in small selected towns. On February 25<sup><em>th</em></sup>, the Government extended the restrictions to impose remote working for all public offices, shutting down schools, and classes at Universities. Restrictions applied to the largest four regions in the north of Italy. On March 1<sup><em>st</em></sup>, these restrictions were extended to the whole Italy, with further lockdown actions entering in place on March 4<sup><em>th</em></sup>&nbsp;and 8<sup><em>th</em></sup>. On March 11<sup><em>th</em></sup>, the &ldquo;#IoRestoACasa&rdquo; Prime Ministerial Decree imposed a total lockdown to the whole Italy. Since then, and still at the time of writing, people are allowed to exit from home only for specific and urgent needs. Common retail businesses, catering and restaurant services are suspended. Gatherings in public places are prohibited. All activities not deemed essential for the Italian production chain are closed. Italy entered the most restrictive lockdown in its history.</p>\r\n\r\n<p><a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fig0001\" name=\"bfig0001\">Fig.&nbsp;1</a>&nbsp;clearly depicts the impact of these measures.<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fn0001\" name=\"bfn0001\"><sup>1</sup></a>&nbsp;It shows the variation of the mobility patterns in Italy since the begin of the emergency and the impact of the restrictions and total lockdown. The vertical bars highlight the relevant events listed above. The leftmost violet bar identifies the date of the first COVID-19 case in Italy. The central brown bar identifies the school shutdown. The rightmost bar marks the date of the &ldquo;#IoRestoACasa&rdquo; decree. The decrease in mobility is drastic after each of those events.</p>\r\n\r\n<p>Restrictions limited people&rsquo;s mobility while remote working, e-learning, online collaboration platforms started to grow along with online leisure solutions, like gaming and video streaming. These new habits highlighted the fundamental role of the Internet. Correspondingly, Internet traffic volume has grown by about 40%, sometimes with a decrease in the download performance, questioning the resiliency of the Internet itself&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#bib0001\" name=\"bbib0001\">[1]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#bib0002\" name=\"bbib0002\">[2]</a>.</p>\r\n\r\n<p><img alt=\"Fig. 1\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128620306046-gr1.jpg\" style=\"height:185px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128620306046-gr1_lrg.jpg\" target=\"_blank\" title=\"Download high-res image (296KB)\">Download :&nbsp;Download high-res image (296KB)</a></li>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128620306046-gr1.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 1.&nbsp;Variations in the mobility patterns in Italy between February and April 2020. Colors mark the days in which new Ministerial Decrees introduced mobility restrictions. Source:&nbsp;<a href=\"https://www.apple.com/covid19/mobility\" rel=\"noreferrer noopener\" target=\"_blank\">https://www.apple.com/covid19/mobility</a>.</p>\r\n\r\n<p>In this paper, we analyze the changes in the traffic patterns that are visible from our university campus, the Politecnico di Torino (PoliTO for short) in Italy. We look at the campus traffic, focusing on collaboration and remote working platforms usage, remote teaching adoption, and look for changes in unsolicited/malicious traffic. PoliTO opted to implement an in-house e-learning solution based on the BigBlueButton framework to support all the classes of the second semester, which were scheduled to start on March 2<sup><em>nd</em></sup>.<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fn0002\" name=\"bfn0002\"><sup>2</sup></a>&nbsp;The platform has been designed, installed, and tested during the first week of March, going live for the starting of the online semester one week later. Here we leverage this unique point of view to observe changes in the campus traffic and services during such a singular event. Moreover, we dig into details on how students access online classes and teaching material. Since students enjoy classes from their homes at different places, connected by different network operators, we check whether and how these factors affect the performance of the online teaching systems.</p>\r\n\r\n<p>Overall, we highlight a 10 times decrease in incoming traffic during the lockdown. Outgoing traffic grows instead of 2.5 times, driven by more than 600 daily online classes, with around 16&nbsp;000 students per day that follow classes. Online collaboration exploded, with faculty and staff members exchanging more than 17&nbsp;000 chat messages and participating to more than 1&nbsp;000 calls per day. We observe a surge in remote learning and working also during the weekends. Considering Internet connectivity, we notice no major problems, with only a few cases of poor performance, possibly related to people connected via 3G/4G operators.</p>\r\n\r\n<p>In a nutshell, we believe this paper testifies how the Internet proved able to cope with the sudden need for connectivity. We attest how remote working, e-learning and online collaboration platforms are a viable solution to cope with the social distancing policies during COVID-19 pandemic. While we all hope the latter will soon be relieved, we believe the experience of online collaboration will continue also after the COVID-19 disappears.</p>\r\n\r\n<p>The paper is organized as follows:&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#sec0002\" name=\"bsec0002\">Section&nbsp;2</a>&nbsp;describes the datasets and methodology;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#sec0007\" name=\"bsec0007\">Section&nbsp;3</a>&nbsp;reports a drill-down on the aggregate campus traffic patterns and online collaboration solutions;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#sec0011\" name=\"bsec0011\">Section&nbsp;4</a>&nbsp;focuses on online classes;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#sec0014\" name=\"bsec0014\">Section&nbsp;5</a>&nbsp;details network performance metrics, breaking down by operator and region;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#sec0017\" name=\"bsec0017\">Section&nbsp;6</a>&nbsp;looks into possible changes in unsolicited and malicious traffic, such as portscans and spam emails;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#sec0018\" name=\"bsec0018\">Section&nbsp;7</a>&nbsp;summarizes related work; finally&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#sec0019\" name=\"bsec0019\">Section&nbsp;8</a>&nbsp;concludes the paper.</p>\r\n\r\n<h2>2.&nbsp;Datasets and methodology</h2>\r\n\r\n<p>PoliTO is a medium-sized university that offers bachelor, master and graduate-level courses in the engineering and architecture fields only. It is among the top Universities in Italy. PoliTO has about 35&nbsp;000 students, of which 30% come from the Piedmont region where Torino is, 55% from other Italian regions, and 15% from the rest of the world. PoliTO employs about 2&nbsp;000 faculty and researchers, and around 1&nbsp;000 administrative staff members.<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fn0003\" name=\"bfn0003\"><sup>3</sup></a>&nbsp;PoliTO main campus network hosts all its IT services, and offers both Ethernet and WiFi connectivity to departments, offices, classrooms, student rooms, and laboratories. Two 10&nbsp;Gbit/s access links connect the campus LAN to the Internet, through the GARR (Gruppo per l&rsquo;Armonizzazione delle Reti della Ricerca) network, which provides Internet access to all Italian universities.</p>\r\n\r\n<p>In the following, we describe the data sources we use to gauge the changes in the traffic and services hosted at the campus network. If not explicitly said, the data cover the period from Saturday, February 1<sup><em>st</em></sup>&nbsp;to Sunday, April 5<sup><em>th</em></sup>&nbsp;2020.</p>\r\n\r\n<h3>2.1.&nbsp;Passive traces</h3>\r\n\r\n<p>We leverage statistics collected by edge routers to observe and compare the load on different Italian University networks. This data is stored by GARR in a central database publicly accessible.<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fn0004\" name=\"bfn0004\"><sup>4</sup></a>&nbsp;The repository stores the time series of the traffic volume on each edge link of the GARR network, with a granularity of five minutes. In our analysis, we consider PoliTO campus and compare it with two other large Italian universities for reference, namely Politecnico di Milano (the biggest technical university in Italy) and Universit&Atilde;&nbsp; di Torino.<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fn0005\" name=\"bfn0005\"><sup>5</sup></a></p>\r\n\r\n<p>While GARR offers only high-level aggregated data, here we also leverage on fine-grained measurements exposed by the monitoring infrastructure deployed in the Campus network. Such infrastructure is based on Tstat&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#bib0003\" name=\"bbib0003\">[3]</a>, a passive sniffer that analyzes the traffic entering and leaving the Campus. It computes flow-level logs similar to NetFlow, exposing information about TCP and UDP flows observed in the network. Beside classical flow-level fields, such as IP addresses and port numbers, Tstat exposes metrics such as Round-Trip time (RTT) and packet losses. We store Tstat logs in a secured Hadoop-based cluster. Tstat limits as much as possible any information that can be used to identify users &ndash; e.g., client IP addresses are anonymized using the CryptoPan algorithm&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#bib0004\" name=\"bbib0004\">[4]</a>, and no payload is stored. All data collection is approved and supervised by the responsible University officers.</p>\r\n\r\n<h3>2.2.&nbsp;Application logs</h3>\r\n\r\n<p>In addition to passive measurements, we extract data about servers and network devices offering specific services and applications that staff members may use for smart working. We focus on three classes of services: (i) the tools to access the internal resources of the Campus while working from home, namely Virtual Private Network (VPN) and Remote Desktop Protocol (RDP) services; (ii) the Microsoft Teams collaborative platform, which PoliTO adopted since 2019 to offer chat, file sharing, video calls and collaboration services to employees and students; (iii) email, antispam and security services. Logs available on the management consoles offer rich information about the usage of these services over time and let us study how the adoption of such services varied during the epidemic.</p>\r\n\r\n<h3>2.3.&nbsp;Virtual classrooms</h3>\r\n\r\n<p>To face the lockdown during the COVID-19 outbreak, PoliTO opted to set up an internally-hosted virtual classroom service for all classes. The system is based on the BigBlueButton framework for online learning, with customization to integrate it in the existing teaching portal. A total of 41 high-end servers running the BigBlueButton components and hosted in the Campus data center were set up in the first week of March. All classes started a week late. The BigBlueButton client-side application is based on HTML5. It provides high-quality audio, video and screen sharing application using the browser&rsquo;s built-in support for web real-time communication (WebRTC) libraries. In a nutshell, once the virtual classroom has been set up, BigBlueButton servers act as WebRTC Selective Forwarding Unit (SFU) capable of receiving multiple media streams (video, audio, screen sharing, etc.) and deciding which of these media streams should be sent to which participants. Video is encoded using the high-quality open-source codec VP8. PoliTO&rsquo;s setup lets the lecturer choose four video quality levels with a bitrate of 50, 100 (the default), 200, 300 kbit/s. Screen sharing may require the highest share of bandwidth, and, if the presenter&rsquo;s screen is updating frequently, the BigBlueButton client could transmit up to 1.0 Mbit/s. Audio is encoded using the OPUS encoder at 40&nbsp;kb/s.<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fn0006\" name=\"bfn0006\"><sup>6</sup></a>&nbsp;Finally, sharing slides takes little bandwidth beyond the initial upload/download of the pdf file.</p>\r\n\r\n<p>In our analyses, we collect and process the application logs of the video servers to study the consumption and performance of virtual classrooms. We also make use of the logs of the legacy teaching web platforms to study access to the teaching material like lecture notes, pre-recorded classrooms, etc.</p>\r\n\r\n<h3>2.4.&nbsp;Security monitors</h3>\r\n\r\n<p>At last, we analyze logs from the campus border firewall that limits the access towards authorized servers while blocking possibly malicious traffic and well-known attacks. Since we are interested in remote-working solutions, we check the firewall for alarms related to SSH, RDP, SIP attacks. Intuitively, we want to check if the attack patterns changed during the COVID-19 pandemic.</p>\r\n\r\n<p>The firewall is configured to let three /24 subnets to be completely open to the Internet, with no hosts connected to it. These sets of addresses act as &ldquo;darknets&rdquo;, i.e., sets of IP addresses regularly advertised which do not host any client or server. Any traffic the darknets receive is unsolicited by definition&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#bib0005\" name=\"bbib0005\">[5]</a>. By passively analyzing incoming packets, we observe important security events, such as the appearance and spread of botnets, DDoS attacks using spoofed IP address, etc. We use this information to further quantify if there is any change in attack patterns to our campus network during the pandemic.</p>\r\n\r\n<h2>3.&nbsp;Impact on campus traffic and remote working solutions</h2>\r\n\r\n<p>In this section, we analyze the impact of the COVID-19 outbreak on campus networks. We first provide quantitative figures on the overall traffic volume changes. Then, we focus on services supporting smart working.</p>\r\n\r\n<h3>3.1.&nbsp;Aggregate traffic volume</h3>\r\n\r\n<p>We first focus on the volume of traffic entering and leaving three Italian university campuses.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>&nbsp;shows the average hourly bitrate. For each hour, we compute the average bitrate seen over five working days. The positive&nbsp;<em>y</em>&nbsp;values represent incoming traffic (traffic directed to clients and servers hosted in the Campus LAN), while negative&nbsp;<em>y</em>&nbsp;values report the outgoing traffic (traffic directed to clients and servers on the Internet). Lines mark the volumes before and after the lockdown: the black lines depict the average per-hour bitrate observed during the week before the lockdown (third week of February), the red ones refer to averages calculated on the second week after the lockdown (third week of March). For comparison, the figure includes plots for the Politecnico di Torino (PoliTO) in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>a, the Politecnico di Milano (PoliMI) in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>b and the Universit&Atilde;&nbsp; di Torino (UniTO) in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>c.</p>\r\n\r\n<p><img alt=\"Fig. 2\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128620306046-gr2.jpg\" style=\"height:191px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128620306046-gr2_lrg.jpg\" target=\"_blank\" title=\"Download high-res image (459KB)\">Download :&nbsp;Download high-res image (459KB)</a></li>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128620306046-gr2.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 2.&nbsp;Traffic from three Italian Universities before and after the lockdown.</p>\r\n\r\n<p>Focusing on the positive&nbsp;y&minus;axes, observe how the incoming traffic has shrunk in the three cases, reflecting the lockdown effects. Since the second week of March, most students, researchers and staff members cannot access the campuses. The traffic after the lockdown is about one tenth of the traffic before it in both PoliTO and UniTO, with PoliMI still observing some sizeable incoming traffic. This difference reflects the different lockdown policies imposed by each university. PoliTO and UniTO completely blocked all teaching and research activities, while PoliMI still allows the activity of some laboratories.</p>\r\n\r\n<p>The negative&nbsp;y&minus;axes report the outgoing traffic. Again, the three campuses present different behaviors: We see a major increase in outgoing traffic from PoliTO, which is not observed in other campuses. This behavior is justified by the online teaching platform hosted in PoliTO which causes an increase of about 2.8 times the baseline outgoing traffic during peak time. PoliMI and UniTO have resorted to cloud-based solutions, hence the outgoing traffic volume does not show relevant changes before and after the lockdown.</p>\r\n\r\n<p><strong>Take away:</strong>&nbsp;<em>Campus incoming traffic drastically reduced during lockdown. Outgoing traffic changed in PoliTO, where an in-house online teaching service has been deployed. This system caused a massive inversion on traffic patterns, with significant growth in upload traffic due to online teaching services.</em></p>\r\n\r\n<h3>3.2.&nbsp;Smart working adoption</h3>\r\n\r\n<p>We now focus on PoliTO only and drill down on the services used by the personnel for working remotely.</p>\r\n\r\n<p>In&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fig0003\" name=\"bfig0003\">Fig.&nbsp;3</a>&nbsp;we show how the number of users relying on VPNs and remote desktop (RDP) solutions have changed over time. VPNs are used to access in-campus services and servers, while RDP allows one to remotely access files or run applications on their office computers. Curves in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fig0003\" name=\"bfig0003\">Fig.&nbsp;3</a>&nbsp;depict the total number of unique users accessing the services at least once in a day.<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128620306046#fn0007\" name=\"bfn0007\"><sup>7</sup></a>&nbsp;The effect of the lockdown started on March 11<sup><em>th</em></sup>&nbsp;2020 is astonishing. Since the lockdown started, these solutions simultaneously present a relevant increase in usage. PoliTO offers VPN services both over IPSec and SSL. Interestingly, SSL-based VPN usage increases significantly more than the IPSec-based solution. This suggests that the lockdown forced non-expert users to resort to a VPN, and they have opted for SSL-based VPN, which is easier to configure.</p>\r\n\r\n<p><img alt=\"Fig. 3\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128620306046-gr3.jpg\" style=\"height:187px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128620306046-gr3_lrg.jpg\" target=\"_blank\" title=\"Download high-res image (416KB)\">Download :&nbsp;Download high-res image (416KB)</a></li>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128620306046-gr3.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 3.&nbsp;Daily accesses to in-house PoliTO smart working systems.</p>\r\n\r\n<p>Users working from home also heavily rely on RDP, with about 500 users contacting such services at least once in a day after the lockdown. Sessions (not reported for the sake of brevity) last several hours, suggesting that this remote access method is mostly used for regular working sessions, and not only to access files on computers left in offices. Notice also the growth in the number of accesses over weekends, with more than 200 RDP accesses per day. This suggests that people, forced at home, keep working during the weekend, too.</p>', '2020-05-17 18:00:23.923080', 'Under Review', NULL, 1, 3);
INSERT INTO `app_article` VALUES (6, 1, 1, '', '2020-05-17 18:09:15.212339', 'Big data analytics for wireless and wired network design: A survey', 'Currently, the world is witnessing a mounting avalanche of data due to the increasing number of mobile network subscribers, Internet websites, and online services. This trend is continuing to develop in a quick and diverse manner in the form of big data. Big data analytics can process large amounts of raw data and extract useful, smaller-sized information, which can be used by different parties to make reliable decisions.\r\n\r\nIn this paper, we conduct a survey on the role that big data analytics can play in the design of data communication networks. Integrating the latest advances that employ big data analytics with the networks’ control/traffic layers might be the best way to build robust data communication networks with refined performance and intelligent features. First, the survey starts with the introduction of the big data basic concepts, framework, and characteristics. Second, we illustrate the main network design cycle employing big data analytics. This cycle represents the umbrella concept that unifies the surveyed topics. Third, there is a detailed review of the current academic and industrial efforts toward network design using big data analytics. Forth, we identify the challenges confronting the utilization of big data analytics in network design. Finally, we highlight several future research directions. To the best of our knowledge, this is the first survey that addresses the use of big data analytics techniques for the design of a broad range of networks.', '<h2>1.&nbsp;Introduction</h2>\r\n\r\n<p>Networks generate traffic in rapid, large, and diverse ways, which leads to an estimate of 2.5 exabytes created per day&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0001\" name=\"bbib0001\">[1]</a>. There are many contributors to the increasing size of the data. For instance, scientific experiments can generate lots of data, such as CERN&#39;s Large Hadron Collider (LHC) that generates over 40 petabyte each year&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0002\" name=\"bbib0002\">[2]</a>. Social media also has its share, with over 1 billion users, spending an average 2.5&nbsp;h daily, liking, tweeting, posting, and sharing their interests on Facebook and Twitter&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0003\" name=\"bbib0003\">[3]</a>. It is without a doubt that using this activity-generated data can affect many aspects, such as intelligence, e-commerce, biomedical, and data&nbsp;<a href=\"https://www.sciencedirect.com/topics/engineering/telecommunication-networks\" title=\"Learn more about Telecommunication Networks from ScienceDirect\'s AI-generated Topic Pages\">communication network</a>&nbsp;design. However, harnessing the powers of this data is not an easy task. To accommodate the data explosion, data centers are being built with massive storage and processing capabilities, an example of which is the National Security Agency (NSA) Utah data centre that can store up to 1 yottabyte of data&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0004\" name=\"bbib0004\">[4]</a>, and with a processing power that exceeds 100 petaflops&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0005\" name=\"bbib0005\">[5]</a>. Due to the increased needs to scale-up databases to data volumes that exceeded processing and/or storage capabilities, systems that ran on computer clusters started to emerge. Perhaps the first milestone took place in June 1986 when&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/teradata\" title=\"Learn more about Teradata from ScienceDirect\'s AI-generated Topic Pages\">Teradata</a>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0006\" name=\"bbib0006\">[6]</a>&nbsp;used the first parallel database system (hardware and software), with one terabyte storage capacity, in Kmart&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/data-warehouses\" title=\"Learn more about Data Warehouses from ScienceDirect\'s AI-generated Topic Pages\">data warehouse</a>&nbsp;to have all their business data saved and available for relational queries and business analysis&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0007\" name=\"bbib0007\">[7]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0008\" name=\"bbib0008\">[8]</a>. Other examples include the Gamma system of the University of Wisconsin&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0009\" name=\"bbib0009\">[9]</a>&nbsp;and the GRACE system of the University of Tokyo&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0010\" name=\"bbib0010\">[10]</a>.</p>\r\n\r\n<p>In light of the above, the term &ldquo;Big Data&rdquo; emerged, and it can be defined as high-volume, high-velocity, and high-variety data that provides substantial opportunities for cost-effective decision-making and enhanced insight through advanced processing which extracts information and knowledge from data&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0011\" name=\"bbib0011\">[11]</a>. Another way to define big data is by saying it is the amount of data that is beyond traditional technology capabilities to store, manage, and process in an efficient and easy way&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0012\" name=\"bbib0012\">[12]</a>. Big data is already being employed by digital-born companies like Google and Amazon to help these companies with data-driven decisions&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0013\" name=\"bbib0013\">[13]</a>. It also helps in the development of smart cities and campuses&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0014\" name=\"bbib0014\">[14]</a>, as well as in other fields like agriculture, healthcare, finance&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0015\" name=\"bbib0015\">[15]</a>, and transportation&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0016\" name=\"bbib0016\">[16]</a>. Big data has the following characteristics:</p>\r\n\r\n<p>1-</p>\r\n\r\n<p><em>Volume</em>: This is a representation of the data size&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0017\" name=\"bbib0017\">[17]</a>.</p>\r\n\r\n<p>2-</p>\r\n\r\n<p><em>Variety</em>: Generating data from a variety of sources results in a range of data types. These data types can be structured (e.g. e-mails), semi-structured (e.g. log files data from a webpage); and unstructured (e.g. customer feedback), and hybrid data&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0018\" name=\"bbib0018\">[18]</a>.</p>\r\n\r\n<p>3-</p>\r\n\r\n<p><em>Velocity</em>: Is an indication of the speed of the data when being generated, streamed, and aggregated&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0019\" name=\"bbib0019\">[19]</a>. It can also refer to the speed at which the data has to be analyzed to maintain relevance&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0017\" name=\"bbib0017\">[17]</a>.</p>\r\n\r\n<p>Depending on the research area and the problem space, other terms or Vs can be added. For example, is this data of any value? How long can we consider this an accurate and valid data? Since we are conducting a survey, we find it compelling to briefly introduce other Vs as well. Typically, the number of analyzed Vs is 3 to 7 in a single paper (e.g. 6V+C&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0020\" name=\"bbib0020\">[20]</a>), where C represents&nbsp;<em>Complexity</em>, however, different papers analyze different sets of Vs and the union (sum) of all the analyzed Vs among all surveyed papers is 8V and a C, as shown in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#tbl0001\" name=\"btbl0001\">Table&nbsp;1</a>.</p>\r\n\r\n<p>4-</p>\r\n\r\n<p><em>Value</em>: Is a measure of data usefulness when it comes to decision making&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0019\" name=\"bbib0019\">[19]</a>, or how much added-value is brought by the collected data to the intended process, activity, or predictive analysis/hypothesis&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0021\" name=\"bbib0021\">[21]</a>.</p>\r\n\r\n<p>5-</p>\r\n\r\n<p><em>Veracity</em>: Refers to the authenticity and trustworthiness of the collected data against unauthorized access and manipulation&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0021\" name=\"bbib0021\">[21]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0022\" name=\"bbib0022\">[22]</a>.</p>\r\n\r\n<p>6-</p>\r\n\r\n<p><em>Volatility</em>: An indication of the period in which the data can still be regarded as valid and for how long that data should be kept and stored&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0023\" name=\"bbib0023\">[23]</a>.</p>\r\n\r\n<p>7-</p>\r\n\r\n<p><em>Validity</em>: This might appear similar to veracity; however, the difference is that validity deals with data accuracy and correctness regarding the intended usage. Thus, certain data might be valid for an application but invalid for another.</p>\r\n\r\n<p>8-</p>\r\n\r\n<p><em>Variability</em>: This refers to the inconsistency of the data. This is due to the high number of distributed autonomous data sources&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0024\" name=\"bbib0024\">[24]</a>. Other researchers refer to the variability as the consistency of the&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/data-over-time\" title=\"Learn more about Data over Time from ScienceDirect\'s AI-generated Topic Pages\">data over time</a>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0022\" name=\"bbib0022\">[22]</a>.</p>\r\n\r\n<p>9-</p>\r\n\r\n<p><em>Complexity</em>: A measure of the degree of&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/interdependence\" title=\"Learn more about Interdependence from ScienceDirect\'s AI-generated Topic Pages\">interdependence</a>&nbsp;and inter-connectedness in big data&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0020\" name=\"bbib0020\">[20]</a>. Such that, a system may witness a (substantial, low, or no) effect due to a very small change(s) that ripples across the system&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0019\" name=\"bbib0019\">[19]</a>. Also, complexity can be considered in terms of relationship, correlation and connectivity of data. It can further manifest in terms of multiple data linkages, and hierarchies. Complexity and its mentioned attributes can however help better organize big data. It should be noted that complexity was included among the big data attributes (Vs) in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0020\" name=\"bbib0020\">[20]</a>&nbsp;where big data was characterized as having 6V + complexity. This is how we will arrange it in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#tbl0001\" name=\"btbl0001\">Table&nbsp;1</a>.</p>\r\n\r\n<p>Table 1.&nbsp;Various big data dimensions.</p>\r\n\r\n<table>\r\n	<thead>\r\n		<tr>\r\n			<th rowspan=\"2\" scope=\"col\">No. of Vs</th>\r\n			<th rowspan=\"2\" scope=\"col\">References</th>\r\n			<th colspan=\"9\" scope=\"col\">Dimensions (Characteristics)</th>\r\n		</tr>\r\n		<tr>\r\n			<th scope=\"col\">Volume</th>\r\n			<th scope=\"col\">Velocity</th>\r\n			<th scope=\"col\">Variety</th>\r\n			<th scope=\"col\">Veracity</th>\r\n			<th scope=\"col\">Value</th>\r\n			<th scope=\"col\">Variability</th>\r\n			<th scope=\"col\">Volatility</th>\r\n			<th scope=\"col\">Validity</th>\r\n			<th scope=\"col\">Complexity</th>\r\n		</tr>\r\n	</thead>\r\n	<tbody>\r\n		<tr>\r\n			<td>3Vs</td>\r\n			<td><a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0025\" name=\"bbib0025\">[25]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0026\" name=\"bbib0026\">[26]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0027\" name=\"bbib0027\">[27]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0028\" name=\"bbib0028\">[28]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0029\" name=\"bbib0029\">[29]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0030\" name=\"bbib0030\">[30]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0031\" name=\"bbib0031\">[31]</a></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n		<tr>\r\n			<td>4Vs</td>\r\n			<td><a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0004\" name=\"bbib0004\">[4]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0032\" name=\"bbib0032\">[32]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0033\" name=\"bbib0033\">[33]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0034\" name=\"bbib0034\">[34]</a></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n		<tr>\r\n			<td>&nbsp;</td>\r\n			<td><a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0035\" name=\"bbib0035\">[35]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0036\" name=\"bbib0036\">[36]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0037\" name=\"bbib0037\">[37]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0038\" name=\"bbib0038\">[38]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0039\" name=\"bbib0039\">[39]</a></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td>&nbsp;</td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n		<tr>\r\n			<td>5Vs</td>\r\n			<td><a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0003\" name=\"bbib0003\">[3]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0011\" name=\"bbib0011\">[11]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0021\" name=\"bbib0021\">[21]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0040\" name=\"bbib0040\">[40]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0041\" name=\"bbib0041\">[41]</a></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n		<tr>\r\n			<td>6Vs</td>\r\n			<td><a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0020\" name=\"bbib0020\">[20]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0022\" name=\"bbib0022\">[22]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0024\" name=\"bbib0024\">[24]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0042\" name=\"bbib0042\">[42]</a></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td>&nbsp;</td>\r\n			<td>&nbsp;</td>\r\n			<td><strong>&radic;</strong></td>\r\n		</tr>\r\n		<tr>\r\n			<td>7Vs</td>\r\n			<td><a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0023\" name=\"bbib0023\">[23]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0043\" name=\"bbib0043\">[43]</a></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td>&nbsp;</td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td><strong>&radic;</strong></td>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p>The process of extracting hidden, valuable patterns, and useful information from big data is called&nbsp;<em><a href=\"https://www.sciencedirect.com/topics/computer-science/big-data-analytics\" title=\"Learn more about Big Data Analytics from ScienceDirect\'s AI-generated Topic Pages\">big data analytics</a></em>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0044\" name=\"bbib0044\">[44]</a>. This is done through applying advanced&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/analytics-technique\" title=\"Learn more about Analytics Technique from ScienceDirect\'s AI-generated Topic Pages\">analytics techniques</a>&nbsp;on&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/large-data-set\" title=\"Learn more about Large Data Set from ScienceDirect\'s AI-generated Topic Pages\">large data sets</a>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0028\" name=\"bbib0028\">[28]</a>. Before commencing the analytics process, data sets may comprise certain consistency and redundancy problems affecting their quality. These problems arise due to the diverse sources from which the data originated.&nbsp;<em><a href=\"https://www.sciencedirect.com/topics/engineering/data-preprocessing\" title=\"Learn more about Data Preprocessing from ScienceDirect\'s AI-generated Topic Pages\">Data pre-processing</a></em>&nbsp;techniques are used to address these problems. The techniques include integration, cleansing (or cleaning), and&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/redundancy-elimination\" title=\"Learn more about Redundancy Elimination from ScienceDirect\'s AI-generated Topic Pages\">redundancy elimination</a>, and they were discussed by the authors in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0039\" name=\"bbib0039\">[39]</a>.</p>\r\n\r\n<p>Big data analytics can be carried out using a number of frameworks (shown below) that usually require an upgradeable cluster dedicated solely for that purpose&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0017\" name=\"bbib0017\">[17]</a>. Even if the cluster can be formed using a number of commodity servers&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0045\" name=\"bbib0045\">[45]</a>, however, this still forms an impediment for limited-budget users who want to analyze their data. The solution is presented through the democratization of computing. This made it possible for any-sized company and business owners to analyze their data using cloud computing platforms for big data analytics. Consequently, the use of big data analytics is not limited to enterprise-level companies. Furthermore, business owners do not have to heavily invest in an expensive hardware dedicated to analyzing their data&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0001\" name=\"bbib0001\">[1]</a>. Amazon is one of the companies that provide &lsquo;cloud-computed&rsquo; big data analytics for its customers. The service is called Amazon EMR (Elastic MapReduce), and it enables users to process their data in the cloud with a considerably lower cost in a pay-as-you-use fashion. The user is able to shrink or expand the size of the computing clusters to control the data volume handled and response time&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0001\" name=\"bbib0001\">[1]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0046\" name=\"bbib0046\">[46]</a></p>\r\n\r\n<p>Dealing with big amounts of data is not an easy task, especially if there is a certain goal in mind since data arrives in a fast manner, it is vital to provide fast collection, sorting, and processing speeds. Apache&nbsp;<a href=\"https://www.sciencedirect.com/topics/engineering/hadoop\" title=\"Learn more about Hadoop from ScienceDirect\'s AI-generated Topic Pages\">Hadoop</a>&nbsp;was created by Doug Cutting&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0047\" name=\"bbib0047\">[47]</a>&nbsp;for this purpose. It was later adopted, developed, and released by Yahoo&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0048\" name=\"bbib0048\">[48]</a>. Apache Hadoop can be defined as a top-level, java-written, open source framework. It utilizes clusters of commodity hardware&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0049\" name=\"bbib0049\">[49]</a>.</p>\r\n\r\n<p>Hadoop V1.x (shown in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#fig0001\" name=\"bfig0001\">Fig.&nbsp;1</a>) consists of two parts: the Hadoop Distributed File System (HDFS) that consists of a storage part, and a data processing and management (MapReduce) part. The master node has two processes,&nbsp;<em>a Job Tracker</em>&nbsp;that manages the processing tasks and a&nbsp;<em>Name Node</em>&nbsp;that manages the storage tasks&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0050\" name=\"bbib0050\">[50]</a>.</p>\r\n\r\n<p><img alt=\"Fig 1\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128618300239-gr1.jpg\" style=\"height:315px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128618300239-gr1_lrg.jpg\" target=\"_blank\" title=\"Download high-res image (221KB)\">Download :&nbsp;Download high-res image (221KB)</a></li>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128618300239-gr1.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 1.&nbsp;<a href=\"https://www.sciencedirect.com/topics/engineering/hadoop\" title=\"Learn more about Hadoop from ScienceDirect\'s AI-generated Topic Pages\">Hadoop</a>&nbsp;V1.x architecture.</p>\r\n\r\n<p>When a Job Tracker takes job requests, it splits the accepted job into tasks and pushes them to the&nbsp;<em>Task Trackers</em>&nbsp;located in the slave nodes&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0051\" name=\"bbib0051\">[51]</a>. The&nbsp;<em>Name Node</em>&nbsp;resembles the master part, while the&nbsp;<em>Data Nodes</em>&nbsp;represent the slave part&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0012\" name=\"bbib0012\">[12]</a>. There is more explanation in the HDFS part below.</p>\r\n\r\n<p>Many projects were developed in a quest to either complement or replace the above parts, and not all projects are hosted by the Apache Software Foundation, which is the reason for the emergence of the term&nbsp;<em>Hadoop ecosystem</em>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0047\" name=\"bbib0047\">[47]</a>.</p>\r\n\r\n<p>Hadoop V2.x is viewed as a three-layered model. These layers are classified as storage, processing, and management, as shown in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#fig0002\" name=\"bfig0002\">Fig.&nbsp;2</a>. The current Hadoop project has four components (modules), which are&nbsp;<a href=\"https://www.sciencedirect.com/topics/engineering/mapreduce\" title=\"Learn more about MapReduce from ScienceDirect\'s AI-generated Topic Pages\">MapReduce</a>, the HDFS,&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/yet-another-resource-negotiator\" title=\"Learn more about yet another resource negotiator from ScienceDirect\'s AI-generated Topic Pages\">Yet Another Resource Negotiator</a>&nbsp;(YARN), and Common utilities&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0017\" name=\"bbib0017\">[17]</a>.</p>\r\n\r\n<p>1-</p>\r\n\r\n<p><em>MapReduce</em>: As a programming model, MapReduce is used as a data processing engine and for cluster resource management. With the emergence of Hadoop v2.0, the resource management task became YARN&#39;s responsibility&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0017\" name=\"bbib0017\">[17]</a>. WordCount is an example illustrating how MapReduce works. As the name implies, it calculates the number of times a specific word is repeated within a document. Tuples 〈<em>w</em>, 1〉 are produced by the map function, where&nbsp;<em>w</em>&nbsp;and 1 represents the word and the times it appeared in the document respectively. The reduce function groups the tuples that share the same word and sums their occurrences to reach the concluding result&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0061\" name=\"bbib0061\">[61]</a>.</p>\r\n\r\n<p>2-</p>\r\n\r\n<p><em>HDFS</em>: HDFS represents the storage file-system component in the Hadoop ecosystem. Its main feature is to store huge amounts of data over multiple nodes and stream those data sets to user applications at high bandwidth. Large files are split into smaller 128 MB blocks, with three copies of each block of data to achieve fault tolerance in the case of disk failure&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0017\" name=\"bbib0017\">[17]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0052\" name=\"bbib0052\">[52]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0053\" name=\"bbib0053\">[53]</a>.</p>\r\n\r\n<p>3-</p>\r\n\r\n<p><em>YARN</em>: YARN was introduced in Hadoop version 2.0, and it simply took over the tasks of cluster resource management from MapReduce and separated it from the programming model, thus making a more generalized Hadoop capable of selecting programming models, like Spark&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0054\" name=\"bbib0054\">[54]</a>, Storm&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0055\" name=\"bbib0055\">[55]</a>, and Dryad&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0056\" name=\"bbib0056\">[56]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0057\" name=\"bbib0057\">[57]</a>.</p>\r\n\r\n<p>4-</p>\r\n\r\n<p><em>Common utilities</em>: To operate Hadoop&#39;s sub-projects or modules, a set of common utilities or components are needed. Shared libraries support operations like error detection, Java implementation for compression codes, and I/O utilities&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0017\" name=\"bbib0017\">[17]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0058\" name=\"bbib0058\">[58]</a>.</p>\r\n\r\n<p><img alt=\"Fig 2\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128618300239-gr2.jpg\" style=\"height:310px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128618300239-gr2_lrg.jpg\" target=\"_blank\" title=\"Download high-res image (144KB)\">Download :&nbsp;Download high-res image (144KB)</a></li>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S1389128618300239-gr2.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 2.&nbsp;<a href=\"https://www.sciencedirect.com/topics/engineering/hadoop\" title=\"Learn more about Hadoop from ScienceDirect\'s AI-generated Topic Pages\">Hadoop</a>&nbsp;V2.x architecture.</p>\r\n\r\n<p>Over the last few years, researchers in telecommunication networks started to consider big data analytics in their design toolbox. Characterized by hundreds of tunable parameters, wireless network design informed by big data analytics received most of the attention, however, other types of networks received increasing attention as well.</p>\r\n\r\n<p>The vast amount of data that can be collected from the networks, along with the distributed modern&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/high-performance-computing\" title=\"Learn more about high-performance computing from ScienceDirect\'s AI-generated Topic Pages\">high-performance computing</a>&nbsp;platforms, can lead to new cost-effective design space (e.g. reducing total cost of ownership by employing dynamic Virtual&nbsp;<a href=\"https://www.sciencedirect.com/topics/engineering/network-topology\" title=\"Learn more about Network Topology from ScienceDirect\'s AI-generated Topic Pages\">Network Topology</a>&nbsp;adaptation) when compared to classical approaches (i.e. static Virtual Network Topologies)&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#bib0059\" name=\"bbib0059\">[59]</a>. This new paradigm is promising to convert networks from being sightless tubes for data into insightful context-aware networks. Our contributions in this paper are as follows:</p>\r\n\r\n<p>1-</p>\r\n\r\n<p>We show in this paper the role big data analytics can play in wireless and wired network design.</p>\r\n\r\n<p>2-</p>\r\n\r\n<p>The above role is corroborated through the illustration of case studies in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#sec0001\" name=\"bsec0001\">Section&nbsp;2</a>.</p>\r\n\r\n<p>3-</p>\r\n\r\n<p>The significance of this paper lies in helping academic researchers save much effort by understanding the state-of-the-art and identifying the opportunities, as well as the challenges facing the use of big data analytics in network design.</p>\r\n\r\n<p>4-</p>\r\n\r\n<p>In addition to academic approaches, we surveyed network equipment manufacturing companies highlighting network solutions based on big data analytics. We also identified the common areas of interest among these solutions, and thus this survey can benefit both academic and industrial-oriented readers.</p>\r\n\r\n<p>5-</p>\r\n\r\n<p>This paper provided insights on potential research directions as illustrated in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#sec0051\" name=\"bsec0051\">Section&nbsp;8</a>.</p>\r\n\r\n<p>This paper is organized as follows:&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#sec0002\" name=\"bsec0002\">Section&nbsp;2</a>&nbsp;presents several case studies uses big data analytics in wireless and wired networks.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#sec0006\" name=\"bsec0006\">Sections&nbsp;3</a>&ndash;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#sec0045\" name=\"bsec0045\">6</a>&nbsp;illustrate the research conducted in the direction of employing big data analytics in the fields of cellular, SDN &amp; intra-data center,&nbsp;<a href=\"https://www.sciencedirect.com/topics/engineering/fiber-optic-networks\" title=\"Learn more about Fiber Optic Networks from ScienceDirect\'s AI-generated Topic Pages\">optical networks</a>, and network security, respectively.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#sec0050\" name=\"bsec0050\">Section&nbsp;7</a>&nbsp;summarizes some of the main big data-based network solutions offered by industry.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#sec0051\" name=\"bsec0051\">Section&nbsp;8</a>&nbsp;discusses the network design cycle based on big data analytics and highlights the challenges encountered in big data-powered network design. In&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#sec0057\" name=\"bsec0057\">Section&nbsp;9</a>&nbsp;we propose open directions for future research. Finally, the paper ends with conclusions in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S1389128618300239#sec0058\" name=\"bsec0058\">Section&nbsp;10</a>.</p>', '2020-05-17 18:09:15.216747', 'Under Review', NULL, 1, 3);
INSERT INTO `app_article` VALUES (7, 1, 1, '', '2020-05-17 18:13:49.038945', 'PyFrac: A planar 3D hydraulic fracture simulator', 'Fluid driven fractures propagate in the upper earth crust either naturally or in response to engineered fluid injections. The quantitative prediction of their evolution is critical in order to better understand their dynamics as well as to optimize their creation. We present an open-source Python implementation of a hydraulic fracture growth simulator based on the implicit level set algorithm originally developed by Peirce & Detournay (2008). This algorithm couples a finite discretization of the fracture with the use of the near tip asymptotic solutions of a steadily propagating semi-infinite hydraulic fracture. This allows to resolve the multi-scale processes governing hydraulic fracture propagation accurately, even on relatively coarse meshes. We present an overview of the mathematical formulation, the numerical scheme and the details of our implementation. A series of problems including a radial hydraulic fracture verification test, the propagation of a height contained hydraulic fracture, the lateral spreading of a magmatic dyke and an example of fracture closure are presented to demonstrate the capabilities, accuracy and robustness of the implemented algorithm.', '<h2>1.&nbsp;Introduction</h2>\r\n\r\n<p>Hydraulic fractures (HFs) are a class of tensile fracture propagating in rocks under pre-existing compressive stress in response to the injection or release of pressurized fluid&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b1\" name=\"bb1\">[1]</a>. They are routinely engineered in order to increase the production of oil and gas wells&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b2\" name=\"bb2\">[2]</a>. Hydraulic fractures are also used in the pre-conditioning of ore body mined via block caving techniques&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b3\" name=\"bb3\">[3]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b4\" name=\"bb4\">[4]</a>. Compensation grouting is another example of their application in civil engineering&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b5\" name=\"bb5\">[5]</a>. HFs also occur naturally as dykes propagating from deep pressurized magma chamber&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b6\" name=\"bb6\">[6]</a>&nbsp;or as fracture propagating at glacier beds following sudden fluid discharge&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b7\" name=\"bb7\">[7]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b8\" name=\"bb8\">[8]</a>. Quantitative estimate of the dynamics and extent of hydraulic fractures is critical in practical applications in order to optimize the engineering design. This is typically done with the help of numerical models. In addition, numerical modelling can also help in understanding hydraulic fracture growth in non-trivial configurations.</p>\r\n\r\n<p>Numerical modelling of hydraulic fractures has been an active area of research since the end of the 1950s. The mathematical models have evolved from simple geometries with ad-hoc growth physics to sophisticated three dimensional models - see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b9\" name=\"bb9\">[9]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b10\" name=\"bb10\">[10]</a>&nbsp;for the most recent reviews. The numerical modeling of the propagation of hydraulic fracture is extremely challenging due to a number of reasons. In addition to the intrinsic moving boundary nature of the problem, the coupling between the lubrication fluid flow inside the fracture and the elastic deformation of the rock (non-local by essence) is extremely non-linear as the fracture hydraulic transmissivity increases with the cube of the local fracture width. Such a hydro-mechanical coupling yields a complex multiscale structure of the solution in the near tip region where the classical linear elastic fracture mechanics asymptote can reduce to a small boundary layer near the tip while a viscous asymptote control the far-field behavior. An intermediate asymptote due to fluid leaking off in the surrounding rock can also appear - see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b11\" name=\"bb11\">[11]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b12\" name=\"bb12\">[12]</a>&nbsp;for detailed solutions and experimental validation. This multi-scale structure of the solution near the propagating hydraulic fracture front is known to control the propagation of finite hydraulic fractures which exhibit a competition between the dissipative processes associated with fluid flow and fracture creation as well as between the amount of fluid leaking off the fracture compared to the amount stored within the fracture&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b13\" name=\"bb13\">[13]</a>. Numerical models of HF growth must therefore properly resolve these different lengthscales near the fracture front in order to yield accurate results. This is particularly challenging numerically as the extent of the different asymptotic regions can vary widely as function of the rock and injection properties - therefore requiring extremely fine meshes in some cases.</p>\r\n\r\n<p>We present a Python implementation of a particularly efficient numerical scheme for hydraulic fracture (HF) propagation denoted as the implicit level set algorithm (ILSA)&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b14\" name=\"bb14\">[14]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b15\" name=\"bb15\">[15]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b16\" name=\"bb16\">[16]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b17\" name=\"bb17\">[17]</a>. The scheme elegantly couples the near-tip asymptotic solution of a steadily moving hydraulic fracture&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b11\" name=\"bb11\">[11]</a>&nbsp;(valid in the near-tip region) with a finite discretization of the fracture. By using the near-tip HF asymptotic solution, the challenging numerical resolution of the multiscales structure of the solution near the tip is avoided altogether. As a result, this allows to obtain highly accurate solutions even on relatively coarse meshes as compared to other fracture propagation algorithms (see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b10\" name=\"bb10\">[10]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b18\" name=\"bb18\">[18]</a>&nbsp;for comparisons).</p>\r\n\r\n<p>Our Python implementation also includes a number of extensions to the original ILSA scheme. In particular, the developed solver includes (1) the capability to advance the fracture front implicitly, explicitly or in a predictor&ndash;corrector fashion&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b19\" name=\"bb19\">[19]</a>, (2) the modification of the lubrication flow to take into account the possible transition to turbulent flow&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b20\" name=\"bb20\">[20]</a>, (3) the possibility to account for an anisotropy of fracture toughness and elasticity&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b21\" name=\"bb21\">[21]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b22\" name=\"bb22\">[22]</a>, and finally (4) the capability to handle closure of the fracture after the end of pumping.</p>\r\n\r\n<p>In the following, we briefly describe the underlying mathematical model of HF growth, its solution in the context of the implicit level set algorithm and discuss some details of our implementation. Several examples are then discussed in order to illustrate the accuracy and capabilities of the developed numerical code.</p>\r\n\r\n<h2>2.&nbsp;Mathematical model</h2>\r\n\r\n<p>PyFrac solves the equations of the classical linear elastic hydraulic fracture problem for a three-dimensional planar fracture. We briefly recall below the governing equations for such class of problems and refer to&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b1\" name=\"bb1\">[1]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b10\" name=\"bb10\">[10]</a>&nbsp;for a more detailed description of the underlying physical assumptions.</p>\r\n\r\n<h3>2.1.&nbsp;Elastic deformation</h3>\r\n\r\n<p>For a pure opening mode planar fracture (mode I), the quasi-static balance of momentum of the medium reduces to a single hyper singular boundary integral equation relating the fracture width&nbsp;w&nbsp;(normal displacement discontinuity) and the normal component of the traction vector. In the case of a planar fracture of area&nbsp;A(t)&nbsp;(evolving with time) in a homogeneous isotropic material, it further reduces to (see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b23\" name=\"bb23\">[23]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b24\" name=\"bb24\">[24]</a>&nbsp;for details)(1)T(x,y,t)&minus;&sigma;o(x,y)=&minus;E&prime;8&pi;&int;A(t)w(x&prime;,y&prime;,t)&nbsp;dA(x&prime;,y&prime;)[(x&prime;&minus;x)2+(y&prime;&minus;y)2]3∕2.where&nbsp;T&nbsp;and&nbsp;&sigma;o&nbsp;are the normal components of the applied traction and the far-field in-situ compressive stress respectively. We account for the fact that the fracture opening&nbsp;w&nbsp;can not be negative. More precisely, upon fracture creation, the fracture may close but exhibit a residual aperture&nbsp;wa&nbsp;taken as the minimum between the maximum opening encountered thus far at this position and a value related to the intrinsic roughness of the created fracture&nbsp;wr:&nbsp;wa=minmax(w),wr. This results in the following contact conditions(2)(w&minus;wa)&ge;0(T&minus;p)(w&minus;wa)=0which states that if the fracture is mechanically open at a given location, the corresponding normal traction on the fracture faces&nbsp;T(x,y,t)&nbsp;equals the fluid pressure&nbsp;p(x,y,t).</p>\r\n\r\n<h3>2.2.&nbsp;Lubrication flow inside the fracture</h3>\r\n\r\n<p>The fluid flow inside the fracture obeys the lubrication approximation&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b25\" name=\"bb25\">[25]</a>. The width averaged mass conservation for a slightly compressible liquid reduces to (see e.g.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b10\" name=\"bb10\">[10]</a>)(3)&part;w&part;t+cfw&part;p&part;t+&nabla;&sdot;q+vL=Q(x,y)&delta;(x,y),where&nbsp;vL&nbsp;denotes the velocity of the fluid leaking out of the two opposite faces of the fracture, and&nbsp;q&nbsp;is the fluid flux within the fracture. Similarly, for such a lubrication flow, the width averaged balance of momentum of the fluid reduces to Poiseuille&rsquo;s law. Accounting for the possible appearance of turbulent flow (but still neglecting inertial terms), the fluid flux&nbsp;q=w&times;v&nbsp;is directly related to the fluid pressure gradient as&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b17\" name=\"bb17\">[17]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b26\" name=\"bb26\">[26]</a>:(4)q=&minus;w312&mu;f̃ReDeq,wR∕w(&nabla;p+&rho;g),where the reduced Fanning friction factor&nbsp;f̃&nbsp;is defined as:(5)f̃ReDeq,wRw=f43Re,wRw∕flaminar.It captures the possible transition to turbulent flow inside the fracture as function of the local Reynolds number&nbsp;Re=&rho;wv∕&mu;&nbsp;and the roughness length scale&nbsp;wR:&nbsp;f&nbsp;is the Fanning friction factor expression for turbulent flow in pipe (function of the Reynolds number) and&nbsp;flaminar=64∕Re&nbsp;is the laminar expression such that&nbsp;f̃=1&nbsp;for laminar flow. Different models for Fanning friction are available in our implementation - notably the one described in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b27\" name=\"bb27\">[27]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b28\" name=\"bb28\">[28]</a>.</p>\r\n\r\n<p>The leak off fluid velocity&nbsp;vL&nbsp;is evaluated using the Carter&rsquo;s leak off model (see e.g.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b10\" name=\"bb10\">[10]</a>&nbsp;for discussion):(6)vL=2CL(x,y)t&minus;t0(x,y).where&nbsp;CL&nbsp;[L.T&minus;1∕2] is the Carter&rsquo;s leak-off coefficient which depends on the rock and fracturing fluid properties.</p>\r\n\r\n<h3>2.3.&nbsp;Boundary conditions</h3>\r\n\r\n<p>PyFrac assumes that the fluid and fracture front coincides: a condition typically encountered when the in-situ normal compressive stress&nbsp;&sigma;o&nbsp;is sufficiently large (see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b29\" name=\"bb29\">[29]</a>&nbsp;for discussion). As a result, at the fracture front, beside the condition of zero fracture width, the component of the fluid flux&nbsp;q(x,t)&nbsp;normal to the fluid front also vanishes:(7)w(xc,t)=0,q(xc,t)&sdot;n(xc,t)=0,xc&isin;C(t),where&nbsp;C(t)&nbsp;denotes the fracture front at time&nbsp;t&nbsp;and&nbsp;n(xc,t)&nbsp;its corresponding normal. Moreover, the hydraulic fracture is assumed to be propagating in quasi-static equilibrium. As a result, the stress intensity factor everywhere along the fracture front is equal to (or below for a stagnant front) the fracture toughness of the rock. This results in the following propagation condition:(8)(KI(xc,t)&minus;KIc(xc,&alpha;))&le;0(9)(KI(xc,t)&minus;KIc(xc,&alpha;))&times;V(xc)=0xc&isin;C(t).where&nbsp;V(xc)&ge;0&nbsp;is the local fracture propagation velocity. The fracture toughness of the material&nbsp;KIc&nbsp;can possibly be function of position (inhomogeneous material) as well as of the propagation direction&nbsp;&alpha;&nbsp;in the case of a material with an anisotropic fracture toughness (see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b21\" name=\"bb21\">[21]</a>&nbsp;for details).</p>\r\n\r\n<h2>3.&nbsp;Numerical solution</h2>\r\n\r\n<p>In this section, We outline some details of our implementation of ILSA. We refer to the description given in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b14\" name=\"bb14\">[14]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b15\" name=\"bb15\">[15]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b17\" name=\"bb17\">[17]</a>&nbsp;for more details.</p>\r\n\r\n<p><img alt=\"\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0010465520301582-gr1.jpg\" style=\"height:275px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S0010465520301582-gr1_lrg.jpg\" target=\"_blank\" title=\"Download high-res image (169KB)\">Download :&nbsp;Download high-res image (169KB)</a></li>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S0010465520301582-gr1.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 1.&nbsp;Schematic of the finite discretization of the fracture plane with the fracture front cutting through the background Cartesian grid. At any time, the cells are classified as either tip (near the front) or channel cells. Among the channel cells, the center of the cells adjacent to the tip cells are taken as survey points and are used to couple the finite discretization with the near-tip hydraulic asymptotic solution.</p>\r\n\r\n<h3>3.1.&nbsp;Discretization</h3>\r\n\r\n<p>The hydraulic fracture is discretized using a fixed Cartesian mesh with rectangular cells of sizes&nbsp;&Delta;x,&nbsp;&Delta;y&nbsp;- see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fig1\" name=\"bfig1\">Fig.&nbsp;1</a>. The algorithm marches forward in time from a known solution at time&nbsp;tn&nbsp;which consists of the location of the fracture front (intersecting the background grid), width and fluid pressures at the center of the cells located inside the fracture.</p>\r\n\r\n<p>Using the distributed dislocation technique, the elasticity equation&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd1\" name=\"bfd1\">(1)</a>&nbsp;is collocated at the center of each cell within the current fracture footprint assuming a piece-wise constant value of fracture width in each cell. It results in a dense linear system for an open fracture loaded by a fluid (where&nbsp;T=p&nbsp;in&nbsp;Eq.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd1\" name=\"bfd1\">(1)</a>). The fluid pressure&nbsp;pi,j&nbsp;at cell&nbsp;(i,j)&nbsp;located in an open part of the fracture (see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fig1\" name=\"bfig1\">Fig.&nbsp;1</a>) is linearly related to the opening in all the other cells(10)pi,j&minus;&sigma;oi,j=Ei,j;k,lwk,l,where&nbsp;Ei,j;k,l&nbsp;is the elastic contribution of cell&nbsp;(k,l)&nbsp;on cell&nbsp;(i,j)&nbsp;and summation is performed on repeated indices. If the fracture is mechanically closed, the width&nbsp;wi,j&nbsp;equals the residual aperture&nbsp;wa, and the corresponding traction&nbsp;Ti,j&nbsp;is now unknown (see Eq.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd2\" name=\"bfd2\">(2)</a>).</p>\r\n\r\n<p>The lubrication equation&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd3\" name=\"bfd3\">(3)</a>&nbsp;is discretized using a cell centered finite volume method. Using a backward-Euler time integration scheme, one obtains the following equation for cell&nbsp;(i,j)&nbsp;over the time step of size&nbsp;&Delta;t:(11)&Delta;wi,j=[Ap]i,j&minus;[C&Delta;p]i,j+Gi,j+&Delta;tQi,j&minus;Li,j,where the fluid flux across the cell edges is approximated by central finite difference resulting in a five point stencil:(12)[Ap]i,j=&Delta;t&Delta;x2Ki+1∕2,jpi+1,j&minus;(Ki+1∕2,j+Ki&minus;1∕2,j)pi,j+Ki&minus;1∕2,jpi&minus;1,j+&Delta;t&Delta;y2Ki,j+1∕2pi,j+1&minus;(Ki,j+1∕2+Ki,j&minus;1∕2)pi,j+Ki,j&minus;1∕2pi,j&minus;1The fracture fluid transmissivity&nbsp;Ki&minus;1∕2,j&nbsp;at the cell edge&nbsp;(i&minus;1∕2,j)&nbsp;(and similarly for the other edges) is given by(13)Ki&minus;1∕2,j=wi&minus;1∕2,j312&mu;f̃(ReDeqi&minus;1∕2,j,wR∕wi&minus;1∕2,j),where the width and Reynolds number are averages of the two neighboring cells. These transmissivities are non-linearly dependent on the current estimate of fracture width.</p>\r\n\r\n<p>For a gravity vector aligned along the&nbsp;y&nbsp;axis of the grid, the gravity term&nbsp;Gi,j&nbsp;is given by(14)Gi,j=&Delta;t&Delta;y(Ki,j+1∕2&minus;Ki,j&minus;1∕2)&rho;g,while the effect of fluid compressibility is strictly local and reads(15)[C&Delta;p]i,j=cfwi,jn+&Delta;wi,j2&Delta;pi,j.Qi,j&nbsp;contains the fluid injection rate (only non-zero in the injection cell). The leak-off contribution&nbsp;Li,j&nbsp;for cell&nbsp;(i,j)&nbsp;over the time-step is approximated as&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b14\" name=\"bb14\">[14]</a>:(16)Li,j=4CL&Delta;ttn+&Delta;t&minus;toi,j&minus;tn&minus;toi,jwhere&nbsp;toi,j&nbsp;is the time at which the fracture front has first passed through the center of cell&nbsp;(i,j)&nbsp;(also refereed to as the trigger time for leak-off).</p>\r\n\r\n<h3>3.2.&nbsp;Elasto-hydrodynamics solver</h3>\r\n\r\n<p>For a&nbsp;<em>known trial</em>&nbsp;position of the fracture front at time&nbsp;t+&Delta;t, the non-linear coupling between the discretized lubrication&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd11\" name=\"bfd11\">(11)</a>&nbsp;and elastic&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd10\" name=\"bfd10\">(10)</a>&nbsp;equations can be re-written in a matrix form. Taking the increment of width and pressure in all cells within the fracture footprint as the primary unknowns, one obtains the following non-linear system when no width constraints are active:(17)E&minus;II&minus;L(&Delta;w)&Delta;w&Delta;p=0A(&Delta;w)&sdot;pn+G(&Delta;w)+S︸FL.In the previous equation,&nbsp;I&nbsp;denotes the identity matrix. The elasticity block&nbsp;E&nbsp;is dense, while&nbsp;L(&Delta;w)=A(&Delta;w)&minus;C(&Delta;w)&nbsp;is sparse (notably the effect of compressibility&nbsp;C&nbsp;is strictly diagonal). We have also highlighted the non-linear dependence of&nbsp;L&nbsp;on the current fracture width increment, and defined&nbsp;S=&Delta;tQ&minus;L&nbsp;combining the injection sources and leak-off sink terms.</p>\r\n\r\n<p>As previously mentioned, the implicit level set algorithm incorporates the near tip asymptotic solution for a steadily moving hydraulic fracture near the fracture front. This is done by identifying the cells intersecting with the fracture front (denoted as tip cells) and the cells within the fracture apart from the tip cells (called channel cells). The fracture widths of the tip cells are imposed according to the HF tip solution which depends on the current estimate of the local fracture velocity. The pressure in the flow equation&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd11\" name=\"bfd11\">(11)</a>&nbsp;is substituted with width using the elasticity equation&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd10\" name=\"bfd10\">(10)</a>&nbsp;for mechanically open channel cells (denoted with a superscript&nbsp;C). In addition to imposing the fracture width in the tip cells, we also enforce the minimum width constraint&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd2\" name=\"bfd2\">(2)</a>&nbsp;everywhere - and denote the corresponding set of cells with active constraints with a superscript&nbsp;A.</p>\r\n\r\n<p>After imposing the width according to the HF tip asymptote and the active minimum width constraints in the set of tip (denoted with a superscript&nbsp;T) and active cells (superscript&nbsp;A) respectively, the nonlinear system&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd17\" name=\"bfd17\">(17)</a>&nbsp;can be re-written to solve for the increment of width&nbsp;&Delta;w&nbsp;in the channel cells and increment of fluid pressure&nbsp;&Delta;p&nbsp;in the tip cells (T) and the cells (A) with an active width constraint. The final non-linear system can be expressed in the following format highlighting the different sub-blocks:(18)ICC&minus;LCCECC&minus;LCT&minus;LCA&minus;LTCECC&minus;LTT&minus;LTA&minus;LACECC&minus;LAT&minus;LAA&Delta;wC&Delta;pT&Delta;pA=FLC+LCCbCFLT&minus;&Delta;wT+LTCbCFLA&minus;&Delta;wA+LACbCwhere the different matrix sub-blocks are defined with respect to the channel (C), tip (T) and active (A) cells. We have also defined(19)bC=ECT&Delta;wT+ECA&Delta;wAand the increment of width in the tip and active cells are simply given by:(20)&Delta;wT=wT&minus;wnT(21)&Delta;wA=waA&minus;wnA,where&nbsp;wT&nbsp;represents the vector of width in the tip cells evaluated using the HF tip asymptote&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b11\" name=\"bb11\">[11]</a>&nbsp;and&nbsp;waA&nbsp;is the vector of minimum residual width. The vectors (e.g.&nbsp;FLC) on the right hand side of Eq.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd18\" name=\"bfd18\">(18)</a>&nbsp;are short notation for the right hand side appearing in the system of Eq.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd17\" name=\"bfd17\">(17)</a>.</p>\r\n\r\n<p>The non-linear system&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd18\" name=\"bfd18\">(18)</a>&nbsp;is solved iteratively using a simple fixed-point scheme which has proven to be robust and accurate. Convergence is reached when the L2 norm of subsequent estimates of the increment of width and pressure are below a prescribed tolerance (in relative term) - typically 10<sup>&minus;6</sup>. The inequality constraints are checked after convergence and the set of active cells updated if required (and the system subsequently re-solved until convergence of the active set). Due to its non-linear nature and the fact that the previous system needs to be solved for each trial position of the fracture front, it is the most critical part of the solver from a computational point of view.</p>\r\n\r\n<p>It is also worthwhile to note that in the case of an inviscid fluid (zero viscosity/toughness dominated propagation), the fluid pressure is uniform inside the fracture (in the absence of gravity). In that limiting case, a simpler set of equations can be solved combining elastic deformation and global volume balance in order to solve for increment of width and a single fluid pressure increment (see e.g.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b14\" name=\"bb14\">[14]</a>&nbsp;for details).</p>\r\n\r\n<h3>3.3.&nbsp;The fracture propagation algorithm</h3>\r\n\r\n<p>The fracture front is represented by a level set function and its new position at the end of the time step is obtained iteratively in a fully implicit manner in the original ILSA scheme&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b14\" name=\"bb14\">[14]</a>.</p>\r\n\r\n<p>Once the non-linear elasto-hydrodynamics system&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fd18\" name=\"bfd18\">(18)</a>&nbsp;has been solved for a given trial position of the fracture front, the estimate of the new width in the cell just behind the tip cells (survey points in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fig1\" name=\"bfig1\">Fig.&nbsp;1</a>) are used in combination with the HF tip solution in order to obtain the local closest distance&nbsp;s&nbsp;from the survey point to the fracture front. This is performed by inverting the HF tip asymptotic solution giving the fracture width as function of the closest distance to the fracture tip. The closest distance to the fracture front obtained in all the cells behind the tip cells provide an initial condition to solve for the signed distance to the fracture front (i.e.&nbsp;the level set function) in all the grid cells. The solution of this Eikonal equation is performed via a fast marching method. The fracture front can then be reconstructed using a piece-wise linear approximation within each cell. Subsequently, the width in the tip cells for this new position of the fracture front can be imposed using the HF near tip asymptotic solution (using the local fracture front velocity). More precisely, the volume of the tip cells are prescribed to ensure proper volume conservation. The algorithm then re-solve the non-linear elasto-hydrodynamics system to obtain a new estimate of the fracture width increment and tip pressure. Convergence is reached when subsequent estimate of the level set function at all survey points falls below a given tolerance (in relative term) - typically 10<sup>&minus;3</sup>.</p>\r\n\r\n<p>It is interesting to point out that beside a fully implicit scheme, we also provide an explicit as well as predictor&ndash;corrector version of the scheme. In the original fully implicit version of the scheme, the first trial position of the new fracture front is kept as its value at the end of the previous time-step. The fully explicit version estimate the new position of the fracture front from the local velocities obtained at the end of the previous time-step (and thus no iteration on the fracture front position are performed). The predictor&ndash;corrector version subsequently iterate from the trial position obtained explicitly. More details and comparisons of the difference scheme are discussed in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b19\" name=\"bb19\">[19]</a>. By default, PyFrac uses a predictor&ndash;corrector scheme but such a choice can be modified by the user if desired.</p>\r\n\r\n<p>A complete summary of the algorithm over one time-step is shown in the form of a flow chart in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#fig2\" name=\"bfig2\">Fig.&nbsp;2</a>. Note that the value of the time-step is automatically adjusted from the current knowledge of the fracture front velocity - see&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465520301582#b19\" name=\"bb19\">[19]</a>&nbsp;for more details.</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p><img alt=\"\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0010465520301582-gr2.jpg\" style=\"height:709px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S0010465520301582-gr2_lrg.jpg\" target=\"_blank\" title=\"Download high-res image (991KB)\">Download :&nbsp;Download high-res image (991KB)</a></li>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S0010465520301582-gr2.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig. 2.&nbsp;The algorithm used by PyFrac to advance a time step. The predictor corrector, implicit and explicit front advancing schemes are shown in blue, red and green colors respectively. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p>', '2020-05-17 18:13:49.041049', 'Rejected', NULL, 1, 2);
INSERT INTO `app_article` VALUES (8, 1, 1, '', '2020-05-17 18:16:40.609249', 'Optimization algorithm for the generation of ONCV pseudopotentials', 'We present an optimization algorithm to construct pseudopotentials and use it to generate a set of Optimized Norm-Conserving Vanderbilt (ONCV) pseudopotentials for elements up to  (Bi) (excluding Lanthanides). We introduce a quality function that assesses the agreement of a pseudopotential calculation with all-electron FLAPW results, and the necessary plane-wave energy cutoff. This quality function allows us to use a Nelder–Mead optimization algorithm on a training set of materials to optimize the input parameters of the pseudopotential construction for most of the periodic table. We control the accuracy of the resulting pseudopotentials on a test set of materials independent of the training set. We find that the automatically constructed pseudopotentials (http://www.quantum-simulation.org) provide a good agreement with the all-electron results obtained using the FLEUR code with a plane-wave energy cutoff of approximately 60 Ry.', '<h2>1.&nbsp;Introduction</h2>\r\n\r\n<p><a href=\"https://www.sciencedirect.com/topics/chemistry/pseudopotential\" title=\"Learn more about Pseudopotential from ScienceDirect\'s AI-generated Topic Pages\">Pseudopotentials</a>&nbsp;were introduced over three decades ago as an elegant simplification of electronic structure computations&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000005\" name=\"bbr000005\">[1]</a>. They allow one to avoid the calculation of electronic states associated with core electrons, and focus instead on&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/valence-electron\" title=\"Learn more about Valence Electron from ScienceDirect\'s AI-generated Topic Pages\">valence electrons</a>&nbsp;that most often dominate phenomena of interest, in particular chemical bonding. In the context of&nbsp;<a href=\"https://www.sciencedirect.com/topics/earth-and-planetary-sciences/density-functional-theory\" title=\"Learn more about Density Functional Theory from ScienceDirect\'s AI-generated Topic Pages\">Density Functional Theory</a>&nbsp;(DFT), pseudopotentials have made it possible to solve the Kohn&ndash;Sham equations&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000010\" name=\"bbr000010\">[2]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000015\" name=\"bbr000015\">[3]</a>&nbsp;using a&nbsp;<a href=\"https://www.sciencedirect.com/topics/physics-and-astronomy/plane-waves\" title=\"Learn more about Plane Waves from ScienceDirect\'s AI-generated Topic Pages\">plane-wave</a>&nbsp;basis set, which considerably reduces the complexity of calculations, and allows for the use of efficient Fast&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/fourier-transform\" title=\"Learn more about Fourier Transform from ScienceDirect\'s AI-generated Topic Pages\">Fourier Transform</a>&nbsp;(FFT) algorithms. The introduction of norm-conserving pseudopotentials (NCPPs) by Hamann et&nbsp;al. in 1979&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000020\" name=\"bbr000020\">[4]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000025\" name=\"bbr000025\">[5]</a>&nbsp;greatly improved the accuracy of DFT plane wave calculations by imposing a constraint (norm conservation) in the construction of the potentials, thus improving the transferability of potentials to different chemical environments. More elaborate representations of pseudopotentials were later proposed, most notably ultrasoft pseudopotentials&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000030\" name=\"bbr000030\">[6]</a>&nbsp;(USPPs) and the projector augmented wave&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000035\" name=\"bbr000035\">[7]</a>&nbsp;(PAW) method, improving computational efficiency by reducing the required plane wave energy cutoff. The implementation of these PPs is however more complex than NCPPs&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000040\" name=\"bbr000040\">[8]</a>. In particular for advanced calculations involving hybrid density functionals&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000045\" name=\"bbr000045\">[9]</a>, many-body&nbsp;<a href=\"https://www.sciencedirect.com/topics/earth-and-planetary-sciences/perturbation-theory\" title=\"Learn more about Perturbation Theory from ScienceDirect\'s AI-generated Topic Pages\">perturbation theory</a>&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000050\" name=\"bbr000050\">[10]</a>, or density-functional perturbation theory&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000055\" name=\"bbr000055\">[11]</a>&nbsp;terms treating the additional on-site contributions have to be developed&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000060\" name=\"bbr000060\">[12]</a>. Both USPPs and PAWs have been used with great success in a large number of computational studies published over the past two decades. NCPPs were also widely used but suffered from the need to use a large plane wave basis set for some elements, especially&nbsp;<a href=\"https://www.sciencedirect.com/topics/physics-and-astronomy/transition-metals\" title=\"Learn more about Transition Metals from ScienceDirect\'s AI-generated Topic Pages\">transition metals</a>.</p>\r\n\r\n<p>Recently, Hamann suggested&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000040\" name=\"bbr000040\">[8]</a>&nbsp;a method to construct optimized norm-conserving Vanderbilt (ONCV) potentials following the USPP&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/construction-algorithm\" title=\"Learn more about Construction Algorithm from ScienceDirect\'s AI-generated Topic Pages\">construction algorithm</a>&nbsp;without forfeiting the norm-conservation. The resulting potentials have an accuracy comparable to the USPPs at a moderately increased plane-wave energy cutoff.</p>\r\n\r\n<p>Since the very first pseudopotentials were introduced, there has been an interest in a database of transferable, reference potentials that could be applied for many elements in the periodic table&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000025\" name=\"bbr000025\">[5]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000065\" name=\"bbr000065\">[13]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000070\" name=\"bbr000070\">[14]</a>. The need for a systematic database in&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/high-throughput\" title=\"Learn more about High Throughput from ScienceDirect\'s AI-generated Topic Pages\">high-throughput</a>&nbsp;calculations led to a recent revival of this field: Garrity et&nbsp;al.&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000075\" name=\"bbr000075\">[15]</a>&nbsp;proposed a new set of USPPs for the whole periodic table except the&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/noble-gas-atom\" title=\"Learn more about Noble Gas Atom from ScienceDirect\'s AI-generated Topic Pages\">noble gases</a>&nbsp;and the&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/lanthanoid-atom\" title=\"Learn more about Lanthanoid Atom from ScienceDirect\'s AI-generated Topic Pages\">rare earths</a>. Dal Corso&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000080\" name=\"bbr000080\">[16]</a>&nbsp;constructed a high- and a low-accuracy PAW set for all elements up to Pu. Common to these approaches is the fact that the input parameters of the PP construction are selected by experience based on the results of the all-electron (AE) calculation of the bare atom. The quality of the constructed PP is then tested by an evaluation of different crystal structures and by comparing to the all-electron FLAPW&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000085\" name=\"bbr000085\">[17]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000090\" name=\"bbr000090\">[18]</a>,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000095\" name=\"bbr000095\">[19]</a>&nbsp;results. To standardize the testing procedure, Lejaeghere et&nbsp;al.&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000100\" name=\"bbr000100\">[20]</a>&nbsp;suggested to compare the area between a Murnaghan fit&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000105\" name=\"bbr000105\">[21]</a>&nbsp;obtained with the PP and the AE calculation resulting in a&nbsp;<a href=\"https://www.sciencedirect.com/topics/earth-and-planetary-sciences/q-factor\" title=\"Learn more about Q Factor from ScienceDirect\'s AI-generated Topic Pages\">quality factor</a>&nbsp;&Delta;. K&uuml;&ccedil;&uuml;kbenli et&nbsp;al.&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000110\" name=\"bbr000110\">[22]</a>&nbsp;proposed a crystalline monoatomic solid test, where this quality factor is evaluated for the&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/simple-cubic-crystal-system\" title=\"Learn more about Simple Cubic Crystal System from ScienceDirect\'s AI-generated Topic Pages\">simple cubic</a>&nbsp;(sc),&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/body-centered-cubic-crystal-system\" title=\"Learn more about Body-Centered Cubic Crystal System from ScienceDirect\'s AI-generated Topic Pages\">body-centered cubic</a>&nbsp;(bcc), and&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/face-centered-cubic-crystal-system\" title=\"Learn more about Face-Centered Cubic Crystal System from ScienceDirect\'s AI-generated Topic Pages\">face-centered cubic</a>&nbsp;(fcc) structure to assess the quality of a PP. There are two improvements over these construction principles that we propose to address in this work. First, we introduce a quality function that takes into account the computational efficiency of the PP as well as its accuracy. Second, we allow for a systematic feedback of this quality function onto the input parameters defining the PP. In this way, we can introduce an automatic construction algorithm that optimizes the properties of the PP without bias from the constructor. We apply this algorithm to construct ONCV pseudopotentials and compare their performance with recent USPP&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000075\" name=\"bbr000075\">[15]</a>&nbsp;and PAW&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000080\" name=\"bbr000080\">[16]</a>&nbsp;PP libraries. The pseudopotentials are available in UPF and XML format on our webpage&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000115\" name=\"bbr000115\">[23]</a>.</p>\r\n\r\n<p>This paper is organized as follows: In Section&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#s000010\" name=\"bs000010\">2</a>, we outline the properties of the ONCV PPs and introduce the input parameters that will be optimized by the algorithm. In Section&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#s000015\" name=\"bs000015\">3</a>, we introduce the quality function to assess the performance of a PP, specify the materials we use to construct and test a PP, outline the setting of the&nbsp;<a href=\"https://www.sciencedirect.com/topics/physics-and-astronomy/dft-calculations\" title=\"Learn more about DFT Calculations from ScienceDirect\'s AI-generated Topic Pages\">DFT calculation</a>, and finally present the&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/optimization-algorithms\" title=\"Learn more about Optimization (Algorithms) from ScienceDirect\'s AI-generated Topic Pages\">optimization algorithm</a>&nbsp;that iterates construction and testing until a good PP is found. We compare the constructed PPs to results obtained with the FLAPW, the USPP, and the PAW method in Section&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#s000045\" name=\"bs000045\">4</a>&nbsp;and draw our conclusions in Section&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#s000065\" name=\"bs000065\">5</a>.</p>\r\n\r\n<h2>2.&nbsp;ONCV pseudopotentials</h2>\r\n\r\n<p>The optimized norm-conserving Vanderbilt (ONCV)&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/pseudopotential\" title=\"Learn more about Pseudopotential from ScienceDirect\'s AI-generated Topic Pages\">pseudopotentials</a>&nbsp;were recently proposed by Hamann&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000040\" name=\"bbr000040\">[8]</a>. Here, we briefly sketch their construction, following Hamann, to highlight the input parameters (bold in text) that determine the properties of the PP. The general idea is to introduce an&nbsp;<strong>upper limit</strong>&nbsp;wave vector&nbsp;qc&nbsp;and optimize the pseudo wave functions&nbsp;&phi;i(r)&nbsp;such that the residual&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/kinetic-energy\" title=\"Learn more about Kinetic Energy from ScienceDirect\'s AI-generated Topic Pages\">kinetic energy</a>(1)Eij(qc)=&int;qc&infin;dqq4&phi;i(q)&phi;j(q)above this cutoff is minimized. Here,&nbsp;&phi;i(q)&nbsp;is the&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/fourier-transform\" title=\"Learn more about Fourier Transform from ScienceDirect\'s AI-generated Topic Pages\">Fourier transform</a>&nbsp;of the pseudo wave function(2)&phi;i(q)=4&pi;&int;0&infin;drr2jl(qr)&phi;i(r),jl(qr)&nbsp;a&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/spherical-bessel-function\" title=\"Learn more about Spherical Bessel Function from ScienceDirect\'s AI-generated Topic Pages\">spherical Bessel function</a>, and&nbsp;l&nbsp;the&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/angular-momentum\" title=\"Learn more about Angular Momentum from ScienceDirect\'s AI-generated Topic Pages\">angular momentum</a>&nbsp;of the pseudo wave function. On the one hand, the cutoff&nbsp;qc&nbsp;determines which features of the physical potential can be described by the PP. On the other hand, increasing&nbsp;qc&nbsp;makes the PP harder and hence more costly to evaluate.</p>\r\n\r\n<p>For every angular momentum, a&nbsp;<strong>projector radius</strong>rc&nbsp;determines in which region the pseudoization is done. The projector radius is approximately inversely proportional to the cutoff&nbsp;qc&nbsp;so that a smaller value increases the computational cost along with the accuracy. Outside of this radius the wave function should follow the true all-electron wave function&nbsp;&psi;. To ensure the continuity at this radius, one imposes&nbsp;M&nbsp;constraints on the continuity of the pseudo wave function(3)dn&phi;drn|rc=dn&psi;drn|rc,for&nbsp;n=0,&hellip;,M&minus;1. In this work, we use&nbsp;M=5&nbsp;for all constructed PPs.</p>\r\n\r\n<p>The basis set used in the optimization is constructed from spherical Bessel functions. As the basis functions are only used inside the sphere, they are set to zero outside of the projector radius. This destroys the&nbsp;<a href=\"https://www.sciencedirect.com/topics/earth-and-planetary-sciences/orthogonality\" title=\"Learn more about Orthogonality from ScienceDirect\'s AI-generated Topic Pages\">orthogonality</a>&nbsp;of the basis, so that one needs to orthogonalize it again. A&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/linear-combination\" title=\"Learn more about Linear Combination from ScienceDirect\'s AI-generated Topic Pages\">linear combination</a>&nbsp;of the orthogonalized basis functions yields a new basis where a single basis function&nbsp;&phi;0&nbsp;satisfies the constraints in Eq.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#fd000015\" name=\"bfd000015\">(3)</a>&nbsp;and for all other basis functions&nbsp;&xi;nN&nbsp;the value and the&nbsp;M&minus;1&nbsp;derivatives at&nbsp;rc&nbsp;are zero. As a consequence, the sum of&nbsp;&phi;0&nbsp;and any linear combination of the&nbsp;&xi;nN&nbsp;will satisfy the constraints in Eq.&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#fd000015\" name=\"bfd000015\">(3)</a>. It is advantageous to select those linear combinations of&nbsp;&xi;nN&nbsp;that have a maximal impact on the&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/residual-energy\" title=\"Learn more about Residual Energy from ScienceDirect\'s AI-generated Topic Pages\">residual energy</a>&nbsp;by evaluating the&nbsp;<a href=\"https://www.sciencedirect.com/topics/earth-and-planetary-sciences/eigenvectors\" title=\"Learn more about Eigenvectors from ScienceDirect\'s AI-generated Topic Pages\">eigenvalues</a>&nbsp;en&nbsp;and eigenvectors&nbsp;&xi;nR(4)&phi;i=&phi;0+&sum;n=1N&minus;Mxn&xi;nR.In this work, we construct the PPs with&nbsp;N=8&nbsp;basis functions. Notice that the optimization of the pseudo wave function is performed under the constraint that the norm of the all-electron wave function is conserved(5)&int;0rcdrr2[&phi;i&lowast;(r)&phi;j(r)&minus;&psi;i&lowast;(r)&psi;j(r)]=0.</p>\r\n\r\n<p>From the obtained pseudo wave functions, one can construct projectors&nbsp;&chi;i(6)&chi;i(r)=(&epsilon;i&minus;T&minus;Vloc)ϕi(r),where&nbsp;T&nbsp;is the kinetic energy operator.&nbsp;Vloc&nbsp;is the local potential that follows the all-electron potential outside of&nbsp;rc&nbsp;and is extended smoothly to the origin by a polynomial. For occupied states&nbsp;&epsilon;i&nbsp;is the eigenvalue of the all-electron calculation. For unoccupied states, one needs to specify this&nbsp;<strong>energy shift</strong>&nbsp;before the construction of the PP. Following Ref.&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000040\" name=\"bbr000040\">[8]</a>, we construct two projectors per angular momentum&nbsp;l&le;lmax&nbsp;and only the local potential for all&nbsp;l&gt;lmax&nbsp;above. The projectors define the following nonlocal potential(7)VNL=&sum;ij|&chi;i〉Bij&minus;1〈&chi;j|where(8)Bij=〈&phi;i|&chi;j〉,which is a&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/hermitian-matrix\" title=\"Learn more about Hermitian Matrix from ScienceDirect\'s AI-generated Topic Pages\">Hermitian matrix</a>&nbsp;when normconserving pseudo wave functions are constructed&nbsp;&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#br000030\" name=\"bbr000030\">[6]</a>. One can simplify this potential by a&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/unitary-transformation\" title=\"Learn more about Unitary Transformation from ScienceDirect\'s AI-generated Topic Pages\">unitary transformation</a>&nbsp;to the eigenspace of the&nbsp;B&nbsp;matrix.</p>\r\n\r\n<h2>3.&nbsp;Computational details</h2>\r\n\r\n<h3>3.1.&nbsp;Quality function</h3>\r\n\r\n<p>In order to employ numerical&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/optimization-algorithms\" title=\"Learn more about Optimization (Algorithms) from ScienceDirect\'s AI-generated Topic Pages\">optimization algorithms</a>&nbsp;in the construction of PPs, we need a function that maps the multidimensional input parameter space onto a single number, the&nbsp;<em>quality</em>&nbsp;of the PP. A good PP is characterized by a small relative deviation(9)&delta;alatPP=alatPP/alatAE&minus;1between the&nbsp;<a href=\"https://www.sciencedirect.com/topics/computer-science/lattice-constant\" title=\"Learn more about Lattice Constant from ScienceDirect\'s AI-generated Topic Pages\">lattice constant</a>&nbsp;obtained in the&nbsp;<a href=\"https://www.sciencedirect.com/topics/physics-and-astronomy/plane-waves\" title=\"Learn more about Plane Waves from ScienceDirect\'s AI-generated Topic Pages\">plane-wave</a>&nbsp;PP calculation&nbsp;alatPP&nbsp;and in the AE calculation&nbsp;alatAE, respectively. A second criterion is the plane-wave energy cutoff&nbsp;Ecut&nbsp;necessary to converge the PP calculation. These two criteria compete with each other because the pseudoization of the potential reduces the necessary energy cutoff at the cost of a lower accuracy near the nucleus. Hence, we need to specify a target accuracy&nbsp;&delta;0&nbsp;which we want to achieve for our PPs, i.e.,&nbsp;for all materials&nbsp;|&delta;alatPP|&le;&delta;0. We select&nbsp;&delta;0=0.2%&nbsp;motivated by the fact that the choice of different codes or input parameters in the all-electron calculation may already lead to a relative error of approximately&nbsp;0.1%. To discriminate between PPs within the target accuracy, we include a term&nbsp;&prop;1/Ecut&nbsp;in the quality function, favoring smoother PPs over hard ones. For PPs that are significantly outside&nbsp;|&delta;alatPP|&gt;2&delta;0&nbsp;our target accuracy, we only focus on optimizing the relative deviation by an&nbsp;1/(&delta;alatPP)2&nbsp;term. We choose a smooth continuation between the two regions, resulting in the function depicted in&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0010465515001897#f000005\" name=\"bf000005\">Fig.&nbsp;1</a>. The quality function has the following form(10)q(&delta;,Ecut)={A+C&delta;2+D&delta;3+E&delta;4+F&delta;5&delta;&lt;2&delta;0(2&delta;0/&delta;)2&delta;&ge;2&delta;0withA=1+1280Ecuty0=1+680EcutC=32y0&minus;16A&minus;294&delta;03D=19A&minus;48y0+544&delta;02E=96y0&minus;33A&minus;12216&delta;04F=5A&minus;16y0+2216&delta;05.The function can be multiplied by an arbitrary scaling constant, which we set such that the value of the quality function is 1 at&nbsp;|&delta;alatPP|=2&delta;0.</p>\r\n\r\n<p><img alt=\"\" src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0010465515001897-gr1.jpg\" style=\"height:277px\" /></p>\r\n\r\n<ol>\r\n	<li><a download=\"\" href=\"https://ars.els-cdn.com/content/image/1-s2.0-S0010465515001897-gr1.jpg\" target=\"_blank\" title=\"Download full-size image\">Download :&nbsp;Download full-size image</a></li>\r\n</ol>\r\n\r\n<p>Fig.&nbsp;1.&nbsp;(Color online) Quality function for various energy-cutoffs&nbsp;Ecut. For small&nbsp;&delta;, it is proportional to&nbsp;1/Ecut; for large&nbsp;&delta;&nbsp;proportional to&nbsp;1/&delta;2&nbsp;and independent of&nbsp;Ecut.</p>\r\n\r\n<h3>3.2.&nbsp;Sets of materials</h3>\r\n\r\n<p>As the constructed&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/pseudopotential\" title=\"Learn more about Pseudopotential from ScienceDirect\'s AI-generated Topic Pages\">pseudopotentials</a>&nbsp;depend on the set of materials used in the optimization algorithm, it is important that the set contain physically relevant environments of the atom. Furthermore, we select highly symmetric structures with at most two atoms per unit cell to reduce the computation time. As representatives of a metallic environment, we select the&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/simple-cubic-crystal-system\" title=\"Learn more about Simple Cubic Crystal System from ScienceDirect\'s AI-generated Topic Pages\">simple cubic</a>&nbsp;(sc), the&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/body-centered-cubic-crystal-system\" title=\"Learn more about Body-Centered Cubic Crystal System from ScienceDirect\'s AI-generated Topic Pages\">body-centered cubic</a>&nbsp;(bcc), the&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/face-centered-cubic-crystal-system\" title=\"Learn more about Face-Centered Cubic Crystal System from ScienceDirect\'s AI-generated Topic Pages\">face-centered cubic</a>&nbsp;(fcc), and the diamond-cubic (dc) structure. Ionic environments are provided in a&nbsp;<a href=\"https://www.sciencedirect.com/topics/earth-and-planetary-sciences/halite\" title=\"Learn more about Halite from ScienceDirect\'s AI-generated Topic Pages\">rock-salt</a>&nbsp;or zinc-blende structure, where we combine elements such that they assume their most common oxidation state. This leads to a combination of elements from the lithium group with the&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/fluorine-atom\" title=\"Learn more about Fluorine Atom from ScienceDirect\'s AI-generated Topic Pages\">fluorine</a>&nbsp;group, the&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/beryllium\" title=\"Learn more about Beryllium from ScienceDirect\'s AI-generated Topic Pages\">beryllium</a>&nbsp;group with the oxygen group, and so on. We always use the three smallest elements of the respective groups to guarantee a variation in size of the resulting compounds. For the&nbsp;<a href=\"https://www.sciencedirect.com/topics/physics-and-astronomy/transition-metals\" title=\"Learn more about Transition Metals from ScienceDirect\'s AI-generated Topic Pages\">transition metals</a>, several oxidation states are often possible. Hence, we combine them with carbon, nitrogen, and oxygen to test these different valencies. As the&nbsp;<a href=\"https://www.sciencedirect.com/topics/chemistry/noble-gas-atom\" title=\"Learn more about Noble Gas Atom from ScienceDirect\'s AI-generated Topic Pages\">noble gases</a>&nbsp;do not form compounds, we test them only in the sc, bcc, fcc, and dc structure.</p>\r\n\r\n<p>Finally, we need to separate these materials into two sets. The&nbsp;<em>training set</em>&nbsp;consists of the bcc, and the fcc structure as well as all rock-salt compounds. It is used in the optimization algorithm to construct the PPs. As the PPs are specifically optimized to reproduce the structural properties of the training set, we can only judge if the PPs are highly accurate by calculating an independent&nbsp;<em>test set</em>. The test set contains the sc and the dc structure as well as all zinc-blende compounds. In total, the training and test sets consist of 602 materials, where every noble-gas atom is part of four materials, and every other element is part of at least ten materials.</p>', '2020-05-17 18:16:40.614597', 'Accepted', NULL, 5, 2);

-- ----------------------------
-- Table structure for app_article_keywords
-- ----------------------------
DROP TABLE IF EXISTS `app_article_keywords`;
CREATE TABLE `app_article_keywords`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `article_id` int NOT NULL,
  `keyword_id` int NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `app_article_keywords_article_id_keyword_id_53f5a227_uniq`(`article_id` ASC, `keyword_id` ASC) USING BTREE,
  INDEX `app_article_keywords_keyword_id_357d30fa_fk_app_keyword_id`(`keyword_id` ASC) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 6 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of app_article_keywords
-- ----------------------------
INSERT INTO `app_article_keywords` VALUES (1, 1, 1);
INSERT INTO `app_article_keywords` VALUES (2, 1, 2);
INSERT INTO `app_article_keywords` VALUES (3, 2, 3);
INSERT INTO `app_article_keywords` VALUES (4, 2, 4);
INSERT INTO `app_article_keywords` VALUES (5, 3, 5);

-- ----------------------------
-- Table structure for app_editornote
-- ----------------------------
DROP TABLE IF EXISTS `app_editornote`;
CREATE TABLE `app_editornote`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `text` varchar(500) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `created_at` datetime(6) NOT NULL,
  `article_id` int NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `app_editornote_article_id_c9992417_fk_app_article_id`(`article_id` ASC) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of app_editornote
-- ----------------------------

-- ----------------------------
-- Table structure for app_journal
-- ----------------------------
DROP TABLE IF EXISTS `app_journal`;
CREATE TABLE `app_journal`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `code` varchar(300) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `j_image` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `description` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL,
  `subject_id` int NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `code`(`code` ASC) USING BTREE,
  INDEX `app_journal_subject_id_4602b1ea_fk_app_subject_id`(`subject_id` ASC) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 6 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of app_journal
-- ----------------------------
INSERT INTO `app_journal` VALUES (1, 'Advances in Data Science and Adaptive Analysis', 'j_images/cover.jpg', 'Advances in Adaptive Data Analysis', 1);
INSERT INTO `app_journal` VALUES (2, 'The Physics Educator', 'j_images/cover_1.jpg', 'The Physics Educator is an international peer-reviewed journal published quarterly by World Scientific and the Institute of Physics Singapore. The focus of the journal is the teaching and learning of physics and related topics at the secondary school, high school, junior college and the introductory undergraduate level. Articles related to the history and philosophy of physics as well as the design of the physics curriculum may also be submitted.\r\nThe aim of the journal is to enhance the teaching of physics in lecture rooms, classrooms and teaching laboratories through new approaches, insights and demonstrations, and to provide a lively forum for discussions on educational and curriculum developments, strategies for teaching and classroom management, pedagogy, equipment and other topics relevant to the teaching of physics. Book reviews relevant to the journal\'s aims may also be submitted.', 2);
INSERT INTO `app_journal` VALUES (3, 'The International Journal of Computer and Telecommunications Networking', 'j_images/computer_image.gif', 'Computer Networks is an international, archival journal providing a publication vehicle for complete coverage of all topics of interest to those involved in the computer communications networking area. The audience includes researchers, managers and operators of networks as well as designers and implementors...', 3);
INSERT INTO `app_journal` VALUES (4, 'Computers & Graphics: X', 'j_images/X25901486.jpg', 'Computers & Graphics: X offers authors with high-quality research who want to publish in a gold open access journal the opportunity to make their work immediately, permanently, and freely accessible.\r\nComputers & Graphics and Computers & Graphics: X have the same aims and scope. A unified editorial team manages rigorous peer-review for both titles using the same submission system. The author\'s choice of journal is blinded to referees, ensuring the editorial process is identical.', 1);
INSERT INTO `app_journal` VALUES (5, 'Artificial Intelligence', 'j_images/X00043702.jpg', 'The journal of Artificial Intelligence (AIJ) welcomes papers on broad aspects of AI that constitute advances in the overall field including, but not limited to, cognition and AI, automated reasoning and inference, case-based reasoning, commonsense reasoning, computer vision, constraint processing, ethical AI, heuristic search, human interfaces, intelligent robotics, knowledge representation, machine learning, multi-agent systems, natural language processing, planning and action, and reasoning under uncertainty. The journal reports results achieved in addition to proposals for new ways of looking at AI problems, both of which must include demonstrations of value and effectiveness.', 1);

-- ----------------------------
-- Table structure for app_journal_keywords
-- ----------------------------
DROP TABLE IF EXISTS `app_journal_keywords`;
CREATE TABLE `app_journal_keywords`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `journal_id` int NOT NULL,
  `keyword_id` int NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `app_journal_keywords_journal_id_keyword_id_a31425da_uniq`(`journal_id` ASC, `keyword_id` ASC) USING BTREE,
  INDEX `app_journal_keywords_keyword_id_5189e585_fk_app_keyword_id`(`keyword_id` ASC) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of app_journal_keywords
-- ----------------------------

-- ----------------------------
-- Table structure for app_keyword
-- ----------------------------
DROP TABLE IF EXISTS `app_keyword`;
CREATE TABLE `app_keyword`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `word` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 6 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of app_keyword
-- ----------------------------
INSERT INTO `app_keyword` VALUES (1, 'Algorithm');
INSERT INTO `app_keyword` VALUES (2, 'Data-Structures');
INSERT INTO `app_keyword` VALUES (3, 'CERN');
INSERT INTO `app_keyword` VALUES (4, 'Particle - Physics');
INSERT INTO `app_keyword` VALUES (5, 'Computer Science');

-- ----------------------------
-- Table structure for app_myuser
-- ----------------------------
DROP TABLE IF EXISTS `app_myuser`;
CREATE TABLE `app_myuser`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `password` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `last_login` datetime(6) NULL DEFAULT NULL,
  `name` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `email` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `user_type` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `bio` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL,
  `is_active` tinyint(1) NOT NULL,
  `is_admin` tinyint(1) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `email`(`email` ASC) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 11 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of app_myuser
-- ----------------------------
INSERT INTO `app_myuser` VALUES (0, 'pbkdf2_sha256$180000$aWDgAJBemkD5$Y8bfLZg6eAjTGJzdKSWuX1iS7iyZFakvcIAWy2dsdfQ=', '2023-02-11 07:38:07.472669', 'Sakarin Habusaya', 'habusaya@gmail.com', 'AUTHOR', NULL, 1, 0);
INSERT INTO `app_myuser` VALUES (1, 'pbkdf2_sha256$180000$aWDgAJBemkD5$Y8bfLZg6eAjTGJzdKSWuX1iS7iyZFakvcIAWy2dsdfQ=', '2020-05-18 07:13:27.386567', 'Sumit', 'sumit@gmail.com', 'AUTHOR', 'Bio', 1, 1);
INSERT INTO `app_myuser` VALUES (2, 'pbkdf2_sha256$180000$aWDgAJBemkD5$Y8bfLZg6eAjTGJzdKSWuX1iS7iyZFakvcIAWy2dsdfQ=', NULL, 'Sumit Kumar', 'sumitkumar150299@gmail.com', 'AUTHOR', 'A short Bio', 1, 0);
INSERT INTO `app_myuser` VALUES (3, 'pbkdf2_sha256$180000$aWDgAJBemkD5$Y8bfLZg6eAjTGJzdKSWuX1iS7iyZFakvcIAWy2dsdfQ=', '2020-05-17 16:54:36.210767', 'Author1', 'author1@gmail.com', 'AUTHOR', NULL, 1, 0);
INSERT INTO `app_myuser` VALUES (4, 'pbkdf2_sha256$180000$aWDgAJBemkD5$Y8bfLZg6eAjTGJzdKSWuX1iS7iyZFakvcIAWy2dsdfQ=', '2023-02-11 07:39:31.259932', 'Publisher1', 'publisher1@gmail.com', 'PUBLISHER', NULL, 1, 0);
INSERT INTO `app_myuser` VALUES (5, 'pbkdf2_sha256$180000$aWDgAJBemkD5$Y8bfLZg6eAjTGJzdKSWuX1iS7iyZFakvcIAWy2dsdfQ=', '2020-05-20 11:40:36.265059', 'Author 2', 'author2@gmail.com', 'AUTHOR', NULL, 1, 0);
INSERT INTO `app_myuser` VALUES (6, 'pbkdf2_sha256$180000$aWDgAJBemkD5$Y8bfLZg6eAjTGJzdKSWuX1iS7iyZFakvcIAWy2dsdfQ=', '2020-05-20 11:43:37.784707', 'Editor 2', 'editor2@gmail.com', 'EDITOR', NULL, 1, 0);
INSERT INTO `app_myuser` VALUES (7, 'pbkdf2_sha256$180000$aWDgAJBemkD5$Y8bfLZg6eAjTGJzdKSWuX1iS7iyZFakvcIAWy2dsdfQ=', '2020-05-20 11:46:47.217067', 'Sumit Kumar', 'publisher2@gmail.com', 'PUBLISHER', NULL, 1, 0);
INSERT INTO `app_myuser` VALUES (8, 'pbkdf2_sha256$180000$aWDgAJBemkD5$Y8bfLZg6eAjTGJzdKSWuX1iS7iyZFakvcIAWy2dsdfQ=', '2023-02-11 07:40:35.017326', 'Ashutosh Singh', 'editor3@gmail.com', 'EDITOR', NULL, 1, 0);
INSERT INTO `app_myuser` VALUES (9, 'pbkdf2_sha256$180000$aWDgAJBemkD5$Y8bfLZg6eAjTGJzdKSWuX1iS7iyZFakvcIAWy2dsdfQ=', '2020-05-20 04:38:12.085772', 'Rohan Singh', 'author3@gmail.com', 'AUTHOR', NULL, 1, 0);
INSERT INTO `app_myuser` VALUES (10, 'pbkdf2_sha256$180000$aWDgAJBemkD5$Y8bfLZg6eAjTGJzdKSWuX1iS7iyZFakvcIAWy2dsdfQ=', '2021-06-18 03:58:42.572258', 'Adones Evangelista', 'ado@gmail.com', 'AUTHOR', NULL, 1, 0);

-- ----------------------------
-- Table structure for app_subject
-- ----------------------------
DROP TABLE IF EXISTS `app_subject`;
CREATE TABLE `app_subject`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `name` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 4 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of app_subject
-- ----------------------------
INSERT INTO `app_subject` VALUES (1, 'Computer Science');
INSERT INTO `app_subject` VALUES (2, 'Physics');
INSERT INTO `app_subject` VALUES (3, 'Computer Networks');

-- ----------------------------
-- Table structure for auth_group
-- ----------------------------
DROP TABLE IF EXISTS `auth_group`;
CREATE TABLE `auth_group`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `name` varchar(150) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `name`(`name` ASC) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of auth_group
-- ----------------------------

-- ----------------------------
-- Table structure for auth_group_permissions
-- ----------------------------
DROP TABLE IF EXISTS `auth_group_permissions`;
CREATE TABLE `auth_group_permissions`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `group_id` int NOT NULL,
  `permission_id` int NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `auth_group_permissions_group_id_permission_id_0cd325b0_uniq`(`group_id` ASC, `permission_id` ASC) USING BTREE,
  INDEX `auth_group_permissio_permission_id_84c5c92e_fk_auth_perm`(`permission_id` ASC) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of auth_group_permissions
-- ----------------------------

-- ----------------------------
-- Table structure for auth_permission
-- ----------------------------
DROP TABLE IF EXISTS `auth_permission`;
CREATE TABLE `auth_permission`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `content_type_id` int NOT NULL,
  `codename` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `auth_permission_content_type_id_codename_01ab375a_uniq`(`content_type_id` ASC, `codename` ASC) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 45 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of auth_permission
-- ----------------------------
INSERT INTO `auth_permission` VALUES (1, 'Can add log entry', 1, 'add_logentry');
INSERT INTO `auth_permission` VALUES (2, 'Can change log entry', 1, 'change_logentry');
INSERT INTO `auth_permission` VALUES (3, 'Can delete log entry', 1, 'delete_logentry');
INSERT INTO `auth_permission` VALUES (4, 'Can view log entry', 1, 'view_logentry');
INSERT INTO `auth_permission` VALUES (5, 'Can add permission', 2, 'add_permission');
INSERT INTO `auth_permission` VALUES (6, 'Can change permission', 2, 'change_permission');
INSERT INTO `auth_permission` VALUES (7, 'Can delete permission', 2, 'delete_permission');
INSERT INTO `auth_permission` VALUES (8, 'Can view permission', 2, 'view_permission');
INSERT INTO `auth_permission` VALUES (9, 'Can add group', 3, 'add_group');
INSERT INTO `auth_permission` VALUES (10, 'Can change group', 3, 'change_group');
INSERT INTO `auth_permission` VALUES (11, 'Can delete group', 3, 'delete_group');
INSERT INTO `auth_permission` VALUES (12, 'Can view group', 3, 'view_group');
INSERT INTO `auth_permission` VALUES (13, 'Can add content type', 4, 'add_contenttype');
INSERT INTO `auth_permission` VALUES (14, 'Can change content type', 4, 'change_contenttype');
INSERT INTO `auth_permission` VALUES (15, 'Can delete content type', 4, 'delete_contenttype');
INSERT INTO `auth_permission` VALUES (16, 'Can view content type', 4, 'view_contenttype');
INSERT INTO `auth_permission` VALUES (17, 'Can add session', 5, 'add_session');
INSERT INTO `auth_permission` VALUES (18, 'Can change session', 5, 'change_session');
INSERT INTO `auth_permission` VALUES (19, 'Can delete session', 5, 'delete_session');
INSERT INTO `auth_permission` VALUES (20, 'Can view session', 5, 'view_session');
INSERT INTO `auth_permission` VALUES (21, 'Can add my user', 6, 'add_myuser');
INSERT INTO `auth_permission` VALUES (22, 'Can change my user', 6, 'change_myuser');
INSERT INTO `auth_permission` VALUES (23, 'Can delete my user', 6, 'delete_myuser');
INSERT INTO `auth_permission` VALUES (24, 'Can view my user', 6, 'view_myuser');
INSERT INTO `auth_permission` VALUES (25, 'Can add article', 7, 'add_article');
INSERT INTO `auth_permission` VALUES (26, 'Can change article', 7, 'change_article');
INSERT INTO `auth_permission` VALUES (27, 'Can delete article', 7, 'delete_article');
INSERT INTO `auth_permission` VALUES (28, 'Can view article', 7, 'view_article');
INSERT INTO `auth_permission` VALUES (29, 'Can add keyword', 8, 'add_keyword');
INSERT INTO `auth_permission` VALUES (30, 'Can change keyword', 8, 'change_keyword');
INSERT INTO `auth_permission` VALUES (31, 'Can delete keyword', 8, 'delete_keyword');
INSERT INTO `auth_permission` VALUES (32, 'Can view keyword', 8, 'view_keyword');
INSERT INTO `auth_permission` VALUES (33, 'Can add subject', 9, 'add_subject');
INSERT INTO `auth_permission` VALUES (34, 'Can change subject', 9, 'change_subject');
INSERT INTO `auth_permission` VALUES (35, 'Can delete subject', 9, 'delete_subject');
INSERT INTO `auth_permission` VALUES (36, 'Can view subject', 9, 'view_subject');
INSERT INTO `auth_permission` VALUES (37, 'Can add journal', 10, 'add_journal');
INSERT INTO `auth_permission` VALUES (38, 'Can change journal', 10, 'change_journal');
INSERT INTO `auth_permission` VALUES (39, 'Can delete journal', 10, 'delete_journal');
INSERT INTO `auth_permission` VALUES (40, 'Can view journal', 10, 'view_journal');
INSERT INTO `auth_permission` VALUES (41, 'Can add editor note', 11, 'add_editornote');
INSERT INTO `auth_permission` VALUES (42, 'Can change editor note', 11, 'change_editornote');
INSERT INTO `auth_permission` VALUES (43, 'Can delete editor note', 11, 'delete_editornote');
INSERT INTO `auth_permission` VALUES (44, 'Can view editor note', 11, 'view_editornote');

-- ----------------------------
-- Table structure for django_admin_log
-- ----------------------------
DROP TABLE IF EXISTS `django_admin_log`;
CREATE TABLE `django_admin_log`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `action_time` datetime(6) NOT NULL,
  `object_id` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL,
  `object_repr` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `action_flag` smallint UNSIGNED NOT NULL,
  `change_message` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `content_type_id` int NULL DEFAULT NULL,
  `user_id` int NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `django_admin_log_content_type_id_c4bce8eb_fk_django_co`(`content_type_id` ASC) USING BTREE,
  INDEX `django_admin_log_user_id_c564eba6_fk_app_myuser_id`(`user_id` ASC) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of django_admin_log
-- ----------------------------

-- ----------------------------
-- Table structure for django_content_type
-- ----------------------------
DROP TABLE IF EXISTS `django_content_type`;
CREATE TABLE `django_content_type`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `app_label` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `model` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE INDEX `django_content_type_app_label_model_76bd3d3b_uniq`(`app_label` ASC, `model` ASC) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 12 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of django_content_type
-- ----------------------------
INSERT INTO `django_content_type` VALUES (1, 'admin', 'logentry');
INSERT INTO `django_content_type` VALUES (7, 'app', 'article');
INSERT INTO `django_content_type` VALUES (11, 'app', 'editornote');
INSERT INTO `django_content_type` VALUES (10, 'app', 'journal');
INSERT INTO `django_content_type` VALUES (8, 'app', 'keyword');
INSERT INTO `django_content_type` VALUES (6, 'app', 'myuser');
INSERT INTO `django_content_type` VALUES (9, 'app', 'subject');
INSERT INTO `django_content_type` VALUES (3, 'auth', 'group');
INSERT INTO `django_content_type` VALUES (2, 'auth', 'permission');
INSERT INTO `django_content_type` VALUES (4, 'contenttypes', 'contenttype');
INSERT INTO `django_content_type` VALUES (5, 'sessions', 'session');

-- ----------------------------
-- Table structure for django_migrations
-- ----------------------------
DROP TABLE IF EXISTS `django_migrations`;
CREATE TABLE `django_migrations`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `app` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `applied` datetime(6) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 28 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of django_migrations
-- ----------------------------
INSERT INTO `django_migrations` VALUES (1, 'contenttypes', '0001_initial', '2023-02-11 07:21:17.158435');
INSERT INTO `django_migrations` VALUES (2, 'app', '0001_initial', '2023-02-11 07:21:18.000791');
INSERT INTO `django_migrations` VALUES (3, 'admin', '0001_initial', '2023-02-11 07:21:19.042580');
INSERT INTO `django_migrations` VALUES (4, 'admin', '0002_logentry_remove_auto_add', '2023-02-11 07:21:22.176091');
INSERT INTO `django_migrations` VALUES (5, 'admin', '0003_logentry_add_action_flag_choices', '2023-02-11 07:21:22.277619');
INSERT INTO `django_migrations` VALUES (6, 'app', '0002_auto_20200515_1655', '2023-02-11 07:21:30.111932');
INSERT INTO `django_migrations` VALUES (7, 'app', '0003_auto_20200517_1354', '2023-02-11 07:21:48.252529');
INSERT INTO `django_migrations` VALUES (8, 'app', '0004_auto_20200517_1357', '2023-02-11 07:21:48.392676');
INSERT INTO `django_migrations` VALUES (9, 'app', '0005_auto_20200517_1506', '2023-02-11 07:21:50.765649');
INSERT INTO `django_migrations` VALUES (10, 'app', '0006_auto_20200517_1507', '2023-02-11 07:21:50.882899');
INSERT INTO `django_migrations` VALUES (11, 'app', '0007_auto_20200517_1755', '2023-02-11 07:21:54.249185');
INSERT INTO `django_migrations` VALUES (12, 'app', '0008_auto_20200520_1149', '2023-02-11 07:21:55.822094');
INSERT INTO `django_migrations` VALUES (13, 'app', '0009_auto_20200520_1150', '2023-02-11 07:21:57.603598');
INSERT INTO `django_migrations` VALUES (14, 'app', '0010_auto_20200520_1154', '2023-02-11 07:21:57.742065');
INSERT INTO `django_migrations` VALUES (15, 'contenttypes', '0002_remove_content_type_name', '2023-02-11 07:22:00.272086');
INSERT INTO `django_migrations` VALUES (16, 'auth', '0001_initial', '2023-02-11 07:22:01.935410');
INSERT INTO `django_migrations` VALUES (17, 'auth', '0002_alter_permission_name_max_length', '2023-02-11 07:22:11.737398');
INSERT INTO `django_migrations` VALUES (18, 'auth', '0003_alter_user_email_max_length', '2023-02-11 07:22:11.856843');
INSERT INTO `django_migrations` VALUES (19, 'auth', '0004_alter_user_username_opts', '2023-02-11 07:22:11.962083');
INSERT INTO `django_migrations` VALUES (20, 'auth', '0005_alter_user_last_login_null', '2023-02-11 07:22:12.129401');
INSERT INTO `django_migrations` VALUES (21, 'auth', '0006_require_contenttypes_0002', '2023-02-11 07:22:12.233962');
INSERT INTO `django_migrations` VALUES (22, 'auth', '0007_alter_validators_add_error_messages', '2023-02-11 07:22:12.364414');
INSERT INTO `django_migrations` VALUES (23, 'auth', '0008_alter_user_username_max_length', '2023-02-11 07:22:12.568188');
INSERT INTO `django_migrations` VALUES (24, 'auth', '0009_alter_user_last_name_max_length', '2023-02-11 07:22:12.795026');
INSERT INTO `django_migrations` VALUES (25, 'auth', '0010_alter_group_name_max_length', '2023-02-11 07:22:15.249793');
INSERT INTO `django_migrations` VALUES (26, 'auth', '0011_update_proxy_permissions', '2023-02-11 07:22:15.712256');
INSERT INTO `django_migrations` VALUES (27, 'sessions', '0001_initial', '2023-02-11 07:22:16.945728');

-- ----------------------------
-- Table structure for django_session
-- ----------------------------
DROP TABLE IF EXISTS `django_session`;
CREATE TABLE `django_session`  (
  `session_key` varchar(40) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `session_data` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `expire_date` datetime(6) NOT NULL,
  PRIMARY KEY (`session_key`) USING BTREE,
  INDEX `django_session_expire_date_a5c62663`(`expire_date` ASC) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of django_session
-- ----------------------------
INSERT INTO `django_session` VALUES ('69ermab6op0b30brlvcbmommu2nkc92x', 'NTlmZTZiNzdiNGMyOTIwNTk5ZDMxMGNkMDg4MzgwNzMyYTY0MDhkZTp7Il9hdXRoX3VzZXJfaWQiOiI2IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIyOTkxN2IxMzhmNzExN2VjNjM2NGI3Yjg3YjkxMjFlOTBlYzQzOGE2In0=', '2020-05-31 04:48:03.538824');
INSERT INTO `django_session` VALUES ('7y6z7xtlatewcu2infe9o2nydhpl2c55', 'MDVkYzRiMTA5ODE4NjFlNGE0MWNhNGEwNmJiNjAzMWYxN2E2YzdjZTp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIxNjVlZWEzYWExNzRkODY3OTIxODE2N2ExYmU2ODNmYzM2YjQ4MTQwIn0=', '2020-05-28 07:04:35.162210');
INSERT INTO `django_session` VALUES ('9vywxp6vg78uuw4nkxrsh8hwvr6mc1qy', 'ZjMzZTE0MThjNTJlMWNjNzBjNzUxOGVjZWM0MmNkNDRmZjcyZmQwMzp7Il9hdXRoX3VzZXJfaWQiOiI1IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJhZDc3NmRiNDIzZTZjNWNjZWNiYTQzNmUwYzViYzczMzg0MGNlNmI1In0=', '2020-05-30 17:54:26.805153');
INSERT INTO `django_session` VALUES ('el3r0xcovnj653sbo2zpkpm1dlhalj0z', 'NTlmZTZiNzdiNGMyOTIwNTk5ZDMxMGNkMDg4MzgwNzMyYTY0MDhkZTp7Il9hdXRoX3VzZXJfaWQiOiI2IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIyOTkxN2IxMzhmNzExN2VjNjM2NGI3Yjg3YjkxMjFlOTBlYzQzOGE2In0=', '2020-05-30 05:57:33.930124');
INSERT INTO `django_session` VALUES ('na43bj95ssez01qwul2wpsiovb22nrne', 'NmU4Y2NmZjQ2Mjg1NWZlYzE5ZmI5YmZkMDUzOWYxNGMxYTlmZTA5MDp7Il9hdXRoX3VzZXJfaWQiOiI3IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJhMGFlMGVmMGM0MmE5ZTRiZGM1NmEwNWM3OTgyNjJiOWY1ZWMzZmQ5In0=', '2020-06-03 11:46:47.317470');
INSERT INTO `django_session` VALUES ('nifws8iy23o93qgomz8n1w59upd1octn', 'NTlmZTZiNzdiNGMyOTIwNTk5ZDMxMGNkMDg4MzgwNzMyYTY0MDhkZTp7Il9hdXRoX3VzZXJfaWQiOiI2IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIyOTkxN2IxMzhmNzExN2VjNjM2NGI3Yjg3YjkxMjFlOTBlYzQzOGE2In0=', '2020-05-29 17:55:12.238082');
INSERT INTO `django_session` VALUES ('oycrddh3ydq08h60ekbfbu0w0n92eow0', 'NTlmZTZiNzdiNGMyOTIwNTk5ZDMxMGNkMDg4MzgwNzMyYTY0MDhkZTp7Il9hdXRoX3VzZXJfaWQiOiI2IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIyOTkxN2IxMzhmNzExN2VjNjM2NGI3Yjg3YjkxMjFlOTBlYzQzOGE2In0=', '2020-05-31 16:56:01.292555');
INSERT INTO `django_session` VALUES ('q36fwe4v4j4pqzcegs3pqy9xkcd79n3d', 'NmU4Y2NmZjQ2Mjg1NWZlYzE5ZmI5YmZkMDUzOWYxNGMxYTlmZTA5MDp7Il9hdXRoX3VzZXJfaWQiOiI3IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJhMGFlMGVmMGM0MmE5ZTRiZGM1NmEwNWM3OTgyNjJiOWY1ZWMzZmQ5In0=', '2020-06-03 07:09:49.387279');
INSERT INTO `django_session` VALUES ('ql6xroadeu1viyvw7z9r8pnsjbzlg3gw', 'NGQ3OGY2NDkyMjc5NzZlYmUyNGU1MTIzMDAxMGQyNmE4ZmNlZTU3ODp7Il9hdXRoX3VzZXJfaWQiOiI4IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIzODBkNTdkNzYxMWUwY2RhZjJjM2E4YzcxM2I1NzYxN2ExMGEyNzlkIn0=', '2023-02-25 07:40:35.120359');
INSERT INTO `django_session` VALUES ('uc6vfh9gic0p4he3hcy8x6bjq5hvpahf', 'MDVkYzRiMTA5ODE4NjFlNGE0MWNhNGEwNmJiNjAzMWYxN2E2YzdjZTp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIxNjVlZWEzYWExNzRkODY3OTIxODE2N2ExYmU2ODNmYzM2YjQ4MTQwIn0=', '2020-05-30 09:42:23.072288');
INSERT INTO `django_session` VALUES ('uii22txq39p65wabh2ir2pqnmwc7hpof', 'ZjMzZTE0MThjNTJlMWNjNzBjNzUxOGVjZWM0MmNkNDRmZjcyZmQwMzp7Il9hdXRoX3VzZXJfaWQiOiI1IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJhZDc3NmRiNDIzZTZjNWNjZWNiYTQzNmUwYzViYzczMzg0MGNlNmI1In0=', '2020-06-01 10:43:53.585166');
INSERT INTO `django_session` VALUES ('v06izjey3wxjsfpyesllerozudy2pfls', 'MDVkYzRiMTA5ODE4NjFlNGE0MWNhNGEwNmJiNjAzMWYxN2E2YzdjZTp7Il9hdXRoX3VzZXJfaWQiOiIxIiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIxNjVlZWEzYWExNzRkODY3OTIxODE2N2ExYmU2ODNmYzM2YjQ4MTQwIn0=', '2020-05-31 15:21:05.762270');
INSERT INTO `django_session` VALUES ('vpjezvg252vc8wesxw5a4g5o8mf83e9x', 'Yzk5Njk5M2E2ZjliOTc0ZWM3NTUwNWU3MDM4N2YwNzEzYzI1ZjA2Zjp7Il9hdXRoX3VzZXJfaWQiOiI0IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJmZGZkZTU2ZjQwNjUyYTM2YzVlZTA0NTNiZWI0NDFkYzQ2ODU4YTU3In0=', '2020-05-30 03:26:02.720834');
INSERT INTO `django_session` VALUES ('w9zhkwu7ojl2dec6umjadj4agjblmopl', 'NTlmZTZiNzdiNGMyOTIwNTk5ZDMxMGNkMDg4MzgwNzMyYTY0MDhkZTp7Il9hdXRoX3VzZXJfaWQiOiI2IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiIyOTkxN2IxMzhmNzExN2VjNjM2NGI3Yjg3YjkxMjFlOTBlYzQzOGE2In0=', '2020-06-01 07:14:36.668927');
INSERT INTO `django_session` VALUES ('wgev4tf507nl4vu62jm6pswj49ari7vc', 'ZjMzZTE0MThjNTJlMWNjNzBjNzUxOGVjZWM0MmNkNDRmZjcyZmQwMzp7Il9hdXRoX3VzZXJfaWQiOiI1IiwiX2F1dGhfdXNlcl9iYWNrZW5kIjoiZGphbmdvLmNvbnRyaWIuYXV0aC5iYWNrZW5kcy5Nb2RlbEJhY2tlbmQiLCJfYXV0aF91c2VyX2hhc2giOiJhZDc3NmRiNDIzZTZjNWNjZWNiYTQzNmUwYzViYzczMzg0MGNlNmI1In0=', '2020-05-30 10:42:25.556766');

-- ----------------------------
-- Table structure for sqlite_sequence
-- ----------------------------
DROP TABLE IF EXISTS `sqlite_sequence`;
CREATE TABLE `sqlite_sequence`  (
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `seq` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of sqlite_sequence
-- ----------------------------
INSERT INTO `sqlite_sequence` VALUES ('django_migrations', '27');
INSERT INTO `sqlite_sequence` VALUES ('django_admin_log', '15');
INSERT INTO `sqlite_sequence` VALUES ('django_content_type', '11');
INSERT INTO `sqlite_sequence` VALUES ('auth_permission', '44');
INSERT INTO `sqlite_sequence` VALUES ('auth_group', '0');
INSERT INTO `sqlite_sequence` VALUES ('app_myuser', '10');
INSERT INTO `sqlite_sequence` VALUES ('app_subject', '3');
INSERT INTO `sqlite_sequence` VALUES ('app_keyword', '5');
INSERT INTO `sqlite_sequence` VALUES ('app_journal', '5');
INSERT INTO `sqlite_sequence` VALUES ('app_journal_keywords', '4');
INSERT INTO `sqlite_sequence` VALUES ('app_article_keywords', '5');
INSERT INTO `sqlite_sequence` VALUES ('app_article', '8');

SET FOREIGN_KEY_CHECKS = 1;
